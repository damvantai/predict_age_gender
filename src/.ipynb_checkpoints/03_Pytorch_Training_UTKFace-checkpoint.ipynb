{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from cnn_finetune import make_model\n",
    "\n",
    "from net import AGNet\n",
    "from loss import AGLoss\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from datagen import ListDataset\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "test_batch_size = 64\n",
    "epochs = 50\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "dropout = 0.2\n",
    "start_epoch = 0\n",
    "best_correct = 0\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.CenterCrop(150),\n",
    "    transforms.RandomCrop(150, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485,0.456,0.406), (0.229,0.224,0.225)\n",
    "    )\n",
    "])\n",
    "trainset = ListDataset(root='../data/UTKFace/', transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=8)\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.CenterCrop(150),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485,0.456,0.406), (0.229,0.224,0.225))\n",
    "])\n",
    "testset = ListDataset(root='../data/test/', transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = AGNet()\n",
    "net.cuda()\n",
    "criterion = AGLoss()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def accuracy(age_preds, age_targets, gender_preds, gender_targets):\n",
    "def accuracy(gender_preds, gender_targets):\n",
    "\n",
    "#     AGE_TOLERANCE = 3\n",
    "#     age_prob = F.softmax(age_preds)\n",
    "#     age_expect = torch.sum(Variable(torch.arange(1, 117)).cuda() * age_prob, 1)\n",
    "    \n",
    "#     age_correct = ((age_expect - age_targets.float()).abs() < AGE_TOLERANCE).int().sum().cpu().data[0]\n",
    "    \n",
    "    gender_preds = F.sigmoid(gender_preds)\n",
    "    gender_preds = (gender_preds > 0.5).int()\n",
    "    gender_correct = (gender_preds == gender_targets.int()).int().cpu().sum().data[0]\n",
    "    return gender_correct\n",
    "#     return age_correct, gender_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    total = 0\n",
    "    age_correct = 0\n",
    "    gender_correct = 0\n",
    "    for batch_idx, (inputs, age_targets, gender_targets) in enumerate(trainloader):\n",
    "        inputs = Variable(inputs.cuda())\n",
    "        age_targets = Variable(age_targets.cuda())\n",
    "        gender_targets = Variable(gender_targets.cuda())\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # \n",
    "        age_preds, gender_preds = net(inputs)\n",
    "        loss = criterion(gender_preds, gender_targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.data[0]\n",
    "        \n",
    "#         age_correct_i, gender_correct_i = accuracy(age_preds,\n",
    "#                                                   age_targets, gender_preds,\n",
    "#                                                   gender_targets)\n",
    "        gender_correct_i = accuracy(gender_preds, gender_targets)\n",
    "#         age_correct += age_correct_i\n",
    "        gender_correct += gender_correct_i\n",
    "        total += len(inputs)\n",
    "        print('train_loss: %f | avg_loss: %f | gender_precise: %f (%d/%d) [%d/%d]'\n",
    "             % (loss.data[0], train_loss/(batch_idx+1),\n",
    "               100.*gender_correct/total, gender_correct, total,\n",
    "               batch_idx+1, len(trainloader)))\n",
    "#         print('train_loss: %.3f | avg_loss: %.3f | age_prec: %.3f (%d/%d) | gender_prec: %.3f (%d/%d)  [%d/%d]'  \\\n",
    "#             % (loss.data[0], train_loss/(batch_idx+1),      \\\n",
    "#                100.*age_correct/total, age_correct, total,  \\\n",
    "#                100.*gender_correct/total, gender_correct, total,    \\\n",
    "#                batch_idx+1, len(trainloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "def test(epoch):\n",
    "    print('\\nTest')\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    total = 0\n",
    "    age_correct = 0\n",
    "    gender_correct = 0\n",
    "    for batch_idx, (inputs, age_targets, gender_targets) in enumerate(testloader):\n",
    "        inputs = Variable(inputs.cuda())\n",
    "        age_targets = Variable(age_targets.cuda())\n",
    "        gender_targets = Variable(gender_targets.cuda())\n",
    "\n",
    "#         age_preds, gender_preds = net(inputs)\n",
    "        age_preds, gender_preds = net(inputs)\n",
    "#         loss = criterion(age_preds, age_targets, gender_preds, gender_targets)\n",
    "#         loss = criterion(gender_preds, gender_targets)\n",
    "\n",
    "#         test_loss += loss.data[0]\n",
    "        gender_correct_i = accuracy(gender_preds, gender_targets)\n",
    "#         age_correct_i, gender_correct_i = accuracy(\n",
    "#             age_preds, age_targets, gender_preds, gender_targets)\n",
    "#         age_correct += age_correct_i\n",
    "        gender_correct += gender_correct_i\n",
    "        total += len(inputs)\n",
    "        print('gender_prec: %f (%d/%d) [%d/%d]' % (100.*gender_correct/total, gender_correct, total, batch_idx+1, len(testloader)))\n",
    "#         print('test_loss: %f | avg_loss: %f | age_prec: %f (%d/%d) | gender_prec: %f (%d/%d)  [%d/%d]' \\\n",
    "#             % (loss.data[0], test_loss/(batch_idx+1),      \\\n",
    "#                100.*age_correct/total, age_correct, total,  \\\n",
    "#                100.*gender_correct/total, gender_correct, total, \\\n",
    "#                batch_idx+1, len(trainloader)))\n",
    "\n",
    "    # Save checkpoint\n",
    "    global best_correct\n",
    "#     if age_correct + gender_correct > best_correct:\n",
    "    if gender_correct > best_correct:\n",
    "        print('Saving..')\n",
    "        best_correct = gender_correct\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'correct': best_correct,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('../weights/checkpoint'):\n",
    "            os.mkdir('../weights/checkpoint')\n",
    "        torch.save(state, '..weights/checkpoint/ckpt.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neosai/Documents/projects/predict_age_gender/src/loss.py:19: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  print(\"gender_loss: {}\".format(gender_loss.data[0]))\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender_loss: 0.6942108273506165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.694211 | avg_loss: 0.694211 | gender_precise: 39.000000 (50/128) [1/186]\n",
      "gender_loss: 0.6932098269462585\n",
      "train_loss: 0.693210 | avg_loss: 0.693710 | gender_precise: 44.000000 (113/256) [2/186]\n",
      "gender_loss: 0.6929138898849487\n",
      "train_loss: 0.692914 | avg_loss: 0.693445 | gender_precise: 47.000000 (181/384) [3/186]\n",
      "gender_loss: 0.6931552290916443\n",
      "train_loss: 0.693155 | avg_loss: 0.693372 | gender_precise: 47.000000 (245/512) [4/186]\n",
      "gender_loss: 0.6931732296943665\n",
      "train_loss: 0.693173 | avg_loss: 0.693333 | gender_precise: 48.000000 (308/640) [5/186]\n",
      "gender_loss: 0.6933927536010742\n",
      "train_loss: 0.693393 | avg_loss: 0.693343 | gender_precise: 47.000000 (364/768) [6/186]\n",
      "gender_loss: 0.6932075023651123\n",
      "train_loss: 0.693208 | avg_loss: 0.693323 | gender_precise: 47.000000 (424/896) [7/186]\n",
      "gender_loss: 0.693169116973877\n",
      "train_loss: 0.693169 | avg_loss: 0.693304 | gender_precise: 47.000000 (483/1024) [8/186]\n",
      "gender_loss: 0.693134605884552\n",
      "train_loss: 0.693135 | avg_loss: 0.693285 | gender_precise: 47.000000 (547/1152) [9/186]\n",
      "gender_loss: 0.6931548118591309\n",
      "train_loss: 0.693155 | avg_loss: 0.693272 | gender_precise: 47.000000 (610/1280) [10/186]\n",
      "gender_loss: 0.692495584487915\n",
      "train_loss: 0.692496 | avg_loss: 0.693202 | gender_precise: 48.000000 (686/1408) [11/186]\n",
      "gender_loss: 0.6921485662460327\n",
      "train_loss: 0.692149 | avg_loss: 0.693114 | gender_precise: 49.000000 (763/1536) [12/186]\n",
      "gender_loss: 0.6935804486274719\n",
      "train_loss: 0.693580 | avg_loss: 0.693150 | gender_precise: 49.000000 (823/1664) [13/186]\n",
      "gender_loss: 0.693985641002655\n",
      "train_loss: 0.693986 | avg_loss: 0.693210 | gender_precise: 49.000000 (881/1792) [14/186]\n",
      "gender_loss: 0.6934849619865417\n",
      "train_loss: 0.693485 | avg_loss: 0.693228 | gender_precise: 49.000000 (943/1920) [15/186]\n",
      "gender_loss: 0.6948617100715637\n",
      "train_loss: 0.694862 | avg_loss: 0.693330 | gender_precise: 48.000000 (997/2048) [16/186]\n",
      "gender_loss: 0.693011999130249\n",
      "train_loss: 0.693012 | avg_loss: 0.693311 | gender_precise: 48.000000 (1062/2176) [17/186]\n",
      "gender_loss: 0.6928268671035767\n",
      "train_loss: 0.692827 | avg_loss: 0.693284 | gender_precise: 48.000000 (1128/2304) [18/186]\n",
      "gender_loss: 0.6930001974105835\n",
      "train_loss: 0.693000 | avg_loss: 0.693269 | gender_precise: 49.000000 (1193/2432) [19/186]\n",
      "gender_loss: 0.6932118535041809\n",
      "train_loss: 0.693212 | avg_loss: 0.693267 | gender_precise: 49.000000 (1257/2560) [20/186]\n",
      "gender_loss: 0.6926469206809998\n",
      "train_loss: 0.692647 | avg_loss: 0.693237 | gender_precise: 49.000000 (1324/2688) [21/186]\n",
      "gender_loss: 0.6909627914428711\n",
      "train_loss: 0.690963 | avg_loss: 0.693134 | gender_precise: 49.000000 (1400/2816) [22/186]\n",
      "gender_loss: 0.6932128071784973\n",
      "train_loss: 0.693213 | avg_loss: 0.693137 | gender_precise: 49.000000 (1464/2944) [23/186]\n",
      "gender_loss: 0.6919600963592529\n",
      "train_loss: 0.691960 | avg_loss: 0.693088 | gender_precise: 49.000000 (1534/3072) [24/186]\n",
      "gender_loss: 0.6923153400421143\n",
      "train_loss: 0.692315 | avg_loss: 0.693057 | gender_precise: 50.000000 (1602/3200) [25/186]\n",
      "gender_loss: 0.6922876238822937\n",
      "train_loss: 0.692288 | avg_loss: 0.693028 | gender_precise: 50.000000 (1670/3328) [26/186]\n",
      "gender_loss: 0.6908829212188721\n",
      "train_loss: 0.690883 | avg_loss: 0.692948 | gender_precise: 50.000000 (1743/3456) [27/186]\n",
      "gender_loss: 0.6916224360466003\n",
      "train_loss: 0.691622 | avg_loss: 0.692901 | gender_precise: 50.000000 (1813/3584) [28/186]\n",
      "gender_loss: 0.6939062476158142\n",
      "train_loss: 0.693906 | avg_loss: 0.692935 | gender_precise: 50.000000 (1875/3712) [29/186]\n",
      "gender_loss: 0.6913854479789734\n",
      "train_loss: 0.691385 | avg_loss: 0.692884 | gender_precise: 50.000000 (1945/3840) [30/186]\n",
      "gender_loss: 0.6882076859474182\n",
      "train_loss: 0.688208 | avg_loss: 0.692733 | gender_precise: 51.000000 (2024/3968) [31/186]\n",
      "gender_loss: 0.6926563382148743\n",
      "train_loss: 0.692656 | avg_loss: 0.692731 | gender_precise: 51.000000 (2090/4096) [32/186]\n",
      "gender_loss: 0.6898565888404846\n",
      "train_loss: 0.689857 | avg_loss: 0.692644 | gender_precise: 51.000000 (2163/4224) [33/186]\n",
      "gender_loss: 0.6909288167953491\n",
      "train_loss: 0.690929 | avg_loss: 0.692593 | gender_precise: 51.000000 (2233/4352) [34/186]\n",
      "gender_loss: 0.6931052803993225\n",
      "train_loss: 0.693105 | avg_loss: 0.692608 | gender_precise: 51.000000 (2298/4480) [35/186]\n",
      "gender_loss: 0.6951308846473694\n",
      "train_loss: 0.695131 | avg_loss: 0.692678 | gender_precise: 51.000000 (2359/4608) [36/186]\n",
      "gender_loss: 0.6869964003562927\n",
      "train_loss: 0.686996 | avg_loss: 0.692524 | gender_precise: 51.000000 (2436/4736) [37/186]\n",
      "gender_loss: 0.69590163230896\n",
      "train_loss: 0.695902 | avg_loss: 0.692613 | gender_precise: 51.000000 (2496/4864) [38/186]\n",
      "gender_loss: 0.6898568868637085\n",
      "train_loss: 0.689857 | avg_loss: 0.692542 | gender_precise: 51.000000 (2567/4992) [39/186]\n",
      "gender_loss: 0.6891555786132812\n",
      "train_loss: 0.689156 | avg_loss: 0.692458 | gender_precise: 51.000000 (2639/5120) [40/186]\n",
      "gender_loss: 0.6926602721214294\n",
      "train_loss: 0.692660 | avg_loss: 0.692463 | gender_precise: 51.000000 (2705/5248) [41/186]\n",
      "gender_loss: 0.6920579075813293\n",
      "train_loss: 0.692058 | avg_loss: 0.692453 | gender_precise: 51.000000 (2772/5376) [42/186]\n",
      "gender_loss: 0.6913461089134216\n",
      "train_loss: 0.691346 | avg_loss: 0.692427 | gender_precise: 51.000000 (2840/5504) [43/186]\n",
      "gender_loss: 0.6926807165145874\n",
      "train_loss: 0.692681 | avg_loss: 0.692433 | gender_precise: 51.000000 (2906/5632) [44/186]\n",
      "gender_loss: 0.6913365721702576\n",
      "train_loss: 0.691337 | avg_loss: 0.692409 | gender_precise: 51.000000 (2974/5760) [45/186]\n",
      "gender_loss: 0.6941279172897339\n",
      "train_loss: 0.694128 | avg_loss: 0.692446 | gender_precise: 51.000000 (3038/5888) [46/186]\n",
      "gender_loss: 0.6970198750495911\n",
      "train_loss: 0.697020 | avg_loss: 0.692543 | gender_precise: 51.000000 (3098/6016) [47/186]\n",
      "gender_loss: 0.6905726194381714\n",
      "train_loss: 0.690573 | avg_loss: 0.692502 | gender_precise: 51.000000 (3167/6144) [48/186]\n",
      "gender_loss: 0.6912891864776611\n",
      "train_loss: 0.691289 | avg_loss: 0.692478 | gender_precise: 51.000000 (3235/6272) [49/186]\n",
      "gender_loss: 0.6861827373504639\n",
      "train_loss: 0.686183 | avg_loss: 0.692352 | gender_precise: 51.000000 (3310/6400) [50/186]\n",
      "gender_loss: 0.6920019388198853\n",
      "train_loss: 0.692002 | avg_loss: 0.692345 | gender_precise: 51.000000 (3377/6528) [51/186]\n",
      "gender_loss: 0.6912769675254822\n",
      "train_loss: 0.691277 | avg_loss: 0.692324 | gender_precise: 51.000000 (3445/6656) [52/186]\n",
      "gender_loss: 0.6874322295188904\n",
      "train_loss: 0.687432 | avg_loss: 0.692232 | gender_precise: 51.000000 (3518/6784) [53/186]\n",
      "gender_loss: 0.6865911483764648\n",
      "train_loss: 0.686591 | avg_loss: 0.692128 | gender_precise: 51.000000 (3592/6912) [54/186]\n",
      "gender_loss: 0.6896644830703735\n",
      "train_loss: 0.689664 | avg_loss: 0.692083 | gender_precise: 52.000000 (3662/7040) [55/186]\n",
      "gender_loss: 0.6953095197677612\n",
      "train_loss: 0.695310 | avg_loss: 0.692140 | gender_precise: 51.000000 (3725/7168) [56/186]\n",
      "gender_loss: 0.6953524351119995\n",
      "train_loss: 0.695352 | avg_loss: 0.692197 | gender_precise: 51.000000 (3788/7296) [57/186]\n",
      "gender_loss: 0.6870282888412476\n",
      "train_loss: 0.687028 | avg_loss: 0.692107 | gender_precise: 52.000000 (3861/7424) [58/186]\n",
      "gender_loss: 0.689500093460083\n",
      "train_loss: 0.689500 | avg_loss: 0.692063 | gender_precise: 52.000000 (3931/7552) [59/186]\n",
      "gender_loss: 0.6911978125572205\n",
      "train_loss: 0.691198 | avg_loss: 0.692049 | gender_precise: 52.000000 (3999/7680) [60/186]\n",
      "gender_loss: 0.6894174218177795\n",
      "train_loss: 0.689417 | avg_loss: 0.692006 | gender_precise: 52.000000 (4069/7808) [61/186]\n",
      "gender_loss: 0.6813248991966248\n",
      "train_loss: 0.681325 | avg_loss: 0.691833 | gender_precise: 52.000000 (4148/7936) [62/186]\n",
      "gender_loss: 0.6984661817550659\n",
      "train_loss: 0.698466 | avg_loss: 0.691939 | gender_precise: 52.000000 (4208/8064) [63/186]\n",
      "gender_loss: 0.6893345713615417\n",
      "train_loss: 0.689335 | avg_loss: 0.691898 | gender_precise: 52.000000 (4278/8192) [64/186]\n",
      "gender_loss: 0.6968132257461548\n",
      "train_loss: 0.696813 | avg_loss: 0.691974 | gender_precise: 52.000000 (4340/8320) [65/186]\n",
      "gender_loss: 0.6892889738082886\n",
      "train_loss: 0.689289 | avg_loss: 0.691933 | gender_precise: 52.000000 (4410/8448) [66/186]\n",
      "gender_loss: 0.6978164315223694\n",
      "train_loss: 0.697816 | avg_loss: 0.692021 | gender_precise: 52.000000 (4471/8576) [67/186]\n",
      "gender_loss: 0.6940402984619141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.694040 | avg_loss: 0.692051 | gender_precise: 52.000000 (4536/8704) [68/186]\n",
      "gender_loss: 0.6959288120269775\n",
      "train_loss: 0.695929 | avg_loss: 0.692107 | gender_precise: 52.000000 (4599/8832) [69/186]\n",
      "gender_loss: 0.6902096271514893\n",
      "train_loss: 0.690210 | avg_loss: 0.692080 | gender_precise: 52.000000 (4668/8960) [70/186]\n",
      "gender_loss: 0.6978049278259277\n",
      "train_loss: 0.697805 | avg_loss: 0.692160 | gender_precise: 52.000000 (4729/9088) [71/186]\n",
      "gender_loss: 0.6846057772636414\n",
      "train_loss: 0.684606 | avg_loss: 0.692055 | gender_precise: 52.000000 (4804/9216) [72/186]\n",
      "gender_loss: 0.6855738759040833\n",
      "train_loss: 0.685574 | avg_loss: 0.691966 | gender_precise: 52.000000 (4878/9344) [73/186]\n",
      "gender_loss: 0.6949324011802673\n",
      "train_loss: 0.694932 | avg_loss: 0.692007 | gender_precise: 52.000000 (4942/9472) [74/186]\n",
      "gender_loss: 0.6930127143859863\n",
      "train_loss: 0.693013 | avg_loss: 0.692020 | gender_precise: 52.000000 (5008/9600) [75/186]\n",
      "gender_loss: 0.695817232131958\n",
      "train_loss: 0.695817 | avg_loss: 0.692070 | gender_precise: 52.000000 (5071/9728) [76/186]\n",
      "gender_loss: 0.701389491558075\n",
      "train_loss: 0.701389 | avg_loss: 0.692191 | gender_precise: 52.000000 (5128/9856) [77/186]\n",
      "gender_loss: 0.6975230574607849\n",
      "train_loss: 0.697523 | avg_loss: 0.692259 | gender_precise: 51.000000 (5189/9984) [78/186]\n",
      "gender_loss: 0.6884902715682983\n",
      "train_loss: 0.688490 | avg_loss: 0.692212 | gender_precise: 52.000000 (5260/10112) [79/186]\n",
      "gender_loss: 0.6973124742507935\n",
      "train_loss: 0.697312 | avg_loss: 0.692275 | gender_precise: 51.000000 (5321/10240) [80/186]\n",
      "gender_loss: 0.6963902115821838\n",
      "train_loss: 0.696390 | avg_loss: 0.692326 | gender_precise: 51.000000 (5383/10368) [81/186]\n",
      "gender_loss: 0.693707287311554\n",
      "train_loss: 0.693707 | avg_loss: 0.692343 | gender_precise: 51.000000 (5448/10496) [82/186]\n",
      "gender_loss: 0.696885347366333\n",
      "train_loss: 0.696885 | avg_loss: 0.692398 | gender_precise: 51.000000 (5509/10624) [83/186]\n",
      "gender_loss: 0.6943822503089905\n",
      "train_loss: 0.694382 | avg_loss: 0.692421 | gender_precise: 51.000000 (5573/10752) [84/186]\n",
      "gender_loss: 0.6874196529388428\n",
      "train_loss: 0.687420 | avg_loss: 0.692362 | gender_precise: 51.000000 (5646/10880) [85/186]\n",
      "gender_loss: 0.6927955746650696\n",
      "train_loss: 0.692796 | avg_loss: 0.692367 | gender_precise: 51.000000 (5712/11008) [86/186]\n",
      "gender_loss: 0.6986211538314819\n",
      "train_loss: 0.698621 | avg_loss: 0.692439 | gender_precise: 51.000000 (5770/11136) [87/186]\n",
      "gender_loss: 0.6848844289779663\n",
      "train_loss: 0.684884 | avg_loss: 0.692354 | gender_precise: 51.000000 (5847/11264) [88/186]\n",
      "gender_loss: 0.6898968815803528\n",
      "train_loss: 0.689897 | avg_loss: 0.692326 | gender_precise: 51.000000 (5917/11392) [89/186]\n",
      "gender_loss: 0.6968916058540344\n",
      "train_loss: 0.696892 | avg_loss: 0.692377 | gender_precise: 51.000000 (5977/11520) [90/186]\n",
      "gender_loss: 0.6893022060394287\n",
      "train_loss: 0.689302 | avg_loss: 0.692343 | gender_precise: 51.000000 (6048/11648) [91/186]\n",
      "gender_loss: 0.6893347501754761\n",
      "train_loss: 0.689335 | avg_loss: 0.692310 | gender_precise: 51.000000 (6119/11776) [92/186]\n",
      "gender_loss: 0.6940262913703918\n",
      "train_loss: 0.694026 | avg_loss: 0.692329 | gender_precise: 51.000000 (6183/11904) [93/186]\n",
      "gender_loss: 0.6973152756690979\n",
      "train_loss: 0.697315 | avg_loss: 0.692382 | gender_precise: 51.000000 (6242/12032) [94/186]\n",
      "gender_loss: 0.6926615834236145\n",
      "train_loss: 0.692662 | avg_loss: 0.692385 | gender_precise: 51.000000 (6308/12160) [95/186]\n",
      "gender_loss: 0.6862205266952515\n",
      "train_loss: 0.686221 | avg_loss: 0.692320 | gender_precise: 51.000000 (6384/12288) [96/186]\n",
      "gender_loss: 0.6901203989982605\n",
      "train_loss: 0.690120 | avg_loss: 0.692298 | gender_precise: 51.000000 (6454/12416) [97/186]\n",
      "gender_loss: 0.6938599944114685\n",
      "train_loss: 0.693860 | avg_loss: 0.692314 | gender_precise: 51.000000 (6518/12544) [98/186]\n",
      "gender_loss: 0.6971217393875122\n",
      "train_loss: 0.697122 | avg_loss: 0.692362 | gender_precise: 51.000000 (6577/12672) [99/186]\n",
      "gender_loss: 0.6945739984512329\n",
      "train_loss: 0.694574 | avg_loss: 0.692384 | gender_precise: 51.000000 (6640/12800) [100/186]\n",
      "gender_loss: 0.6839596629142761\n",
      "train_loss: 0.683960 | avg_loss: 0.692301 | gender_precise: 51.000000 (6720/12928) [101/186]\n",
      "gender_loss: 0.6932722926139832\n",
      "train_loss: 0.693272 | avg_loss: 0.692311 | gender_precise: 51.000000 (6785/13056) [102/186]\n",
      "gender_loss: 0.6907403469085693\n",
      "train_loss: 0.690740 | avg_loss: 0.692295 | gender_precise: 51.000000 (6854/13184) [103/186]\n",
      "gender_loss: 0.6945642232894897\n",
      "train_loss: 0.694564 | avg_loss: 0.692317 | gender_precise: 51.000000 (6917/13312) [104/186]\n",
      "gender_loss: 0.6907415390014648\n",
      "train_loss: 0.690742 | avg_loss: 0.692302 | gender_precise: 51.000000 (6986/13440) [105/186]\n",
      "gender_loss: 0.6945680379867554\n",
      "train_loss: 0.694568 | avg_loss: 0.692323 | gender_precise: 51.000000 (7049/13568) [106/186]\n",
      "gender_loss: 0.6995711326599121\n",
      "train_loss: 0.699571 | avg_loss: 0.692391 | gender_precise: 51.000000 (7104/13696) [107/186]\n",
      "gender_loss: 0.6895729899406433\n",
      "train_loss: 0.689573 | avg_loss: 0.692365 | gender_precise: 51.000000 (7175/13824) [108/186]\n",
      "gender_loss: 0.6907704472541809\n",
      "train_loss: 0.690770 | avg_loss: 0.692350 | gender_precise: 51.000000 (7244/13952) [109/186]\n",
      "gender_loss: 0.6920053362846375\n",
      "train_loss: 0.692005 | avg_loss: 0.692347 | gender_precise: 51.000000 (7311/14080) [110/186]\n",
      "gender_loss: 0.6919679641723633\n",
      "train_loss: 0.691968 | avg_loss: 0.692344 | gender_precise: 51.000000 (7378/14208) [111/186]\n",
      "gender_loss: 0.6932439208030701\n",
      "train_loss: 0.693244 | avg_loss: 0.692352 | gender_precise: 51.000000 (7443/14336) [112/186]\n",
      "gender_loss: 0.6968117356300354\n",
      "train_loss: 0.696812 | avg_loss: 0.692392 | gender_precise: 51.000000 (7502/14464) [113/186]\n",
      "gender_loss: 0.6890952587127686\n",
      "train_loss: 0.689095 | avg_loss: 0.692363 | gender_precise: 51.000000 (7574/14592) [114/186]\n",
      "gender_loss: 0.6873335838317871\n",
      "train_loss: 0.687334 | avg_loss: 0.692319 | gender_precise: 51.000000 (7649/14720) [115/186]\n",
      "gender_loss: 0.6943804621696472\n",
      "train_loss: 0.694380 | avg_loss: 0.692337 | gender_precise: 51.000000 (7712/14848) [116/186]\n",
      "gender_loss: 0.6966915726661682\n",
      "train_loss: 0.696692 | avg_loss: 0.692374 | gender_precise: 51.000000 (7771/14976) [117/186]\n",
      "gender_loss: 0.6955347657203674\n",
      "train_loss: 0.695535 | avg_loss: 0.692401 | gender_precise: 51.000000 (7832/15104) [118/186]\n",
      "gender_loss: 0.6903378963470459\n",
      "train_loss: 0.690338 | avg_loss: 0.692383 | gender_precise: 51.000000 (7902/15232) [119/186]\n",
      "gender_loss: 0.6914296746253967\n",
      "train_loss: 0.691430 | avg_loss: 0.692375 | gender_precise: 51.000000 (7970/15360) [120/186]\n",
      "gender_loss: 0.6932363510131836\n",
      "train_loss: 0.693236 | avg_loss: 0.692382 | gender_precise: 51.000000 (8035/15488) [121/186]\n",
      "gender_loss: 0.6970391869544983\n",
      "train_loss: 0.697039 | avg_loss: 0.692421 | gender_precise: 51.000000 (8093/15616) [122/186]\n",
      "gender_loss: 0.692069411277771\n",
      "train_loss: 0.692069 | avg_loss: 0.692418 | gender_precise: 51.000000 (8160/15744) [123/186]\n",
      "gender_loss: 0.6903991103172302\n",
      "train_loss: 0.690399 | avg_loss: 0.692401 | gender_precise: 51.000000 (8230/15872) [124/186]\n",
      "gender_loss: 0.6952472925186157\n",
      "train_loss: 0.695247 | avg_loss: 0.692424 | gender_precise: 51.000000 (8291/16000) [125/186]\n",
      "gender_loss: 0.6941225528717041\n",
      "train_loss: 0.694123 | avg_loss: 0.692438 | gender_precise: 51.000000 (8354/16128) [126/186]\n",
      "gender_loss: 0.6951351761817932\n",
      "train_loss: 0.695135 | avg_loss: 0.692459 | gender_precise: 51.000000 (8415/16256) [127/186]\n",
      "gender_loss: 0.6961258053779602\n",
      "train_loss: 0.696126 | avg_loss: 0.692488 | gender_precise: 51.000000 (8474/16384) [128/186]\n",
      "gender_loss: 0.6949379444122314\n",
      "train_loss: 0.694938 | avg_loss: 0.692507 | gender_precise: 51.000000 (8535/16512) [129/186]\n",
      "gender_loss: 0.6921305060386658\n",
      "train_loss: 0.692131 | avg_loss: 0.692504 | gender_precise: 51.000000 (8602/16640) [130/186]\n",
      "gender_loss: 0.6898990869522095\n",
      "train_loss: 0.689899 | avg_loss: 0.692484 | gender_precise: 51.000000 (8674/16768) [131/186]\n",
      "gender_loss: 0.6883069276809692\n",
      "train_loss: 0.688307 | avg_loss: 0.692452 | gender_precise: 51.000000 (8750/16896) [132/186]\n",
      "gender_loss: 0.6912821531295776\n",
      "train_loss: 0.691282 | avg_loss: 0.692443 | gender_precise: 51.000000 (8819/17024) [133/186]\n",
      "gender_loss: 0.6938100457191467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.693810 | avg_loss: 0.692454 | gender_precise: 51.000000 (8882/17152) [134/186]\n",
      "gender_loss: 0.6890815496444702\n",
      "train_loss: 0.689082 | avg_loss: 0.692429 | gender_precise: 51.000000 (8956/17280) [135/186]\n",
      "gender_loss: 0.6939033269882202\n",
      "train_loss: 0.693903 | avg_loss: 0.692439 | gender_precise: 51.000000 (9019/17408) [136/186]\n",
      "gender_loss: 0.6973665952682495\n",
      "train_loss: 0.697367 | avg_loss: 0.692475 | gender_precise: 51.000000 (9074/17536) [137/186]\n",
      "gender_loss: 0.6951184272766113\n",
      "train_loss: 0.695118 | avg_loss: 0.692495 | gender_precise: 51.000000 (9134/17664) [138/186]\n",
      "gender_loss: 0.6882700324058533\n",
      "train_loss: 0.688270 | avg_loss: 0.692464 | gender_precise: 51.000000 (9210/17792) [139/186]\n",
      "gender_loss: 0.6938259601593018\n",
      "train_loss: 0.693826 | avg_loss: 0.692474 | gender_precise: 51.000000 (9273/17920) [140/186]\n",
      "gender_loss: 0.6912797689437866\n",
      "train_loss: 0.691280 | avg_loss: 0.692465 | gender_precise: 51.000000 (9342/18048) [141/186]\n",
      "gender_loss: 0.6963562369346619\n",
      "train_loss: 0.696356 | avg_loss: 0.692493 | gender_precise: 51.000000 (9399/18176) [142/186]\n",
      "gender_loss: 0.6963120102882385\n",
      "train_loss: 0.696312 | avg_loss: 0.692520 | gender_precise: 51.000000 (9456/18304) [143/186]\n",
      "gender_loss: 0.6909928321838379\n",
      "train_loss: 0.690993 | avg_loss: 0.692509 | gender_precise: 51.000000 (9526/18432) [144/186]\n",
      "gender_loss: 0.6922019720077515\n",
      "train_loss: 0.692202 | avg_loss: 0.692507 | gender_precise: 51.000000 (9593/18560) [145/186]\n",
      "gender_loss: 0.6898366808891296\n",
      "train_loss: 0.689837 | avg_loss: 0.692489 | gender_precise: 51.000000 (9666/18688) [146/186]\n",
      "gender_loss: 0.6913938522338867\n",
      "train_loss: 0.691394 | avg_loss: 0.692481 | gender_precise: 51.000000 (9735/18816) [147/186]\n",
      "gender_loss: 0.6910240054130554\n",
      "train_loss: 0.691024 | avg_loss: 0.692471 | gender_precise: 51.000000 (9805/18944) [148/186]\n",
      "gender_loss: 0.6952550411224365\n",
      "train_loss: 0.695255 | avg_loss: 0.692490 | gender_precise: 51.000000 (9864/19072) [149/186]\n",
      "gender_loss: 0.6922051310539246\n",
      "train_loss: 0.692205 | avg_loss: 0.692488 | gender_precise: 51.000000 (9931/19200) [150/186]\n",
      "gender_loss: 0.6921337246894836\n",
      "train_loss: 0.692134 | avg_loss: 0.692486 | gender_precise: 51.000000 (9998/19328) [151/186]\n",
      "gender_loss: 0.6929073929786682\n",
      "train_loss: 0.692907 | avg_loss: 0.692488 | gender_precise: 51.000000 (10063/19456) [152/186]\n",
      "gender_loss: 0.690186083316803\n",
      "train_loss: 0.690186 | avg_loss: 0.692473 | gender_precise: 51.000000 (10135/19584) [153/186]\n",
      "gender_loss: 0.6857335567474365\n",
      "train_loss: 0.685734 | avg_loss: 0.692430 | gender_precise: 51.000000 (10218/19712) [154/186]\n",
      "gender_loss: 0.6904553771018982\n",
      "train_loss: 0.690455 | avg_loss: 0.692417 | gender_precise: 51.000000 (10289/19840) [155/186]\n",
      "gender_loss: 0.6885131001472473\n",
      "train_loss: 0.688513 | avg_loss: 0.692392 | gender_precise: 51.000000 (10364/19968) [156/186]\n",
      "gender_loss: 0.688256561756134\n",
      "train_loss: 0.688257 | avg_loss: 0.692365 | gender_precise: 51.000000 (10439/20096) [157/186]\n",
      "gender_loss: 0.6894285082817078\n",
      "train_loss: 0.689429 | avg_loss: 0.692347 | gender_precise: 51.000000 (10511/20224) [158/186]\n",
      "gender_loss: 0.6892790198326111\n",
      "train_loss: 0.689279 | avg_loss: 0.692328 | gender_precise: 51.000000 (10583/20352) [159/186]\n",
      "gender_loss: 0.689582347869873\n",
      "train_loss: 0.689582 | avg_loss: 0.692310 | gender_precise: 52.000000 (10654/20480) [160/186]\n",
      "gender_loss: 0.6962646245956421\n",
      "train_loss: 0.696265 | avg_loss: 0.692335 | gender_precise: 51.000000 (10714/20608) [161/186]\n",
      "gender_loss: 0.6951253414154053\n",
      "train_loss: 0.695125 | avg_loss: 0.692352 | gender_precise: 51.000000 (10776/20736) [162/186]\n",
      "gender_loss: 0.693929135799408\n",
      "train_loss: 0.693929 | avg_loss: 0.692362 | gender_precise: 51.000000 (10840/20864) [163/186]\n",
      "gender_loss: 0.6898640990257263\n",
      "train_loss: 0.689864 | avg_loss: 0.692347 | gender_precise: 51.000000 (10910/20992) [164/186]\n",
      "gender_loss: 0.6947756409645081\n",
      "train_loss: 0.694776 | avg_loss: 0.692361 | gender_precise: 51.000000 (10973/21120) [165/186]\n",
      "gender_loss: 0.6947073936462402\n",
      "train_loss: 0.694707 | avg_loss: 0.692376 | gender_precise: 51.000000 (11036/21248) [166/186]\n",
      "gender_loss: 0.6889970302581787\n",
      "train_loss: 0.688997 | avg_loss: 0.692355 | gender_precise: 51.000000 (11107/21376) [167/186]\n",
      "gender_loss: 0.696224570274353\n",
      "train_loss: 0.696225 | avg_loss: 0.692378 | gender_precise: 51.000000 (11168/21504) [168/186]\n",
      "gender_loss: 0.6918143630027771\n",
      "train_loss: 0.691814 | avg_loss: 0.692375 | gender_precise: 51.000000 (11235/21632) [169/186]\n",
      "gender_loss: 0.6941593289375305\n",
      "train_loss: 0.694159 | avg_loss: 0.692385 | gender_precise: 51.000000 (11299/21760) [170/186]\n",
      "gender_loss: 0.6934534907341003\n",
      "train_loss: 0.693453 | avg_loss: 0.692392 | gender_precise: 51.000000 (11364/21888) [171/186]\n",
      "gender_loss: 0.6859530210494995\n",
      "train_loss: 0.685953 | avg_loss: 0.692354 | gender_precise: 51.000000 (11439/22016) [172/186]\n",
      "gender_loss: 0.6911369562149048\n",
      "train_loss: 0.691137 | avg_loss: 0.692347 | gender_precise: 51.000000 (11507/22144) [173/186]\n",
      "gender_loss: 0.6835460662841797\n",
      "train_loss: 0.683546 | avg_loss: 0.692297 | gender_precise: 52.000000 (11585/22272) [174/186]\n",
      "gender_loss: 0.6887956857681274\n",
      "train_loss: 0.688796 | avg_loss: 0.692277 | gender_precise: 52.000000 (11656/22400) [175/186]\n",
      "gender_loss: 0.6887660026550293\n",
      "train_loss: 0.688766 | avg_loss: 0.692257 | gender_precise: 52.000000 (11727/22528) [176/186]\n",
      "gender_loss: 0.6935572028160095\n",
      "train_loss: 0.693557 | avg_loss: 0.692264 | gender_precise: 52.000000 (11792/22656) [177/186]\n",
      "gender_loss: 0.6967971324920654\n",
      "train_loss: 0.696797 | avg_loss: 0.692290 | gender_precise: 52.000000 (11853/22784) [178/186]\n",
      "gender_loss: 0.6853339076042175\n",
      "train_loss: 0.685334 | avg_loss: 0.692251 | gender_precise: 52.000000 (11928/22912) [179/186]\n",
      "gender_loss: 0.6969953775405884\n",
      "train_loss: 0.696995 | avg_loss: 0.692277 | gender_precise: 52.000000 (11989/23040) [180/186]\n",
      "gender_loss: 0.6867017149925232\n",
      "train_loss: 0.686702 | avg_loss: 0.692246 | gender_precise: 52.000000 (12062/23168) [181/186]\n",
      "gender_loss: 0.694474458694458\n",
      "train_loss: 0.694474 | avg_loss: 0.692259 | gender_precise: 52.000000 (12126/23296) [182/186]\n",
      "gender_loss: 0.6971619129180908\n",
      "train_loss: 0.697162 | avg_loss: 0.692285 | gender_precise: 52.000000 (12187/23424) [183/186]\n",
      "gender_loss: 0.6988753080368042\n",
      "train_loss: 0.698875 | avg_loss: 0.692321 | gender_precise: 51.000000 (12246/23552) [184/186]\n",
      "gender_loss: 0.6893579959869385\n",
      "train_loss: 0.689358 | avg_loss: 0.692305 | gender_precise: 52.000000 (12316/23680) [185/186]\n",
      "gender_loss: 0.6945289373397827\n",
      "train_loss: 0.694529 | avg_loss: 0.692317 | gender_precise: 52.000000 (12330/23708) [186/186]\n",
      "\n",
      "Test\n",
      "gender_prec: 72.000000 (93/128) [1/2]\n",
      "gender_prec: 71.000000 (96/134) [2/2]\n",
      "Saving..\n",
      "Number epoch: 1\n",
      "gender_loss: 0.6977877020835876\n",
      "train_loss: 0.697788 | avg_loss: 0.697788 | gender_precise: 46.000000 (60/128) [1/186]\n",
      "gender_loss: 0.6894693374633789\n",
      "train_loss: 0.689469 | avg_loss: 0.693629 | gender_precise: 50.000000 (130/256) [2/186]\n",
      "gender_loss: 0.6992571353912354\n",
      "train_loss: 0.699257 | avg_loss: 0.695505 | gender_precise: 48.000000 (188/384) [3/186]\n",
      "gender_loss: 0.6878709197044373\n",
      "train_loss: 0.687871 | avg_loss: 0.693596 | gender_precise: 50.000000 (260/512) [4/186]\n",
      "gender_loss: 0.6936848759651184\n",
      "train_loss: 0.693685 | avg_loss: 0.693614 | gender_precise: 50.000000 (325/640) [5/186]\n",
      "gender_loss: 0.6887977123260498\n",
      "train_loss: 0.688798 | avg_loss: 0.692811 | gender_precise: 51.000000 (396/768) [6/186]\n",
      "gender_loss: 0.6911337971687317\n",
      "train_loss: 0.691134 | avg_loss: 0.692572 | gender_precise: 51.000000 (464/896) [7/186]\n",
      "gender_loss: 0.6912754774093628\n",
      "train_loss: 0.691275 | avg_loss: 0.692410 | gender_precise: 51.000000 (532/1024) [8/186]\n",
      "gender_loss: 0.6872982978820801\n",
      "train_loss: 0.687298 | avg_loss: 0.691842 | gender_precise: 52.000000 (605/1152) [9/186]\n",
      "gender_loss: 0.6988011002540588\n",
      "train_loss: 0.698801 | avg_loss: 0.692538 | gender_precise: 51.000000 (663/1280) [10/186]\n",
      "gender_loss: 0.6924436688423157\n",
      "train_loss: 0.692444 | avg_loss: 0.692529 | gender_precise: 51.000000 (729/1408) [11/186]\n",
      "gender_loss: 0.688112735748291\n",
      "train_loss: 0.688113 | avg_loss: 0.692161 | gender_precise: 52.000000 (801/1536) [12/186]\n",
      "gender_loss: 0.6919190883636475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.691919 | avg_loss: 0.692142 | gender_precise: 52.000000 (868/1664) [13/186]\n",
      "gender_loss: 0.6894540190696716\n",
      "train_loss: 0.689454 | avg_loss: 0.691951 | gender_precise: 52.000000 (938/1792) [14/186]\n",
      "gender_loss: 0.684411883354187\n",
      "train_loss: 0.684412 | avg_loss: 0.691448 | gender_precise: 52.000000 (1015/1920) [15/186]\n",
      "gender_loss: 0.6873265504837036\n",
      "train_loss: 0.687327 | avg_loss: 0.691190 | gender_precise: 53.000000 (1088/2048) [16/186]\n",
      "gender_loss: 0.6839935779571533\n",
      "train_loss: 0.683994 | avg_loss: 0.690767 | gender_precise: 53.000000 (1165/2176) [17/186]\n",
      "gender_loss: 0.693673849105835\n",
      "train_loss: 0.693674 | avg_loss: 0.690928 | gender_precise: 53.000000 (1230/2304) [18/186]\n",
      "gender_loss: 0.6894683837890625\n",
      "train_loss: 0.689468 | avg_loss: 0.690852 | gender_precise: 53.000000 (1300/2432) [19/186]\n",
      "gender_loss: 0.6927663683891296\n",
      "train_loss: 0.692766 | avg_loss: 0.690947 | gender_precise: 53.000000 (1366/2560) [20/186]\n",
      "gender_loss: 0.693443775177002\n",
      "train_loss: 0.693444 | avg_loss: 0.691066 | gender_precise: 53.000000 (1431/2688) [21/186]\n",
      "gender_loss: 0.6902658939361572\n",
      "train_loss: 0.690266 | avg_loss: 0.691030 | gender_precise: 53.000000 (1500/2816) [22/186]\n",
      "gender_loss: 0.6884831190109253\n",
      "train_loss: 0.688483 | avg_loss: 0.690919 | gender_precise: 53.000000 (1571/2944) [23/186]\n",
      "gender_loss: 0.6822971105575562\n",
      "train_loss: 0.682297 | avg_loss: 0.690560 | gender_precise: 53.000000 (1649/3072) [24/186]\n",
      "gender_loss: 0.6946184635162354\n",
      "train_loss: 0.694618 | avg_loss: 0.690722 | gender_precise: 53.000000 (1713/3200) [25/186]\n",
      "gender_loss: 0.6992579698562622\n",
      "train_loss: 0.699258 | avg_loss: 0.691051 | gender_precise: 53.000000 (1772/3328) [26/186]\n",
      "gender_loss: 0.6900303363800049\n",
      "train_loss: 0.690030 | avg_loss: 0.691013 | gender_precise: 53.000000 (1841/3456) [27/186]\n",
      "gender_loss: 0.6918392777442932\n",
      "train_loss: 0.691839 | avg_loss: 0.691042 | gender_precise: 53.000000 (1908/3584) [28/186]\n",
      "gender_loss: 0.69285649061203\n",
      "train_loss: 0.692856 | avg_loss: 0.691105 | gender_precise: 53.000000 (1974/3712) [29/186]\n",
      "gender_loss: 0.6946805119514465\n",
      "train_loss: 0.694681 | avg_loss: 0.691224 | gender_precise: 53.000000 (2038/3840) [30/186]\n",
      "gender_loss: 0.6882075667381287\n",
      "train_loss: 0.688208 | avg_loss: 0.691127 | gender_precise: 53.000000 (2109/3968) [31/186]\n",
      "gender_loss: 0.6862106323242188\n",
      "train_loss: 0.686211 | avg_loss: 0.690973 | gender_precise: 53.000000 (2182/4096) [32/186]\n",
      "gender_loss: 0.691925048828125\n",
      "train_loss: 0.691925 | avg_loss: 0.691002 | gender_precise: 53.000000 (2249/4224) [33/186]\n",
      "gender_loss: 0.7042170763015747\n",
      "train_loss: 0.704217 | avg_loss: 0.691391 | gender_precise: 52.000000 (2303/4352) [34/186]\n",
      "gender_loss: 0.695554792881012\n",
      "train_loss: 0.695555 | avg_loss: 0.691510 | gender_precise: 52.000000 (2366/4480) [35/186]\n",
      "gender_loss: 0.6919504404067993\n",
      "train_loss: 0.691950 | avg_loss: 0.691522 | gender_precise: 52.000000 (2433/4608) [36/186]\n",
      "gender_loss: 0.6909240484237671\n",
      "train_loss: 0.690924 | avg_loss: 0.691506 | gender_precise: 52.000000 (2501/4736) [37/186]\n",
      "gender_loss: 0.6837115287780762\n",
      "train_loss: 0.683712 | avg_loss: 0.691301 | gender_precise: 52.000000 (2577/4864) [38/186]\n",
      "gender_loss: 0.6829853057861328\n",
      "train_loss: 0.682985 | avg_loss: 0.691087 | gender_precise: 53.000000 (2654/4992) [39/186]\n",
      "gender_loss: 0.6818774938583374\n",
      "train_loss: 0.681877 | avg_loss: 0.690857 | gender_precise: 53.000000 (2732/5120) [40/186]\n",
      "gender_loss: 0.6926488280296326\n",
      "train_loss: 0.692649 | avg_loss: 0.690901 | gender_precise: 53.000000 (2798/5248) [41/186]\n",
      "gender_loss: 0.7015113830566406\n",
      "train_loss: 0.701511 | avg_loss: 0.691153 | gender_precise: 53.000000 (2855/5376) [42/186]\n",
      "gender_loss: 0.6965697407722473\n",
      "train_loss: 0.696570 | avg_loss: 0.691279 | gender_precise: 52.000000 (2917/5504) [43/186]\n",
      "gender_loss: 0.690778374671936\n",
      "train_loss: 0.690778 | avg_loss: 0.691268 | gender_precise: 53.000000 (2985/5632) [44/186]\n",
      "gender_loss: 0.6797265410423279\n",
      "train_loss: 0.679727 | avg_loss: 0.691012 | gender_precise: 53.000000 (3065/5760) [45/186]\n",
      "gender_loss: 0.6948049068450928\n",
      "train_loss: 0.694805 | avg_loss: 0.691094 | gender_precise: 53.000000 (3129/5888) [46/186]\n",
      "gender_loss: 0.69771808385849\n",
      "train_loss: 0.697718 | avg_loss: 0.691235 | gender_precise: 53.000000 (3190/6016) [47/186]\n",
      "gender_loss: 0.6994253396987915\n",
      "train_loss: 0.699425 | avg_loss: 0.691406 | gender_precise: 52.000000 (3249/6144) [48/186]\n",
      "gender_loss: 0.7003109455108643\n",
      "train_loss: 0.700311 | avg_loss: 0.691587 | gender_precise: 52.000000 (3307/6272) [49/186]\n",
      "gender_loss: 0.6846678853034973\n",
      "train_loss: 0.684668 | avg_loss: 0.691449 | gender_precise: 52.000000 (3382/6400) [50/186]\n",
      "gender_loss: 0.6908988952636719\n",
      "train_loss: 0.690899 | avg_loss: 0.691438 | gender_precise: 52.000000 (3450/6528) [51/186]\n",
      "gender_loss: 0.6837121844291687\n",
      "train_loss: 0.683712 | avg_loss: 0.691290 | gender_precise: 52.000000 (3526/6656) [52/186]\n",
      "gender_loss: 0.6872227191925049\n",
      "train_loss: 0.687223 | avg_loss: 0.691213 | gender_precise: 53.000000 (3598/6784) [53/186]\n",
      "gender_loss: 0.6964235305786133\n",
      "train_loss: 0.696424 | avg_loss: 0.691309 | gender_precise: 52.000000 (3660/6912) [54/186]\n",
      "gender_loss: 0.6873379945755005\n",
      "train_loss: 0.687338 | avg_loss: 0.691237 | gender_precise: 53.000000 (3732/7040) [55/186]\n",
      "gender_loss: 0.6936035752296448\n",
      "train_loss: 0.693604 | avg_loss: 0.691279 | gender_precise: 52.000000 (3797/7168) [56/186]\n",
      "gender_loss: 0.6924724578857422\n",
      "train_loss: 0.692472 | avg_loss: 0.691300 | gender_precise: 52.000000 (3863/7296) [57/186]\n",
      "gender_loss: 0.6863397359848022\n",
      "train_loss: 0.686340 | avg_loss: 0.691215 | gender_precise: 53.000000 (3936/7424) [58/186]\n",
      "gender_loss: 0.6908339262008667\n",
      "train_loss: 0.690834 | avg_loss: 0.691208 | gender_precise: 53.000000 (4004/7552) [59/186]\n",
      "gender_loss: 0.6898582577705383\n",
      "train_loss: 0.689858 | avg_loss: 0.691186 | gender_precise: 53.000000 (4073/7680) [60/186]\n",
      "gender_loss: 0.682826817035675\n",
      "train_loss: 0.682827 | avg_loss: 0.691049 | gender_precise: 53.000000 (4150/7808) [61/186]\n",
      "gender_loss: 0.6980524659156799\n",
      "train_loss: 0.698052 | avg_loss: 0.691162 | gender_precise: 53.000000 (4210/7936) [62/186]\n",
      "gender_loss: 0.6935538649559021\n",
      "train_loss: 0.693554 | avg_loss: 0.691200 | gender_precise: 53.000000 (4275/8064) [63/186]\n",
      "gender_loss: 0.6963585615158081\n",
      "train_loss: 0.696359 | avg_loss: 0.691280 | gender_precise: 52.000000 (4337/8192) [64/186]\n",
      "gender_loss: 0.6899189352989197\n",
      "train_loss: 0.689919 | avg_loss: 0.691259 | gender_precise: 52.000000 (4406/8320) [65/186]\n",
      "gender_loss: 0.6908911466598511\n",
      "train_loss: 0.690891 | avg_loss: 0.691254 | gender_precise: 52.000000 (4474/8448) [66/186]\n",
      "gender_loss: 0.6942769289016724\n",
      "train_loss: 0.694277 | avg_loss: 0.691299 | gender_precise: 52.000000 (4538/8576) [67/186]\n",
      "gender_loss: 0.6908498406410217\n",
      "train_loss: 0.690850 | avg_loss: 0.691292 | gender_precise: 52.000000 (4606/8704) [68/186]\n",
      "gender_loss: 0.6917897462844849\n",
      "train_loss: 0.691790 | avg_loss: 0.691299 | gender_precise: 52.000000 (4673/8832) [69/186]\n",
      "gender_loss: 0.678135097026825\n",
      "train_loss: 0.678135 | avg_loss: 0.691111 | gender_precise: 53.000000 (4755/8960) [70/186]\n",
      "gender_loss: 0.6936987042427063\n",
      "train_loss: 0.693699 | avg_loss: 0.691148 | gender_precise: 53.000000 (4820/9088) [71/186]\n",
      "gender_loss: 0.6898824572563171\n",
      "train_loss: 0.689882 | avg_loss: 0.691130 | gender_precise: 53.000000 (4889/9216) [72/186]\n",
      "gender_loss: 0.7019349336624146\n",
      "train_loss: 0.701935 | avg_loss: 0.691278 | gender_precise: 52.000000 (4945/9344) [73/186]\n",
      "gender_loss: 0.6908584833145142\n",
      "train_loss: 0.690858 | avg_loss: 0.691273 | gender_precise: 52.000000 (5013/9472) [74/186]\n",
      "gender_loss: 0.692302942276001\n",
      "train_loss: 0.692303 | avg_loss: 0.691286 | gender_precise: 52.000000 (5079/9600) [75/186]\n",
      "gender_loss: 0.6864700317382812\n",
      "train_loss: 0.686470 | avg_loss: 0.691223 | gender_precise: 52.000000 (5152/9728) [76/186]\n",
      "gender_loss: 0.6972529888153076\n",
      "train_loss: 0.697253 | avg_loss: 0.691301 | gender_precise: 52.000000 (5213/9856) [77/186]\n",
      "gender_loss: 0.6934770941734314\n",
      "train_loss: 0.693477 | avg_loss: 0.691329 | gender_precise: 52.000000 (5278/9984) [78/186]\n",
      "gender_loss: 0.6914299726486206\n",
      "train_loss: 0.691430 | avg_loss: 0.691330 | gender_precise: 52.000000 (5345/10112) [79/186]\n",
      "gender_loss: 0.6828085780143738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.682809 | avg_loss: 0.691224 | gender_precise: 52.000000 (5422/10240) [80/186]\n",
      "gender_loss: 0.686247706413269\n",
      "train_loss: 0.686248 | avg_loss: 0.691163 | gender_precise: 52.000000 (5495/10368) [81/186]\n",
      "gender_loss: 0.6826953887939453\n",
      "train_loss: 0.682695 | avg_loss: 0.691059 | gender_precise: 53.000000 (5572/10496) [82/186]\n",
      "gender_loss: 0.6926846504211426\n",
      "train_loss: 0.692685 | avg_loss: 0.691079 | gender_precise: 53.000000 (5638/10624) [83/186]\n",
      "gender_loss: 0.6932688355445862\n",
      "train_loss: 0.693269 | avg_loss: 0.691105 | gender_precise: 53.000000 (5703/10752) [84/186]\n",
      "gender_loss: 0.6951802372932434\n",
      "train_loss: 0.695180 | avg_loss: 0.691153 | gender_precise: 52.000000 (5766/10880) [85/186]\n",
      "gender_loss: 0.6799356937408447\n",
      "train_loss: 0.679936 | avg_loss: 0.691022 | gender_precise: 53.000000 (5846/11008) [86/186]\n",
      "gender_loss: 0.6889631152153015\n",
      "train_loss: 0.688963 | avg_loss: 0.690999 | gender_precise: 53.000000 (5916/11136) [87/186]\n",
      "gender_loss: 0.6860582232475281\n",
      "train_loss: 0.686058 | avg_loss: 0.690943 | gender_precise: 53.000000 (5989/11264) [88/186]\n",
      "gender_loss: 0.6848858594894409\n",
      "train_loss: 0.684886 | avg_loss: 0.690875 | gender_precise: 53.000000 (6063/11392) [89/186]\n",
      "gender_loss: 0.6956198215484619\n",
      "train_loss: 0.695620 | avg_loss: 0.690927 | gender_precise: 53.000000 (6126/11520) [90/186]\n",
      "gender_loss: 0.6982443928718567\n",
      "train_loss: 0.698244 | avg_loss: 0.691008 | gender_precise: 53.000000 (6186/11648) [91/186]\n",
      "gender_loss: 0.6916231513023376\n",
      "train_loss: 0.691623 | avg_loss: 0.691014 | gender_precise: 53.000000 (6253/11776) [92/186]\n",
      "gender_loss: 0.685858964920044\n",
      "train_loss: 0.685859 | avg_loss: 0.690959 | gender_precise: 53.000000 (6326/11904) [93/186]\n",
      "gender_loss: 0.691881000995636\n",
      "train_loss: 0.691881 | avg_loss: 0.690969 | gender_precise: 53.000000 (6393/12032) [94/186]\n",
      "gender_loss: 0.6878454685211182\n",
      "train_loss: 0.687845 | avg_loss: 0.690936 | gender_precise: 53.000000 (6464/12160) [95/186]\n",
      "gender_loss: 0.6817046403884888\n",
      "train_loss: 0.681705 | avg_loss: 0.690840 | gender_precise: 53.000000 (6541/12288) [96/186]\n",
      "gender_loss: 0.6919131278991699\n",
      "train_loss: 0.691913 | avg_loss: 0.690851 | gender_precise: 53.000000 (6608/12416) [97/186]\n",
      "gender_loss: 0.688597559928894\n",
      "train_loss: 0.688598 | avg_loss: 0.690828 | gender_precise: 53.000000 (6678/12544) [98/186]\n",
      "gender_loss: 0.6985464692115784\n",
      "train_loss: 0.698546 | avg_loss: 0.690906 | gender_precise: 53.000000 (6738/12672) [99/186]\n",
      "gender_loss: 0.6903932690620422\n",
      "train_loss: 0.690393 | avg_loss: 0.690901 | gender_precise: 53.000000 (6806/12800) [100/186]\n",
      "gender_loss: 0.6909148693084717\n",
      "train_loss: 0.690915 | avg_loss: 0.690901 | gender_precise: 53.000000 (6874/12928) [101/186]\n",
      "gender_loss: 0.6961445212364197\n",
      "train_loss: 0.696145 | avg_loss: 0.690952 | gender_precise: 53.000000 (6937/13056) [102/186]\n",
      "gender_loss: 0.6962636113166809\n",
      "train_loss: 0.696264 | avg_loss: 0.691004 | gender_precise: 53.000000 (7000/13184) [103/186]\n",
      "gender_loss: 0.6916431188583374\n",
      "train_loss: 0.691643 | avg_loss: 0.691010 | gender_precise: 53.000000 (7067/13312) [104/186]\n",
      "gender_loss: 0.6923969388008118\n",
      "train_loss: 0.692397 | avg_loss: 0.691023 | gender_precise: 53.000000 (7133/13440) [105/186]\n",
      "gender_loss: 0.6825463771820068\n",
      "train_loss: 0.682546 | avg_loss: 0.690943 | gender_precise: 53.000000 (7209/13568) [106/186]\n",
      "gender_loss: 0.6830668449401855\n",
      "train_loss: 0.683067 | avg_loss: 0.690870 | gender_precise: 53.000000 (7284/13696) [107/186]\n",
      "gender_loss: 0.6919207572937012\n",
      "train_loss: 0.691921 | avg_loss: 0.690879 | gender_precise: 53.000000 (7351/13824) [108/186]\n",
      "gender_loss: 0.6886260509490967\n",
      "train_loss: 0.688626 | avg_loss: 0.690859 | gender_precise: 53.000000 (7421/13952) [109/186]\n",
      "gender_loss: 0.7012642025947571\n",
      "train_loss: 0.701264 | avg_loss: 0.690953 | gender_precise: 53.000000 (7479/14080) [110/186]\n",
      "gender_loss: 0.6875758171081543\n",
      "train_loss: 0.687576 | avg_loss: 0.690923 | gender_precise: 53.000000 (7550/14208) [111/186]\n",
      "gender_loss: 0.6907922625541687\n",
      "train_loss: 0.690792 | avg_loss: 0.690922 | gender_precise: 53.000000 (7618/14336) [112/186]\n",
      "gender_loss: 0.6925808787345886\n",
      "train_loss: 0.692581 | avg_loss: 0.690936 | gender_precise: 53.000000 (7684/14464) [113/186]\n",
      "gender_loss: 0.6963930726051331\n",
      "train_loss: 0.696393 | avg_loss: 0.690984 | gender_precise: 53.000000 (7746/14592) [114/186]\n",
      "gender_loss: 0.6865608096122742\n",
      "train_loss: 0.686561 | avg_loss: 0.690946 | gender_precise: 53.000000 (7818/14720) [115/186]\n",
      "gender_loss: 0.6886498332023621\n",
      "train_loss: 0.688650 | avg_loss: 0.690926 | gender_precise: 53.000000 (7888/14848) [116/186]\n",
      "gender_loss: 0.6992626190185547\n",
      "train_loss: 0.699263 | avg_loss: 0.690997 | gender_precise: 53.000000 (7948/14976) [117/186]\n",
      "gender_loss: 0.6941869854927063\n",
      "train_loss: 0.694187 | avg_loss: 0.691024 | gender_precise: 53.000000 (8012/15104) [118/186]\n",
      "gender_loss: 0.699103057384491\n",
      "train_loss: 0.699103 | avg_loss: 0.691092 | gender_precise: 52.000000 (8071/15232) [119/186]\n",
      "gender_loss: 0.6890931129455566\n",
      "train_loss: 0.689093 | avg_loss: 0.691076 | gender_precise: 52.000000 (8140/15360) [120/186]\n",
      "gender_loss: 0.6918145418167114\n",
      "train_loss: 0.691815 | avg_loss: 0.691082 | gender_precise: 52.000000 (8206/15488) [121/186]\n",
      "gender_loss: 0.6954090595245361\n",
      "train_loss: 0.695409 | avg_loss: 0.691117 | gender_precise: 52.000000 (8269/15616) [122/186]\n",
      "gender_loss: 0.6925680041313171\n",
      "train_loss: 0.692568 | avg_loss: 0.691129 | gender_precise: 52.000000 (8335/15744) [123/186]\n",
      "gender_loss: 0.6878700256347656\n",
      "train_loss: 0.687870 | avg_loss: 0.691103 | gender_precise: 52.000000 (8406/15872) [124/186]\n",
      "gender_loss: 0.6995830535888672\n",
      "train_loss: 0.699583 | avg_loss: 0.691171 | gender_precise: 52.000000 (8464/16000) [125/186]\n",
      "gender_loss: 0.6872839331626892\n",
      "train_loss: 0.687284 | avg_loss: 0.691140 | gender_precise: 52.000000 (8535/16128) [126/186]\n",
      "gender_loss: 0.6887999773025513\n",
      "train_loss: 0.688800 | avg_loss: 0.691121 | gender_precise: 52.000000 (8605/16256) [127/186]\n",
      "gender_loss: 0.6930550932884216\n",
      "train_loss: 0.693055 | avg_loss: 0.691136 | gender_precise: 52.000000 (8670/16384) [128/186]\n",
      "gender_loss: 0.6900270581245422\n",
      "train_loss: 0.690027 | avg_loss: 0.691128 | gender_precise: 52.000000 (8739/16512) [129/186]\n",
      "gender_loss: 0.6936261057853699\n",
      "train_loss: 0.693626 | avg_loss: 0.691147 | gender_precise: 52.000000 (8803/16640) [130/186]\n",
      "gender_loss: 0.6892644166946411\n",
      "train_loss: 0.689264 | avg_loss: 0.691133 | gender_precise: 52.000000 (8872/16768) [131/186]\n",
      "gender_loss: 0.6868472099304199\n",
      "train_loss: 0.686847 | avg_loss: 0.691100 | gender_precise: 52.000000 (8944/16896) [132/186]\n",
      "gender_loss: 0.6882665157318115\n",
      "train_loss: 0.688267 | avg_loss: 0.691079 | gender_precise: 52.000000 (9015/17024) [133/186]\n",
      "gender_loss: 0.6968647241592407\n",
      "train_loss: 0.696865 | avg_loss: 0.691122 | gender_precise: 52.000000 (9075/17152) [134/186]\n",
      "gender_loss: 0.693659245967865\n",
      "train_loss: 0.693659 | avg_loss: 0.691141 | gender_precise: 52.000000 (9139/17280) [135/186]\n",
      "gender_loss: 0.6978112459182739\n",
      "train_loss: 0.697811 | avg_loss: 0.691190 | gender_precise: 52.000000 (9197/17408) [136/186]\n",
      "gender_loss: 0.6909196972846985\n",
      "train_loss: 0.690920 | avg_loss: 0.691188 | gender_precise: 52.000000 (9264/17536) [137/186]\n",
      "gender_loss: 0.6929203867912292\n",
      "train_loss: 0.692920 | avg_loss: 0.691200 | gender_precise: 52.000000 (9328/17664) [138/186]\n",
      "gender_loss: 0.691199779510498\n",
      "train_loss: 0.691200 | avg_loss: 0.691200 | gender_precise: 52.000000 (9394/17792) [139/186]\n",
      "gender_loss: 0.6927735209465027\n",
      "train_loss: 0.692774 | avg_loss: 0.691212 | gender_precise: 52.000000 (9459/17920) [140/186]\n",
      "gender_loss: 0.6922417283058167\n",
      "train_loss: 0.692242 | avg_loss: 0.691219 | gender_precise: 52.000000 (9523/18048) [141/186]\n",
      "gender_loss: 0.6898573637008667\n",
      "train_loss: 0.689857 | avg_loss: 0.691209 | gender_precise: 52.000000 (9591/18176) [142/186]\n",
      "gender_loss: 0.6903499364852905\n",
      "train_loss: 0.690350 | avg_loss: 0.691203 | gender_precise: 52.000000 (9659/18304) [143/186]\n",
      "gender_loss: 0.69413822889328\n",
      "train_loss: 0.694138 | avg_loss: 0.691224 | gender_precise: 52.000000 (9721/18432) [144/186]\n",
      "gender_loss: 0.6896570920944214\n",
      "train_loss: 0.689657 | avg_loss: 0.691213 | gender_precise: 52.000000 (9789/18560) [145/186]\n",
      "gender_loss: 0.6859684586524963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.685968 | avg_loss: 0.691177 | gender_precise: 52.000000 (9864/18688) [146/186]\n",
      "gender_loss: 0.6893224716186523\n",
      "train_loss: 0.689322 | avg_loss: 0.691164 | gender_precise: 52.000000 (9933/18816) [147/186]\n",
      "gender_loss: 0.6908865571022034\n",
      "train_loss: 0.690887 | avg_loss: 0.691162 | gender_precise: 52.000000 (10000/18944) [148/186]\n",
      "gender_loss: 0.6979867815971375\n",
      "train_loss: 0.697987 | avg_loss: 0.691208 | gender_precise: 52.000000 (10055/19072) [149/186]\n",
      "gender_loss: 0.6931210160255432\n",
      "train_loss: 0.693121 | avg_loss: 0.691221 | gender_precise: 52.000000 (10118/19200) [150/186]\n",
      "gender_loss: 0.6950445175170898\n",
      "train_loss: 0.695045 | avg_loss: 0.691246 | gender_precise: 52.000000 (10177/19328) [151/186]\n",
      "gender_loss: 0.6912137269973755\n",
      "train_loss: 0.691214 | avg_loss: 0.691246 | gender_precise: 52.000000 (10242/19456) [152/186]\n",
      "gender_loss: 0.6963440775871277\n",
      "train_loss: 0.696344 | avg_loss: 0.691279 | gender_precise: 52.000000 (10300/19584) [153/186]\n",
      "gender_loss: 0.6872273683547974\n",
      "train_loss: 0.687227 | avg_loss: 0.691253 | gender_precise: 52.000000 (10373/19712) [154/186]\n",
      "gender_loss: 0.689001739025116\n",
      "train_loss: 0.689002 | avg_loss: 0.691239 | gender_precise: 52.000000 (10442/19840) [155/186]\n",
      "gender_loss: 0.691332995891571\n",
      "train_loss: 0.691333 | avg_loss: 0.691239 | gender_precise: 52.000000 (10510/19968) [156/186]\n",
      "gender_loss: 0.6891564726829529\n",
      "train_loss: 0.689156 | avg_loss: 0.691226 | gender_precise: 52.000000 (10579/20096) [157/186]\n",
      "gender_loss: 0.6926472187042236\n",
      "train_loss: 0.692647 | avg_loss: 0.691235 | gender_precise: 52.000000 (10639/20224) [158/186]\n",
      "gender_loss: 0.689956784248352\n",
      "train_loss: 0.689957 | avg_loss: 0.691227 | gender_precise: 52.000000 (10707/20352) [159/186]\n",
      "gender_loss: 0.6944899559020996\n",
      "train_loss: 0.694490 | avg_loss: 0.691247 | gender_precise: 52.000000 (10767/20480) [160/186]\n",
      "gender_loss: 0.6917433142662048\n",
      "train_loss: 0.691743 | avg_loss: 0.691250 | gender_precise: 52.000000 (10832/20608) [161/186]\n",
      "gender_loss: 0.6931045651435852\n",
      "train_loss: 0.693105 | avg_loss: 0.691262 | gender_precise: 52.000000 (10894/20736) [162/186]\n",
      "gender_loss: 0.6947882175445557\n",
      "train_loss: 0.694788 | avg_loss: 0.691283 | gender_precise: 52.000000 (10949/20864) [163/186]\n",
      "gender_loss: 0.6900787353515625\n",
      "train_loss: 0.690079 | avg_loss: 0.691276 | gender_precise: 52.000000 (11015/20992) [164/186]\n",
      "gender_loss: 0.6899712681770325\n",
      "train_loss: 0.689971 | avg_loss: 0.691268 | gender_precise: 52.000000 (11082/21120) [165/186]\n",
      "gender_loss: 0.6884194612503052\n",
      "train_loss: 0.688419 | avg_loss: 0.691251 | gender_precise: 52.000000 (11156/21248) [166/186]\n",
      "gender_loss: 0.6889324188232422\n",
      "train_loss: 0.688932 | avg_loss: 0.691237 | gender_precise: 52.000000 (11226/21376) [167/186]\n",
      "gender_loss: 0.6898306608200073\n",
      "train_loss: 0.689831 | avg_loss: 0.691229 | gender_precise: 52.000000 (11292/21504) [168/186]\n",
      "gender_loss: 0.6922156810760498\n",
      "train_loss: 0.692216 | avg_loss: 0.691235 | gender_precise: 52.000000 (11352/21632) [169/186]\n",
      "gender_loss: 0.6883189082145691\n",
      "train_loss: 0.688319 | avg_loss: 0.691217 | gender_precise: 52.000000 (11421/21760) [170/186]\n",
      "gender_loss: 0.6929729580879211\n",
      "train_loss: 0.692973 | avg_loss: 0.691228 | gender_precise: 52.000000 (11483/21888) [171/186]\n",
      "gender_loss: 0.6943699717521667\n",
      "train_loss: 0.694370 | avg_loss: 0.691246 | gender_precise: 52.000000 (11538/22016) [172/186]\n",
      "gender_loss: 0.6895791292190552\n",
      "train_loss: 0.689579 | avg_loss: 0.691236 | gender_precise: 52.000000 (11608/22144) [173/186]\n",
      "gender_loss: 0.6905544996261597\n",
      "train_loss: 0.690554 | avg_loss: 0.691232 | gender_precise: 52.000000 (11670/22272) [174/186]\n",
      "gender_loss: 0.6896349787712097\n",
      "train_loss: 0.689635 | avg_loss: 0.691223 | gender_precise: 52.000000 (11739/22400) [175/186]\n",
      "gender_loss: 0.6918461918830872\n",
      "train_loss: 0.691846 | avg_loss: 0.691227 | gender_precise: 52.000000 (11807/22528) [176/186]\n",
      "gender_loss: 0.6899198889732361\n",
      "train_loss: 0.689920 | avg_loss: 0.691220 | gender_precise: 52.000000 (11879/22656) [177/186]\n",
      "gender_loss: 0.6900296807289124\n",
      "train_loss: 0.690030 | avg_loss: 0.691213 | gender_precise: 52.000000 (11955/22784) [178/186]\n",
      "gender_loss: 0.6915424466133118\n",
      "train_loss: 0.691542 | avg_loss: 0.691215 | gender_precise: 52.000000 (12027/22912) [179/186]\n",
      "gender_loss: 0.6900244355201721\n",
      "train_loss: 0.690024 | avg_loss: 0.691208 | gender_precise: 52.000000 (12100/23040) [180/186]\n",
      "gender_loss: 0.6930293440818787\n",
      "train_loss: 0.693029 | avg_loss: 0.691218 | gender_precise: 52.000000 (12167/23168) [181/186]\n",
      "gender_loss: 0.6884427070617676\n",
      "train_loss: 0.688443 | avg_loss: 0.691203 | gender_precise: 52.000000 (12237/23296) [182/186]\n",
      "gender_loss: 0.6893596649169922\n",
      "train_loss: 0.689360 | avg_loss: 0.691193 | gender_precise: 52.000000 (12309/23424) [183/186]\n",
      "gender_loss: 0.6880949139595032\n",
      "train_loss: 0.688095 | avg_loss: 0.691176 | gender_precise: 52.000000 (12389/23552) [184/186]\n",
      "gender_loss: 0.6877090930938721\n",
      "train_loss: 0.687709 | avg_loss: 0.691157 | gender_precise: 52.000000 (12471/23680) [185/186]\n",
      "gender_loss: 0.6862688660621643\n",
      "train_loss: 0.686269 | avg_loss: 0.691131 | gender_precise: 52.000000 (12490/23708) [186/186]\n",
      "\n",
      "Test\n",
      "gender_prec: 67.000000 (87/128) [1/2]\n",
      "gender_prec: 66.000000 (89/134) [2/2]\n",
      "Number epoch: 2\n",
      "gender_loss: 0.6906821727752686\n",
      "train_loss: 0.690682 | avg_loss: 0.690682 | gender_precise: 56.000000 (72/128) [1/186]\n",
      "gender_loss: 0.6888383626937866\n",
      "train_loss: 0.688838 | avg_loss: 0.689760 | gender_precise: 60.000000 (154/256) [2/186]\n",
      "gender_loss: 0.6895773410797119\n",
      "train_loss: 0.689577 | avg_loss: 0.689699 | gender_precise: 58.000000 (226/384) [3/186]\n",
      "gender_loss: 0.6878302693367004\n",
      "train_loss: 0.687830 | avg_loss: 0.689232 | gender_precise: 60.000000 (308/512) [4/186]\n",
      "gender_loss: 0.6877891421318054\n",
      "train_loss: 0.687789 | avg_loss: 0.688944 | gender_precise: 61.000000 (392/640) [5/186]\n",
      "gender_loss: 0.6868157982826233\n",
      "train_loss: 0.686816 | avg_loss: 0.688589 | gender_precise: 61.000000 (473/768) [6/186]\n",
      "gender_loss: 0.6872316598892212\n",
      "train_loss: 0.687232 | avg_loss: 0.688395 | gender_precise: 61.000000 (555/896) [7/186]\n",
      "gender_loss: 0.6900621652603149\n",
      "train_loss: 0.690062 | avg_loss: 0.688603 | gender_precise: 61.000000 (628/1024) [8/186]\n",
      "gender_loss: 0.6916945576667786\n",
      "train_loss: 0.691695 | avg_loss: 0.688947 | gender_precise: 60.000000 (698/1152) [9/186]\n",
      "gender_loss: 0.6859962344169617\n",
      "train_loss: 0.685996 | avg_loss: 0.688652 | gender_precise: 61.000000 (784/1280) [10/186]\n",
      "gender_loss: 0.6916660666465759\n",
      "train_loss: 0.691666 | avg_loss: 0.688926 | gender_precise: 60.000000 (852/1408) [11/186]\n",
      "gender_loss: 0.6890350580215454\n",
      "train_loss: 0.689035 | avg_loss: 0.688935 | gender_precise: 60.000000 (927/1536) [12/186]\n",
      "gender_loss: 0.686147153377533\n",
      "train_loss: 0.686147 | avg_loss: 0.688720 | gender_precise: 60.000000 (1011/1664) [13/186]\n",
      "gender_loss: 0.6892584562301636\n",
      "train_loss: 0.689258 | avg_loss: 0.688759 | gender_precise: 60.000000 (1084/1792) [14/186]\n",
      "gender_loss: 0.6898660659790039\n",
      "train_loss: 0.689866 | avg_loss: 0.688833 | gender_precise: 60.000000 (1159/1920) [15/186]\n",
      "gender_loss: 0.6862131357192993\n",
      "train_loss: 0.686213 | avg_loss: 0.688669 | gender_precise: 60.000000 (1238/2048) [16/186]\n",
      "gender_loss: 0.6883441209793091\n",
      "train_loss: 0.688344 | avg_loss: 0.688650 | gender_precise: 60.000000 (1318/2176) [17/186]\n",
      "gender_loss: 0.686442494392395\n",
      "train_loss: 0.686442 | avg_loss: 0.688527 | gender_precise: 60.000000 (1400/2304) [18/186]\n",
      "gender_loss: 0.6831042766571045\n",
      "train_loss: 0.683104 | avg_loss: 0.688242 | gender_precise: 61.000000 (1486/2432) [19/186]\n",
      "gender_loss: 0.6889224648475647\n",
      "train_loss: 0.688922 | avg_loss: 0.688276 | gender_precise: 61.000000 (1563/2560) [20/186]\n",
      "gender_loss: 0.6830721497535706\n",
      "train_loss: 0.683072 | avg_loss: 0.688028 | gender_precise: 61.000000 (1648/2688) [21/186]\n",
      "gender_loss: 0.6869175434112549\n",
      "train_loss: 0.686918 | avg_loss: 0.687978 | gender_precise: 61.000000 (1721/2816) [22/186]\n",
      "gender_loss: 0.6882540583610535\n",
      "train_loss: 0.688254 | avg_loss: 0.687990 | gender_precise: 60.000000 (1793/2944) [23/186]\n",
      "gender_loss: 0.684036910533905\n",
      "train_loss: 0.684037 | avg_loss: 0.687825 | gender_precise: 60.000000 (1871/3072) [24/186]\n",
      "gender_loss: 0.6822863817214966\n",
      "train_loss: 0.682286 | avg_loss: 0.687603 | gender_precise: 60.000000 (1948/3200) [25/186]\n",
      "gender_loss: 0.6896753907203674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.689675 | avg_loss: 0.687683 | gender_precise: 60.000000 (2015/3328) [26/186]\n",
      "gender_loss: 0.6835059523582458\n",
      "train_loss: 0.683506 | avg_loss: 0.687528 | gender_precise: 60.000000 (2090/3456) [27/186]\n",
      "gender_loss: 0.6833314895629883\n",
      "train_loss: 0.683331 | avg_loss: 0.687379 | gender_precise: 60.000000 (2164/3584) [28/186]\n",
      "gender_loss: 0.6872897744178772\n",
      "train_loss: 0.687290 | avg_loss: 0.687375 | gender_precise: 60.000000 (2235/3712) [29/186]\n",
      "gender_loss: 0.6788393259048462\n",
      "train_loss: 0.678839 | avg_loss: 0.687091 | gender_precise: 60.000000 (2319/3840) [30/186]\n",
      "gender_loss: 0.6916712522506714\n",
      "train_loss: 0.691671 | avg_loss: 0.687239 | gender_precise: 60.000000 (2387/3968) [31/186]\n",
      "gender_loss: 0.6816034317016602\n",
      "train_loss: 0.681603 | avg_loss: 0.687063 | gender_precise: 60.000000 (2461/4096) [32/186]\n",
      "gender_loss: 0.6876484155654907\n",
      "train_loss: 0.687648 | avg_loss: 0.687080 | gender_precise: 60.000000 (2538/4224) [33/186]\n",
      "gender_loss: 0.6844367384910583\n",
      "train_loss: 0.684437 | avg_loss: 0.687003 | gender_precise: 60.000000 (2614/4352) [34/186]\n",
      "gender_loss: 0.682410478591919\n",
      "train_loss: 0.682410 | avg_loss: 0.686871 | gender_precise: 60.000000 (2691/4480) [35/186]\n",
      "gender_loss: 0.6812569499015808\n",
      "train_loss: 0.681257 | avg_loss: 0.686715 | gender_precise: 60.000000 (2772/4608) [36/186]\n",
      "gender_loss: 0.6782944202423096\n",
      "train_loss: 0.678294 | avg_loss: 0.686488 | gender_precise: 60.000000 (2853/4736) [37/186]\n",
      "gender_loss: 0.6806862354278564\n",
      "train_loss: 0.680686 | avg_loss: 0.686335 | gender_precise: 60.000000 (2931/4864) [38/186]\n",
      "gender_loss: 0.6803567409515381\n",
      "train_loss: 0.680357 | avg_loss: 0.686182 | gender_precise: 60.000000 (3012/4992) [39/186]\n",
      "gender_loss: 0.6828256845474243\n",
      "train_loss: 0.682826 | avg_loss: 0.686098 | gender_precise: 60.000000 (3091/5120) [40/186]\n",
      "gender_loss: 0.6809026002883911\n",
      "train_loss: 0.680903 | avg_loss: 0.685971 | gender_precise: 60.000000 (3170/5248) [41/186]\n",
      "gender_loss: 0.6800780892372131\n",
      "train_loss: 0.680078 | avg_loss: 0.685831 | gender_precise: 60.000000 (3248/5376) [42/186]\n",
      "gender_loss: 0.6759259700775146\n",
      "train_loss: 0.675926 | avg_loss: 0.685601 | gender_precise: 60.000000 (3328/5504) [43/186]\n",
      "gender_loss: 0.6712853908538818\n",
      "train_loss: 0.671285 | avg_loss: 0.685275 | gender_precise: 60.000000 (3414/5632) [44/186]\n",
      "gender_loss: 0.6756746768951416\n",
      "train_loss: 0.675675 | avg_loss: 0.685062 | gender_precise: 60.000000 (3498/5760) [45/186]\n",
      "gender_loss: 0.6740869879722595\n",
      "train_loss: 0.674087 | avg_loss: 0.684823 | gender_precise: 60.000000 (3579/5888) [46/186]\n",
      "gender_loss: 0.6816751956939697\n",
      "train_loss: 0.681675 | avg_loss: 0.684756 | gender_precise: 60.000000 (3655/6016) [47/186]\n",
      "gender_loss: 0.6907488703727722\n",
      "train_loss: 0.690749 | avg_loss: 0.684881 | gender_precise: 60.000000 (3724/6144) [48/186]\n",
      "gender_loss: 0.6761859655380249\n",
      "train_loss: 0.676186 | avg_loss: 0.684704 | gender_precise: 60.000000 (3803/6272) [49/186]\n",
      "gender_loss: 0.6760565042495728\n",
      "train_loss: 0.676057 | avg_loss: 0.684531 | gender_precise: 60.000000 (3880/6400) [50/186]\n",
      "gender_loss: 0.6880611181259155\n",
      "train_loss: 0.688061 | avg_loss: 0.684600 | gender_precise: 60.000000 (3946/6528) [51/186]\n",
      "gender_loss: 0.670923113822937\n",
      "train_loss: 0.670923 | avg_loss: 0.684337 | gender_precise: 60.000000 (4018/6656) [52/186]\n",
      "gender_loss: 0.6802033185958862\n",
      "train_loss: 0.680203 | avg_loss: 0.684259 | gender_precise: 60.000000 (4093/6784) [53/186]\n",
      "gender_loss: 0.6754370927810669\n",
      "train_loss: 0.675437 | avg_loss: 0.684096 | gender_precise: 60.000000 (4171/6912) [54/186]\n",
      "gender_loss: 0.6811172366142273\n",
      "train_loss: 0.681117 | avg_loss: 0.684041 | gender_precise: 60.000000 (4251/7040) [55/186]\n",
      "gender_loss: 0.6736344695091248\n",
      "train_loss: 0.673634 | avg_loss: 0.683856 | gender_precise: 60.000000 (4330/7168) [56/186]\n",
      "gender_loss: 0.6654602885246277\n",
      "train_loss: 0.665460 | avg_loss: 0.683533 | gender_precise: 60.000000 (4410/7296) [57/186]\n",
      "gender_loss: 0.6710498332977295\n",
      "train_loss: 0.671050 | avg_loss: 0.683318 | gender_precise: 60.000000 (4486/7424) [58/186]\n",
      "gender_loss: 0.6553561687469482\n",
      "train_loss: 0.655356 | avg_loss: 0.682844 | gender_precise: 60.000000 (4576/7552) [59/186]\n",
      "gender_loss: 0.6672555804252625\n",
      "train_loss: 0.667256 | avg_loss: 0.682584 | gender_precise: 60.000000 (4657/7680) [60/186]\n",
      "gender_loss: 0.6584056615829468\n",
      "train_loss: 0.658406 | avg_loss: 0.682187 | gender_precise: 60.000000 (4737/7808) [61/186]\n",
      "gender_loss: 0.6725984215736389\n",
      "train_loss: 0.672598 | avg_loss: 0.682033 | gender_precise: 60.000000 (4818/7936) [62/186]\n",
      "gender_loss: 0.6763618588447571\n",
      "train_loss: 0.676362 | avg_loss: 0.681943 | gender_precise: 60.000000 (4890/8064) [63/186]\n",
      "gender_loss: 0.6726943850517273\n",
      "train_loss: 0.672694 | avg_loss: 0.681798 | gender_precise: 60.000000 (4966/8192) [64/186]\n",
      "gender_loss: 0.6651833057403564\n",
      "train_loss: 0.665183 | avg_loss: 0.681543 | gender_precise: 60.000000 (5049/8320) [65/186]\n",
      "gender_loss: 0.6665273308753967\n",
      "train_loss: 0.666527 | avg_loss: 0.681315 | gender_precise: 60.000000 (5133/8448) [66/186]\n",
      "gender_loss: 0.67103111743927\n",
      "train_loss: 0.671031 | avg_loss: 0.681162 | gender_precise: 60.000000 (5217/8576) [67/186]\n",
      "gender_loss: 0.6531144380569458\n",
      "train_loss: 0.653114 | avg_loss: 0.680749 | gender_precise: 60.000000 (5306/8704) [68/186]\n",
      "gender_loss: 0.6605550646781921\n",
      "train_loss: 0.660555 | avg_loss: 0.680457 | gender_precise: 61.000000 (5388/8832) [69/186]\n",
      "gender_loss: 0.667087197303772\n",
      "train_loss: 0.667087 | avg_loss: 0.680266 | gender_precise: 61.000000 (5477/8960) [70/186]\n",
      "gender_loss: 0.6726129651069641\n",
      "train_loss: 0.672613 | avg_loss: 0.680158 | gender_precise: 61.000000 (5556/9088) [71/186]\n",
      "gender_loss: 0.6513074040412903\n",
      "train_loss: 0.651307 | avg_loss: 0.679757 | gender_precise: 61.000000 (5646/9216) [72/186]\n",
      "gender_loss: 0.6477534174919128\n",
      "train_loss: 0.647753 | avg_loss: 0.679319 | gender_precise: 61.000000 (5742/9344) [73/186]\n",
      "gender_loss: 0.6594284176826477\n",
      "train_loss: 0.659428 | avg_loss: 0.679050 | gender_precise: 61.000000 (5824/9472) [74/186]\n",
      "gender_loss: 0.6418906450271606\n",
      "train_loss: 0.641891 | avg_loss: 0.678555 | gender_precise: 61.000000 (5914/9600) [75/186]\n",
      "gender_loss: 0.6574357748031616\n",
      "train_loss: 0.657436 | avg_loss: 0.678277 | gender_precise: 61.000000 (5997/9728) [76/186]\n",
      "gender_loss: 0.6539504528045654\n",
      "train_loss: 0.653950 | avg_loss: 0.677961 | gender_precise: 61.000000 (6080/9856) [77/186]\n",
      "gender_loss: 0.664180338382721\n",
      "train_loss: 0.664180 | avg_loss: 0.677784 | gender_precise: 61.000000 (6164/9984) [78/186]\n",
      "gender_loss: 0.63931804895401\n",
      "train_loss: 0.639318 | avg_loss: 0.677297 | gender_precise: 61.000000 (6254/10112) [79/186]\n",
      "gender_loss: 0.6451135277748108\n",
      "train_loss: 0.645114 | avg_loss: 0.676895 | gender_precise: 61.000000 (6342/10240) [80/186]\n",
      "gender_loss: 0.634411633014679\n",
      "train_loss: 0.634412 | avg_loss: 0.676370 | gender_precise: 61.000000 (6427/10368) [81/186]\n",
      "gender_loss: 0.6780192255973816\n",
      "train_loss: 0.678019 | avg_loss: 0.676390 | gender_precise: 61.000000 (6501/10496) [82/186]\n",
      "gender_loss: 0.6331958174705505\n",
      "train_loss: 0.633196 | avg_loss: 0.675870 | gender_precise: 62.000000 (6590/10624) [83/186]\n",
      "gender_loss: 0.6084293723106384\n",
      "train_loss: 0.608429 | avg_loss: 0.675067 | gender_precise: 62.000000 (6688/10752) [84/186]\n",
      "gender_loss: 0.6288770437240601\n",
      "train_loss: 0.628877 | avg_loss: 0.674524 | gender_precise: 62.000000 (6772/10880) [85/186]\n",
      "gender_loss: 0.6450768709182739\n",
      "train_loss: 0.645077 | avg_loss: 0.674181 | gender_precise: 62.000000 (6860/11008) [86/186]\n",
      "gender_loss: 0.6374543309211731\n",
      "train_loss: 0.637454 | avg_loss: 0.673759 | gender_precise: 62.000000 (6942/11136) [87/186]\n",
      "gender_loss: 0.6047659516334534\n",
      "train_loss: 0.604766 | avg_loss: 0.672975 | gender_precise: 62.000000 (7031/11264) [88/186]\n",
      "gender_loss: 0.6376335620880127\n",
      "train_loss: 0.637634 | avg_loss: 0.672578 | gender_precise: 62.000000 (7109/11392) [89/186]\n",
      "gender_loss: 0.6178040504455566\n",
      "train_loss: 0.617804 | avg_loss: 0.671970 | gender_precise: 62.000000 (7196/11520) [90/186]\n",
      "gender_loss: 0.6244564056396484\n",
      "train_loss: 0.624456 | avg_loss: 0.671447 | gender_precise: 62.000000 (7282/11648) [91/186]\n",
      "gender_loss: 0.6265214085578918\n",
      "train_loss: 0.626521 | avg_loss: 0.670959 | gender_precise: 62.000000 (7366/11776) [92/186]\n",
      "gender_loss: 0.6037329435348511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.603733 | avg_loss: 0.670236 | gender_precise: 62.000000 (7456/11904) [93/186]\n",
      "gender_loss: 0.6167487502098083\n",
      "train_loss: 0.616749 | avg_loss: 0.669667 | gender_precise: 62.000000 (7550/12032) [94/186]\n",
      "gender_loss: 0.6434347629547119\n",
      "train_loss: 0.643435 | avg_loss: 0.669391 | gender_precise: 62.000000 (7632/12160) [95/186]\n",
      "gender_loss: 0.624903678894043\n",
      "train_loss: 0.624904 | avg_loss: 0.668928 | gender_precise: 62.000000 (7722/12288) [96/186]\n",
      "gender_loss: 0.5962358713150024\n",
      "train_loss: 0.596236 | avg_loss: 0.668178 | gender_precise: 62.000000 (7818/12416) [97/186]\n",
      "gender_loss: 0.6144238114356995\n",
      "train_loss: 0.614424 | avg_loss: 0.667630 | gender_precise: 63.000000 (7905/12544) [98/186]\n",
      "gender_loss: 0.6244215965270996\n",
      "train_loss: 0.624422 | avg_loss: 0.667193 | gender_precise: 63.000000 (7989/12672) [99/186]\n",
      "gender_loss: 0.5553866028785706\n",
      "train_loss: 0.555387 | avg_loss: 0.666075 | gender_precise: 63.000000 (8089/12800) [100/186]\n",
      "gender_loss: 0.6009172797203064\n",
      "train_loss: 0.600917 | avg_loss: 0.665430 | gender_precise: 63.000000 (8181/12928) [101/186]\n",
      "gender_loss: 0.579444169998169\n",
      "train_loss: 0.579444 | avg_loss: 0.664587 | gender_precise: 63.000000 (8272/13056) [102/186]\n",
      "gender_loss: 0.5670957565307617\n",
      "train_loss: 0.567096 | avg_loss: 0.663641 | gender_precise: 63.000000 (8368/13184) [103/186]\n",
      "gender_loss: 0.5481047034263611\n",
      "train_loss: 0.548105 | avg_loss: 0.662530 | gender_precise: 63.000000 (8465/13312) [104/186]\n",
      "gender_loss: 0.5410898327827454\n",
      "train_loss: 0.541090 | avg_loss: 0.661373 | gender_precise: 63.000000 (8567/13440) [105/186]\n",
      "gender_loss: 0.5385157465934753\n",
      "train_loss: 0.538516 | avg_loss: 0.660214 | gender_precise: 63.000000 (8665/13568) [106/186]\n",
      "gender_loss: 0.5629931092262268\n",
      "train_loss: 0.562993 | avg_loss: 0.659305 | gender_precise: 63.000000 (8756/13696) [107/186]\n",
      "gender_loss: 0.5524165630340576\n",
      "train_loss: 0.552417 | avg_loss: 0.658316 | gender_precise: 64.000000 (8852/13824) [108/186]\n",
      "gender_loss: 0.5442126393318176\n",
      "train_loss: 0.544213 | avg_loss: 0.657269 | gender_precise: 64.000000 (8945/13952) [109/186]\n",
      "gender_loss: 0.5878554582595825\n",
      "train_loss: 0.587855 | avg_loss: 0.656638 | gender_precise: 64.000000 (9034/14080) [110/186]\n",
      "gender_loss: 0.5391363501548767\n",
      "train_loss: 0.539136 | avg_loss: 0.655579 | gender_precise: 64.000000 (9136/14208) [111/186]\n",
      "gender_loss: 0.525215744972229\n",
      "train_loss: 0.525216 | avg_loss: 0.654415 | gender_precise: 64.000000 (9230/14336) [112/186]\n",
      "gender_loss: 0.5607932209968567\n",
      "train_loss: 0.560793 | avg_loss: 0.653587 | gender_precise: 64.000000 (9325/14464) [113/186]\n",
      "gender_loss: 0.6060155034065247\n",
      "train_loss: 0.606016 | avg_loss: 0.653170 | gender_precise: 64.000000 (9413/14592) [114/186]\n",
      "gender_loss: 0.6168820858001709\n",
      "train_loss: 0.616882 | avg_loss: 0.652854 | gender_precise: 64.000000 (9496/14720) [115/186]\n",
      "gender_loss: 0.6159706115722656\n",
      "train_loss: 0.615971 | avg_loss: 0.652536 | gender_precise: 64.000000 (9582/14848) [116/186]\n",
      "gender_loss: 0.535399854183197\n",
      "train_loss: 0.535400 | avg_loss: 0.651535 | gender_precise: 64.000000 (9679/14976) [117/186]\n",
      "gender_loss: 0.5967593193054199\n",
      "train_loss: 0.596759 | avg_loss: 0.651071 | gender_precise: 64.000000 (9767/15104) [118/186]\n",
      "gender_loss: 0.5318471193313599\n",
      "train_loss: 0.531847 | avg_loss: 0.650069 | gender_precise: 64.000000 (9863/15232) [119/186]\n",
      "gender_loss: 0.6049656867980957\n",
      "train_loss: 0.604966 | avg_loss: 0.649693 | gender_precise: 64.000000 (9949/15360) [120/186]\n",
      "gender_loss: 0.5862309336662292\n",
      "train_loss: 0.586231 | avg_loss: 0.649168 | gender_precise: 64.000000 (10040/15488) [121/186]\n",
      "gender_loss: 0.546064555644989\n",
      "train_loss: 0.546065 | avg_loss: 0.648323 | gender_precise: 64.000000 (10132/15616) [122/186]\n",
      "gender_loss: 0.5368065237998962\n",
      "train_loss: 0.536807 | avg_loss: 0.647417 | gender_precise: 64.000000 (10228/15744) [123/186]\n",
      "gender_loss: 0.514507532119751\n",
      "train_loss: 0.514508 | avg_loss: 0.646345 | gender_precise: 65.000000 (10326/15872) [124/186]\n",
      "gender_loss: 0.5476889610290527\n",
      "train_loss: 0.547689 | avg_loss: 0.645556 | gender_precise: 65.000000 (10422/16000) [125/186]\n",
      "gender_loss: 0.49783065915107727\n",
      "train_loss: 0.497831 | avg_loss: 0.644383 | gender_precise: 65.000000 (10521/16128) [126/186]\n",
      "gender_loss: 0.49500754475593567\n",
      "train_loss: 0.495008 | avg_loss: 0.643207 | gender_precise: 65.000000 (10621/16256) [127/186]\n",
      "gender_loss: 0.5220515727996826\n",
      "train_loss: 0.522052 | avg_loss: 0.642260 | gender_precise: 65.000000 (10717/16384) [128/186]\n",
      "gender_loss: 0.43467357754707336\n",
      "train_loss: 0.434674 | avg_loss: 0.640651 | gender_precise: 65.000000 (10828/16512) [129/186]\n",
      "gender_loss: 0.5706571340560913\n",
      "train_loss: 0.570657 | avg_loss: 0.640113 | gender_precise: 65.000000 (10921/16640) [130/186]\n",
      "gender_loss: 0.5454504489898682\n",
      "train_loss: 0.545450 | avg_loss: 0.639390 | gender_precise: 65.000000 (11014/16768) [131/186]\n",
      "gender_loss: 0.490019291639328\n",
      "train_loss: 0.490019 | avg_loss: 0.638259 | gender_precise: 65.000000 (11115/16896) [132/186]\n",
      "gender_loss: 0.5034734606742859\n",
      "train_loss: 0.503473 | avg_loss: 0.637245 | gender_precise: 65.000000 (11214/17024) [133/186]\n",
      "gender_loss: 0.48125484585762024\n",
      "train_loss: 0.481255 | avg_loss: 0.636081 | gender_precise: 65.000000 (11314/17152) [134/186]\n",
      "gender_loss: 0.5310906171798706\n",
      "train_loss: 0.531091 | avg_loss: 0.635303 | gender_precise: 66.000000 (11411/17280) [135/186]\n",
      "gender_loss: 0.3901337683200836\n",
      "train_loss: 0.390134 | avg_loss: 0.633501 | gender_precise: 66.000000 (11523/17408) [136/186]\n",
      "gender_loss: 0.4532020092010498\n",
      "train_loss: 0.453202 | avg_loss: 0.632185 | gender_precise: 66.000000 (11621/17536) [137/186]\n",
      "gender_loss: 0.523007869720459\n",
      "train_loss: 0.523008 | avg_loss: 0.631394 | gender_precise: 66.000000 (11719/17664) [138/186]\n",
      "gender_loss: 0.5381527543067932\n",
      "train_loss: 0.538153 | avg_loss: 0.630723 | gender_precise: 66.000000 (11808/17792) [139/186]\n",
      "gender_loss: 0.4676380753517151\n",
      "train_loss: 0.467638 | avg_loss: 0.629558 | gender_precise: 66.000000 (11909/17920) [140/186]\n",
      "gender_loss: 0.5066344141960144\n",
      "train_loss: 0.506634 | avg_loss: 0.628686 | gender_precise: 66.000000 (12013/18048) [141/186]\n",
      "gender_loss: 0.5780620574951172\n",
      "train_loss: 0.578062 | avg_loss: 0.628330 | gender_precise: 66.000000 (12102/18176) [142/186]\n",
      "gender_loss: 0.5289793014526367\n",
      "train_loss: 0.528979 | avg_loss: 0.627635 | gender_precise: 66.000000 (12201/18304) [143/186]\n",
      "gender_loss: 0.6012816429138184\n",
      "train_loss: 0.601282 | avg_loss: 0.627452 | gender_precise: 66.000000 (12293/18432) [144/186]\n",
      "gender_loss: 0.5478402376174927\n",
      "train_loss: 0.547840 | avg_loss: 0.626903 | gender_precise: 66.000000 (12394/18560) [145/186]\n",
      "gender_loss: 0.532679557800293\n",
      "train_loss: 0.532680 | avg_loss: 0.626257 | gender_precise: 66.000000 (12491/18688) [146/186]\n",
      "gender_loss: 0.5401504635810852\n",
      "train_loss: 0.540150 | avg_loss: 0.625672 | gender_precise: 66.000000 (12586/18816) [147/186]\n",
      "gender_loss: 0.6015356779098511\n",
      "train_loss: 0.601536 | avg_loss: 0.625509 | gender_precise: 66.000000 (12675/18944) [148/186]\n",
      "gender_loss: 0.492074191570282\n",
      "train_loss: 0.492074 | avg_loss: 0.624613 | gender_precise: 66.000000 (12771/19072) [149/186]\n",
      "gender_loss: 0.5234221816062927\n",
      "train_loss: 0.523422 | avg_loss: 0.623938 | gender_precise: 66.000000 (12863/19200) [150/186]\n",
      "gender_loss: 0.5200764536857605\n",
      "train_loss: 0.520076 | avg_loss: 0.623251 | gender_precise: 67.000000 (12957/19328) [151/186]\n",
      "gender_loss: 0.4941706955432892\n",
      "train_loss: 0.494171 | avg_loss: 0.622401 | gender_precise: 67.000000 (13057/19456) [152/186]\n",
      "gender_loss: 0.4824642241001129\n",
      "train_loss: 0.482464 | avg_loss: 0.621487 | gender_precise: 67.000000 (13160/19584) [153/186]\n",
      "gender_loss: 0.550417423248291\n",
      "train_loss: 0.550417 | avg_loss: 0.621025 | gender_precise: 67.000000 (13258/19712) [154/186]\n",
      "gender_loss: 0.4555763006210327\n",
      "train_loss: 0.455576 | avg_loss: 0.619958 | gender_precise: 67.000000 (13358/19840) [155/186]\n",
      "gender_loss: 0.4782032370567322\n",
      "train_loss: 0.478203 | avg_loss: 0.619049 | gender_precise: 67.000000 (13459/19968) [156/186]\n",
      "gender_loss: 0.4877837002277374\n",
      "train_loss: 0.487784 | avg_loss: 0.618213 | gender_precise: 67.000000 (13557/20096) [157/186]\n",
      "gender_loss: 0.4512713849544525\n",
      "train_loss: 0.451271 | avg_loss: 0.617156 | gender_precise: 67.000000 (13659/20224) [158/186]\n",
      "gender_loss: 0.507548451423645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.507548 | avg_loss: 0.616467 | gender_precise: 67.000000 (13754/20352) [159/186]\n",
      "gender_loss: 0.4338093400001526\n",
      "train_loss: 0.433809 | avg_loss: 0.615325 | gender_precise: 67.000000 (13861/20480) [160/186]\n",
      "gender_loss: 0.4566800892353058\n",
      "train_loss: 0.456680 | avg_loss: 0.614340 | gender_precise: 67.000000 (13959/20608) [161/186]\n",
      "gender_loss: 0.4553655982017517\n",
      "train_loss: 0.455366 | avg_loss: 0.613359 | gender_precise: 67.000000 (14056/20736) [162/186]\n",
      "gender_loss: 0.42951643466949463\n",
      "train_loss: 0.429516 | avg_loss: 0.612231 | gender_precise: 67.000000 (14157/20864) [163/186]\n",
      "gender_loss: 0.39813148975372314\n",
      "train_loss: 0.398131 | avg_loss: 0.610925 | gender_precise: 67.000000 (14264/20992) [164/186]\n",
      "gender_loss: 0.46134722232818604\n",
      "train_loss: 0.461347 | avg_loss: 0.610019 | gender_precise: 68.000000 (14364/21120) [165/186]\n",
      "gender_loss: 0.4579216241836548\n",
      "train_loss: 0.457922 | avg_loss: 0.609103 | gender_precise: 68.000000 (14465/21248) [166/186]\n",
      "gender_loss: 0.439752995967865\n",
      "train_loss: 0.439753 | avg_loss: 0.608089 | gender_precise: 68.000000 (14571/21376) [167/186]\n",
      "gender_loss: 0.4826700687408447\n",
      "train_loss: 0.482670 | avg_loss: 0.607342 | gender_precise: 68.000000 (14669/21504) [168/186]\n",
      "gender_loss: 0.39205625653266907\n",
      "train_loss: 0.392056 | avg_loss: 0.606068 | gender_precise: 68.000000 (14780/21632) [169/186]\n",
      "gender_loss: 0.42669203877449036\n",
      "train_loss: 0.426692 | avg_loss: 0.605013 | gender_precise: 68.000000 (14885/21760) [170/186]\n",
      "gender_loss: 0.5293684601783752\n",
      "train_loss: 0.529368 | avg_loss: 0.604571 | gender_precise: 68.000000 (14984/21888) [171/186]\n",
      "gender_loss: 0.3656642436981201\n",
      "train_loss: 0.365664 | avg_loss: 0.603182 | gender_precise: 68.000000 (15093/22016) [172/186]\n",
      "gender_loss: 0.44101038575172424\n",
      "train_loss: 0.441010 | avg_loss: 0.602244 | gender_precise: 68.000000 (15195/22144) [173/186]\n",
      "gender_loss: 0.40215015411376953\n",
      "train_loss: 0.402150 | avg_loss: 0.601094 | gender_precise: 68.000000 (15299/22272) [174/186]\n",
      "gender_loss: 0.4192781150341034\n",
      "train_loss: 0.419278 | avg_loss: 0.600055 | gender_precise: 68.000000 (15403/22400) [175/186]\n",
      "gender_loss: 0.4696284830570221\n",
      "train_loss: 0.469628 | avg_loss: 0.599314 | gender_precise: 68.000000 (15501/22528) [176/186]\n",
      "gender_loss: 0.4117145240306854\n",
      "train_loss: 0.411715 | avg_loss: 0.598254 | gender_precise: 68.000000 (15602/22656) [177/186]\n",
      "gender_loss: 0.44227302074432373\n",
      "train_loss: 0.442273 | avg_loss: 0.597378 | gender_precise: 68.000000 (15701/22784) [178/186]\n",
      "gender_loss: 0.5455403923988342\n",
      "train_loss: 0.545540 | avg_loss: 0.597089 | gender_precise: 68.000000 (15797/22912) [179/186]\n",
      "gender_loss: 0.430077463388443\n",
      "train_loss: 0.430077 | avg_loss: 0.596161 | gender_precise: 69.000000 (15904/23040) [180/186]\n",
      "gender_loss: 0.44655194878578186\n",
      "train_loss: 0.446552 | avg_loss: 0.595334 | gender_precise: 69.000000 (16005/23168) [181/186]\n",
      "gender_loss: 0.4317358732223511\n",
      "train_loss: 0.431736 | avg_loss: 0.594435 | gender_precise: 69.000000 (16107/23296) [182/186]\n",
      "gender_loss: 0.3752480745315552\n",
      "train_loss: 0.375248 | avg_loss: 0.593237 | gender_precise: 69.000000 (16217/23424) [183/186]\n",
      "gender_loss: 0.43013158440589905\n",
      "train_loss: 0.430132 | avg_loss: 0.592351 | gender_precise: 69.000000 (16321/23552) [184/186]\n",
      "gender_loss: 0.5520778298377991\n",
      "train_loss: 0.552078 | avg_loss: 0.592133 | gender_precise: 69.000000 (16416/23680) [185/186]\n",
      "gender_loss: 0.3970341384410858\n",
      "train_loss: 0.397034 | avg_loss: 0.591084 | gender_precise: 69.000000 (16437/23708) [186/186]\n",
      "\n",
      "Test\n",
      "gender_prec: 76.000000 (98/128) [1/2]\n",
      "gender_prec: 75.000000 (101/134) [2/2]\n",
      "Saving..\n",
      "Number epoch: 3\n",
      "gender_loss: 0.467555969953537\n",
      "train_loss: 0.467556 | avg_loss: 0.467556 | gender_precise: 78.000000 (100/128) [1/186]\n",
      "gender_loss: 0.43396231532096863\n",
      "train_loss: 0.433962 | avg_loss: 0.450759 | gender_precise: 78.000000 (202/256) [2/186]\n",
      "gender_loss: 0.41316482424736023\n",
      "train_loss: 0.413165 | avg_loss: 0.438228 | gender_precise: 79.000000 (304/384) [3/186]\n",
      "gender_loss: 0.3929135799407959\n",
      "train_loss: 0.392914 | avg_loss: 0.426899 | gender_precise: 80.000000 (411/512) [4/186]\n",
      "gender_loss: 0.40644192695617676\n",
      "train_loss: 0.406442 | avg_loss: 0.422808 | gender_precise: 80.000000 (517/640) [5/186]\n",
      "gender_loss: 0.4506203830242157\n",
      "train_loss: 0.450620 | avg_loss: 0.427443 | gender_precise: 80.000000 (618/768) [6/186]\n",
      "gender_loss: 0.43424665927886963\n",
      "train_loss: 0.434247 | avg_loss: 0.428415 | gender_precise: 80.000000 (720/896) [7/186]\n",
      "gender_loss: 0.4391785264015198\n",
      "train_loss: 0.439179 | avg_loss: 0.429761 | gender_precise: 79.000000 (818/1024) [8/186]\n",
      "gender_loss: 0.5393478870391846\n",
      "train_loss: 0.539348 | avg_loss: 0.441937 | gender_precise: 79.000000 (913/1152) [9/186]\n",
      "gender_loss: 0.5174084305763245\n",
      "train_loss: 0.517408 | avg_loss: 0.449484 | gender_precise: 79.000000 (1013/1280) [10/186]\n",
      "gender_loss: 0.37880244851112366\n",
      "train_loss: 0.378802 | avg_loss: 0.443058 | gender_precise: 79.000000 (1119/1408) [11/186]\n",
      "gender_loss: 0.49889469146728516\n",
      "train_loss: 0.498895 | avg_loss: 0.447711 | gender_precise: 79.000000 (1222/1536) [12/186]\n",
      "gender_loss: 0.34030258655548096\n",
      "train_loss: 0.340303 | avg_loss: 0.439449 | gender_precise: 80.000000 (1335/1664) [13/186]\n",
      "gender_loss: 0.4217723608016968\n",
      "train_loss: 0.421772 | avg_loss: 0.438187 | gender_precise: 80.000000 (1437/1792) [14/186]\n",
      "gender_loss: 0.412800133228302\n",
      "train_loss: 0.412800 | avg_loss: 0.436494 | gender_precise: 80.000000 (1540/1920) [15/186]\n",
      "gender_loss: 0.4394600987434387\n",
      "train_loss: 0.439460 | avg_loss: 0.436680 | gender_precise: 80.000000 (1641/2048) [16/186]\n",
      "gender_loss: 0.38662654161453247\n",
      "train_loss: 0.386627 | avg_loss: 0.433735 | gender_precise: 80.000000 (1745/2176) [17/186]\n",
      "gender_loss: 0.33538568019866943\n",
      "train_loss: 0.335386 | avg_loss: 0.428271 | gender_precise: 80.000000 (1854/2304) [18/186]\n",
      "gender_loss: 0.5358148217201233\n",
      "train_loss: 0.535815 | avg_loss: 0.433932 | gender_precise: 80.000000 (1956/2432) [19/186]\n",
      "gender_loss: 0.44577473402023315\n",
      "train_loss: 0.445775 | avg_loss: 0.434524 | gender_precise: 80.000000 (2059/2560) [20/186]\n",
      "gender_loss: 0.3568391799926758\n",
      "train_loss: 0.356839 | avg_loss: 0.430825 | gender_precise: 80.000000 (2171/2688) [21/186]\n",
      "gender_loss: 0.41614624857902527\n",
      "train_loss: 0.416146 | avg_loss: 0.430157 | gender_precise: 80.000000 (2279/2816) [22/186]\n",
      "gender_loss: 0.4245319664478302\n",
      "train_loss: 0.424532 | avg_loss: 0.429913 | gender_precise: 80.000000 (2379/2944) [23/186]\n",
      "gender_loss: 0.41527774930000305\n",
      "train_loss: 0.415278 | avg_loss: 0.429303 | gender_precise: 80.000000 (2482/3072) [24/186]\n",
      "gender_loss: 0.4067036211490631\n",
      "train_loss: 0.406704 | avg_loss: 0.428399 | gender_precise: 80.000000 (2587/3200) [25/186]\n",
      "gender_loss: 0.45038142800331116\n",
      "train_loss: 0.450381 | avg_loss: 0.429244 | gender_precise: 80.000000 (2688/3328) [26/186]\n",
      "gender_loss: 0.39361217617988586\n",
      "train_loss: 0.393612 | avg_loss: 0.427925 | gender_precise: 80.000000 (2791/3456) [27/186]\n",
      "gender_loss: 0.3838001489639282\n",
      "train_loss: 0.383800 | avg_loss: 0.426349 | gender_precise: 80.000000 (2898/3584) [28/186]\n",
      "gender_loss: 0.34260696172714233\n",
      "train_loss: 0.342607 | avg_loss: 0.423461 | gender_precise: 81.000000 (3012/3712) [29/186]\n",
      "gender_loss: 0.4149121940135956\n",
      "train_loss: 0.414912 | avg_loss: 0.423176 | gender_precise: 81.000000 (3116/3840) [30/186]\n",
      "gender_loss: 0.3812345862388611\n",
      "train_loss: 0.381235 | avg_loss: 0.421823 | gender_precise: 81.000000 (3224/3968) [31/186]\n",
      "gender_loss: 0.39582908153533936\n",
      "train_loss: 0.395829 | avg_loss: 0.421011 | gender_precise: 81.000000 (3327/4096) [32/186]\n",
      "gender_loss: 0.3375861942768097\n",
      "train_loss: 0.337586 | avg_loss: 0.418483 | gender_precise: 81.000000 (3434/4224) [33/186]\n",
      "gender_loss: 0.36854538321495056\n",
      "train_loss: 0.368545 | avg_loss: 0.417014 | gender_precise: 81.000000 (3543/4352) [34/186]\n",
      "gender_loss: 0.4043442904949188\n",
      "train_loss: 0.404344 | avg_loss: 0.416652 | gender_precise: 81.000000 (3649/4480) [35/186]\n",
      "gender_loss: 0.3944137990474701\n",
      "train_loss: 0.394414 | avg_loss: 0.416034 | gender_precise: 81.000000 (3755/4608) [36/186]\n",
      "gender_loss: 0.46757858991622925\n",
      "train_loss: 0.467579 | avg_loss: 0.417428 | gender_precise: 81.000000 (3855/4736) [37/186]\n",
      "gender_loss: 0.3888038098812103\n",
      "train_loss: 0.388804 | avg_loss: 0.416674 | gender_precise: 81.000000 (3958/4864) [38/186]\n",
      "gender_loss: 0.3751852810382843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.375185 | avg_loss: 0.415610 | gender_precise: 81.000000 (4067/4992) [39/186]\n",
      "gender_loss: 0.3291642367839813\n",
      "train_loss: 0.329164 | avg_loss: 0.413449 | gender_precise: 81.000000 (4176/5120) [40/186]\n",
      "gender_loss: 0.342203825712204\n",
      "train_loss: 0.342204 | avg_loss: 0.411712 | gender_precise: 81.000000 (4283/5248) [41/186]\n",
      "gender_loss: 0.2798180878162384\n",
      "train_loss: 0.279818 | avg_loss: 0.408571 | gender_precise: 81.000000 (4398/5376) [42/186]\n",
      "gender_loss: 0.34360629320144653\n",
      "train_loss: 0.343606 | avg_loss: 0.407060 | gender_precise: 81.000000 (4507/5504) [43/186]\n",
      "gender_loss: 0.38674548268318176\n",
      "train_loss: 0.386745 | avg_loss: 0.406599 | gender_precise: 81.000000 (4614/5632) [44/186]\n",
      "gender_loss: 0.2982025742530823\n",
      "train_loss: 0.298203 | avg_loss: 0.404190 | gender_precise: 82.000000 (4725/5760) [45/186]\n",
      "gender_loss: 0.37577080726623535\n",
      "train_loss: 0.375771 | avg_loss: 0.403572 | gender_precise: 82.000000 (4830/5888) [46/186]\n",
      "gender_loss: 0.3592092990875244\n",
      "train_loss: 0.359209 | avg_loss: 0.402628 | gender_precise: 82.000000 (4937/6016) [47/186]\n",
      "gender_loss: 0.4107419550418854\n",
      "train_loss: 0.410742 | avg_loss: 0.402797 | gender_precise: 82.000000 (5046/6144) [48/186]\n",
      "gender_loss: 0.33664044737815857\n",
      "train_loss: 0.336640 | avg_loss: 0.401447 | gender_precise: 82.000000 (5155/6272) [49/186]\n",
      "gender_loss: 0.3645005524158478\n",
      "train_loss: 0.364501 | avg_loss: 0.400708 | gender_precise: 82.000000 (5262/6400) [50/186]\n",
      "gender_loss: 0.32690122723579407\n",
      "train_loss: 0.326901 | avg_loss: 0.399261 | gender_precise: 82.000000 (5375/6528) [51/186]\n",
      "gender_loss: 0.3175436556339264\n",
      "train_loss: 0.317544 | avg_loss: 0.397690 | gender_precise: 82.000000 (5488/6656) [52/186]\n",
      "gender_loss: 0.3296763300895691\n",
      "train_loss: 0.329676 | avg_loss: 0.396406 | gender_precise: 82.000000 (5596/6784) [53/186]\n",
      "gender_loss: 0.43966352939605713\n",
      "train_loss: 0.439664 | avg_loss: 0.397207 | gender_precise: 82.000000 (5703/6912) [54/186]\n",
      "gender_loss: 0.3465309739112854\n",
      "train_loss: 0.346531 | avg_loss: 0.396286 | gender_precise: 82.000000 (5812/7040) [55/186]\n",
      "gender_loss: 0.3750144839286804\n",
      "train_loss: 0.375014 | avg_loss: 0.395906 | gender_precise: 82.000000 (5916/7168) [56/186]\n",
      "gender_loss: 0.3402261435985565\n",
      "train_loss: 0.340226 | avg_loss: 0.394929 | gender_precise: 82.000000 (6023/7296) [57/186]\n",
      "gender_loss: 0.3104206621646881\n",
      "train_loss: 0.310421 | avg_loss: 0.393472 | gender_precise: 82.000000 (6134/7424) [58/186]\n",
      "gender_loss: 0.32633766531944275\n",
      "train_loss: 0.326338 | avg_loss: 0.392334 | gender_precise: 82.000000 (6241/7552) [59/186]\n",
      "gender_loss: 0.46183276176452637\n",
      "train_loss: 0.461833 | avg_loss: 0.393493 | gender_precise: 82.000000 (6343/7680) [60/186]\n",
      "gender_loss: 0.27886462211608887\n",
      "train_loss: 0.278865 | avg_loss: 0.391613 | gender_precise: 82.000000 (6461/7808) [61/186]\n",
      "gender_loss: 0.3030344545841217\n",
      "train_loss: 0.303034 | avg_loss: 0.390185 | gender_precise: 82.000000 (6574/7936) [62/186]\n",
      "gender_loss: 0.43079763650894165\n",
      "train_loss: 0.430798 | avg_loss: 0.390829 | gender_precise: 82.000000 (6676/8064) [63/186]\n",
      "gender_loss: 0.31969311833381653\n",
      "train_loss: 0.319693 | avg_loss: 0.389718 | gender_precise: 82.000000 (6788/8192) [64/186]\n",
      "gender_loss: 0.36337175965309143\n",
      "train_loss: 0.363372 | avg_loss: 0.389313 | gender_precise: 82.000000 (6895/8320) [65/186]\n",
      "gender_loss: 0.33851224184036255\n",
      "train_loss: 0.338512 | avg_loss: 0.388543 | gender_precise: 82.000000 (7005/8448) [66/186]\n",
      "gender_loss: 0.34243130683898926\n",
      "train_loss: 0.342431 | avg_loss: 0.387855 | gender_precise: 82.000000 (7108/8576) [67/186]\n",
      "gender_loss: 0.40971624851226807\n",
      "train_loss: 0.409716 | avg_loss: 0.388176 | gender_precise: 82.000000 (7212/8704) [68/186]\n",
      "gender_loss: 0.287727415561676\n",
      "train_loss: 0.287727 | avg_loss: 0.386720 | gender_precise: 82.000000 (7323/8832) [69/186]\n",
      "gender_loss: 0.2892392575740814\n",
      "train_loss: 0.289239 | avg_loss: 0.385328 | gender_precise: 82.000000 (7434/8960) [70/186]\n",
      "gender_loss: 0.31210029125213623\n",
      "train_loss: 0.312100 | avg_loss: 0.384296 | gender_precise: 83.000000 (7546/9088) [71/186]\n",
      "gender_loss: 0.2732909321784973\n",
      "train_loss: 0.273291 | avg_loss: 0.382755 | gender_precise: 83.000000 (7662/9216) [72/186]\n",
      "gender_loss: 0.27918553352355957\n",
      "train_loss: 0.279186 | avg_loss: 0.381336 | gender_precise: 83.000000 (7776/9344) [73/186]\n",
      "gender_loss: 0.3044510781764984\n",
      "train_loss: 0.304451 | avg_loss: 0.380297 | gender_precise: 83.000000 (7884/9472) [74/186]\n",
      "gender_loss: 0.2982095181941986\n",
      "train_loss: 0.298210 | avg_loss: 0.379202 | gender_precise: 83.000000 (7995/9600) [75/186]\n",
      "gender_loss: 0.33042025566101074\n",
      "train_loss: 0.330420 | avg_loss: 0.378561 | gender_precise: 83.000000 (8101/9728) [76/186]\n",
      "gender_loss: 0.2862832546234131\n",
      "train_loss: 0.286283 | avg_loss: 0.377362 | gender_precise: 83.000000 (8213/9856) [77/186]\n",
      "gender_loss: 0.3746188282966614\n",
      "train_loss: 0.374619 | avg_loss: 0.377327 | gender_precise: 83.000000 (8319/9984) [78/186]\n",
      "gender_loss: 0.3293136954307556\n",
      "train_loss: 0.329314 | avg_loss: 0.376719 | gender_precise: 83.000000 (8431/10112) [79/186]\n",
      "gender_loss: 0.42765378952026367\n",
      "train_loss: 0.427654 | avg_loss: 0.377356 | gender_precise: 83.000000 (8537/10240) [80/186]\n",
      "gender_loss: 0.41028186678886414\n",
      "train_loss: 0.410282 | avg_loss: 0.377762 | gender_precise: 83.000000 (8637/10368) [81/186]\n",
      "gender_loss: 0.3206818103790283\n",
      "train_loss: 0.320682 | avg_loss: 0.377066 | gender_precise: 83.000000 (8748/10496) [82/186]\n",
      "gender_loss: 0.28704357147216797\n",
      "train_loss: 0.287044 | avg_loss: 0.375982 | gender_precise: 83.000000 (8859/10624) [83/186]\n",
      "gender_loss: 0.29481592774391174\n",
      "train_loss: 0.294816 | avg_loss: 0.375015 | gender_precise: 83.000000 (8970/10752) [84/186]\n",
      "gender_loss: 0.36057519912719727\n",
      "train_loss: 0.360575 | avg_loss: 0.374846 | gender_precise: 83.000000 (9081/10880) [85/186]\n",
      "gender_loss: 0.46511590480804443\n",
      "train_loss: 0.465116 | avg_loss: 0.375895 | gender_precise: 83.000000 (9177/11008) [86/186]\n",
      "gender_loss: 0.3828538954257965\n",
      "train_loss: 0.382854 | avg_loss: 0.375975 | gender_precise: 83.000000 (9285/11136) [87/186]\n",
      "gender_loss: 0.3354824185371399\n",
      "train_loss: 0.335482 | avg_loss: 0.375515 | gender_precise: 83.000000 (9397/11264) [88/186]\n",
      "gender_loss: 0.35864025354385376\n",
      "train_loss: 0.358640 | avg_loss: 0.375325 | gender_precise: 83.000000 (9507/11392) [89/186]\n",
      "gender_loss: 0.3214394450187683\n",
      "train_loss: 0.321439 | avg_loss: 0.374727 | gender_precise: 83.000000 (9618/11520) [90/186]\n",
      "gender_loss: 0.45462390780448914\n",
      "train_loss: 0.454624 | avg_loss: 0.375605 | gender_precise: 83.000000 (9721/11648) [91/186]\n",
      "gender_loss: 0.34294044971466064\n",
      "train_loss: 0.342940 | avg_loss: 0.375250 | gender_precise: 83.000000 (9829/11776) [92/186]\n",
      "gender_loss: 0.35890159010887146\n",
      "train_loss: 0.358902 | avg_loss: 0.375074 | gender_precise: 83.000000 (9935/11904) [93/186]\n",
      "gender_loss: 0.4142206013202667\n",
      "train_loss: 0.414221 | avg_loss: 0.375490 | gender_precise: 83.000000 (10036/12032) [94/186]\n",
      "gender_loss: 0.2798589766025543\n",
      "train_loss: 0.279859 | avg_loss: 0.374484 | gender_precise: 83.000000 (10149/12160) [95/186]\n",
      "gender_loss: 0.3449002504348755\n",
      "train_loss: 0.344900 | avg_loss: 0.374175 | gender_precise: 83.000000 (10254/12288) [96/186]\n",
      "gender_loss: 0.31019899249076843\n",
      "train_loss: 0.310199 | avg_loss: 0.373516 | gender_precise: 83.000000 (10362/12416) [97/186]\n",
      "gender_loss: 0.37199866771698\n",
      "train_loss: 0.371999 | avg_loss: 0.373500 | gender_precise: 83.000000 (10467/12544) [98/186]\n",
      "gender_loss: 0.3580065965652466\n",
      "train_loss: 0.358007 | avg_loss: 0.373344 | gender_precise: 83.000000 (10576/12672) [99/186]\n",
      "gender_loss: 0.31648433208465576\n",
      "train_loss: 0.316484 | avg_loss: 0.372775 | gender_precise: 83.000000 (10688/12800) [100/186]\n",
      "gender_loss: 0.3224312365055084\n",
      "train_loss: 0.322431 | avg_loss: 0.372277 | gender_precise: 83.000000 (10797/12928) [101/186]\n",
      "gender_loss: 0.35233408212661743\n",
      "train_loss: 0.352334 | avg_loss: 0.372081 | gender_precise: 83.000000 (10905/13056) [102/186]\n",
      "gender_loss: 0.28255289793014526\n",
      "train_loss: 0.282553 | avg_loss: 0.371212 | gender_precise: 83.000000 (11014/13184) [103/186]\n",
      "gender_loss: 0.2944536805152893\n",
      "train_loss: 0.294454 | avg_loss: 0.370474 | gender_precise: 83.000000 (11127/13312) [104/186]\n",
      "gender_loss: 0.3865452706813812\n",
      "train_loss: 0.386545 | avg_loss: 0.370627 | gender_precise: 83.000000 (11233/13440) [105/186]\n",
      "gender_loss: 0.3353002965450287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.335300 | avg_loss: 0.370294 | gender_precise: 83.000000 (11342/13568) [106/186]\n",
      "gender_loss: 0.38431769609451294\n",
      "train_loss: 0.384318 | avg_loss: 0.370425 | gender_precise: 83.000000 (11447/13696) [107/186]\n",
      "gender_loss: 0.2924637496471405\n",
      "train_loss: 0.292464 | avg_loss: 0.369703 | gender_precise: 83.000000 (11557/13824) [108/186]\n",
      "gender_loss: 0.34408560395240784\n",
      "train_loss: 0.344086 | avg_loss: 0.369468 | gender_precise: 83.000000 (11665/13952) [109/186]\n",
      "gender_loss: 0.2321425825357437\n",
      "train_loss: 0.232143 | avg_loss: 0.368220 | gender_precise: 83.000000 (11781/14080) [110/186]\n",
      "gender_loss: 0.28845828771591187\n",
      "train_loss: 0.288458 | avg_loss: 0.367501 | gender_precise: 83.000000 (11891/14208) [111/186]\n",
      "gender_loss: 0.3432818353176117\n",
      "train_loss: 0.343282 | avg_loss: 0.367285 | gender_precise: 83.000000 (11998/14336) [112/186]\n",
      "gender_loss: 0.2802627682685852\n",
      "train_loss: 0.280263 | avg_loss: 0.366515 | gender_precise: 83.000000 (12108/14464) [113/186]\n",
      "gender_loss: 0.31969842314720154\n",
      "train_loss: 0.319698 | avg_loss: 0.366104 | gender_precise: 83.000000 (12221/14592) [114/186]\n",
      "gender_loss: 0.25661274790763855\n",
      "train_loss: 0.256613 | avg_loss: 0.365152 | gender_precise: 83.000000 (12332/14720) [115/186]\n",
      "gender_loss: 0.37085655331611633\n",
      "train_loss: 0.370857 | avg_loss: 0.365201 | gender_precise: 83.000000 (12440/14848) [116/186]\n",
      "gender_loss: 0.3177489638328552\n",
      "train_loss: 0.317749 | avg_loss: 0.364796 | gender_precise: 83.000000 (12551/14976) [117/186]\n",
      "gender_loss: 0.2927560806274414\n",
      "train_loss: 0.292756 | avg_loss: 0.364185 | gender_precise: 83.000000 (12661/15104) [118/186]\n",
      "gender_loss: 0.3110691010951996\n",
      "train_loss: 0.311069 | avg_loss: 0.363739 | gender_precise: 83.000000 (12774/15232) [119/186]\n",
      "gender_loss: 0.38319915533065796\n",
      "train_loss: 0.383199 | avg_loss: 0.363901 | gender_precise: 83.000000 (12887/15360) [120/186]\n",
      "gender_loss: 0.30791568756103516\n",
      "train_loss: 0.307916 | avg_loss: 0.363438 | gender_precise: 83.000000 (12996/15488) [121/186]\n",
      "gender_loss: 0.3335167169570923\n",
      "train_loss: 0.333517 | avg_loss: 0.363193 | gender_precise: 83.000000 (13107/15616) [122/186]\n",
      "gender_loss: 0.3208147883415222\n",
      "train_loss: 0.320815 | avg_loss: 0.362848 | gender_precise: 83.000000 (13218/15744) [123/186]\n",
      "gender_loss: 0.2713260352611542\n",
      "train_loss: 0.271326 | avg_loss: 0.362110 | gender_precise: 83.000000 (13330/15872) [124/186]\n",
      "gender_loss: 0.34602412581443787\n",
      "train_loss: 0.346024 | avg_loss: 0.361982 | gender_precise: 83.000000 (13438/16000) [125/186]\n",
      "gender_loss: 0.29975536465644836\n",
      "train_loss: 0.299755 | avg_loss: 0.361488 | gender_precise: 84.000000 (13549/16128) [126/186]\n",
      "gender_loss: 0.3077034056186676\n",
      "train_loss: 0.307703 | avg_loss: 0.361064 | gender_precise: 84.000000 (13660/16256) [127/186]\n",
      "gender_loss: 0.34271159768104553\n",
      "train_loss: 0.342712 | avg_loss: 0.360921 | gender_precise: 84.000000 (13769/16384) [128/186]\n",
      "gender_loss: 0.26943713426589966\n",
      "train_loss: 0.269437 | avg_loss: 0.360212 | gender_precise: 84.000000 (13877/16512) [129/186]\n",
      "gender_loss: 0.36983656883239746\n",
      "train_loss: 0.369837 | avg_loss: 0.360286 | gender_precise: 84.000000 (13981/16640) [130/186]\n",
      "gender_loss: 0.3435731530189514\n",
      "train_loss: 0.343573 | avg_loss: 0.360158 | gender_precise: 84.000000 (14090/16768) [131/186]\n",
      "gender_loss: 0.3625276982784271\n",
      "train_loss: 0.362528 | avg_loss: 0.360176 | gender_precise: 84.000000 (14202/16896) [132/186]\n",
      "gender_loss: 0.354743093252182\n",
      "train_loss: 0.354743 | avg_loss: 0.360135 | gender_precise: 84.000000 (14309/17024) [133/186]\n",
      "gender_loss: 0.2994810938835144\n",
      "train_loss: 0.299481 | avg_loss: 0.359683 | gender_precise: 84.000000 (14420/17152) [134/186]\n",
      "gender_loss: 0.3127109110355377\n",
      "train_loss: 0.312711 | avg_loss: 0.359335 | gender_precise: 84.000000 (14532/17280) [135/186]\n",
      "gender_loss: 0.2671002745628357\n",
      "train_loss: 0.267100 | avg_loss: 0.358656 | gender_precise: 84.000000 (14645/17408) [136/186]\n",
      "gender_loss: 0.3619661033153534\n",
      "train_loss: 0.361966 | avg_loss: 0.358681 | gender_precise: 84.000000 (14755/17536) [137/186]\n",
      "gender_loss: 0.4234647750854492\n",
      "train_loss: 0.423465 | avg_loss: 0.359150 | gender_precise: 84.000000 (14861/17664) [138/186]\n",
      "gender_loss: 0.4011303186416626\n",
      "train_loss: 0.401130 | avg_loss: 0.359452 | gender_precise: 84.000000 (14966/17792) [139/186]\n",
      "gender_loss: 0.332830011844635\n",
      "train_loss: 0.332830 | avg_loss: 0.359262 | gender_precise: 84.000000 (15077/17920) [140/186]\n",
      "gender_loss: 0.2623389661312103\n",
      "train_loss: 0.262339 | avg_loss: 0.358575 | gender_precise: 84.000000 (15189/18048) [141/186]\n",
      "gender_loss: 0.32197901606559753\n",
      "train_loss: 0.321979 | avg_loss: 0.358317 | gender_precise: 84.000000 (15296/18176) [142/186]\n",
      "gender_loss: 0.3907582461833954\n",
      "train_loss: 0.390758 | avg_loss: 0.358544 | gender_precise: 84.000000 (15401/18304) [143/186]\n",
      "gender_loss: 0.2589990496635437\n",
      "train_loss: 0.258999 | avg_loss: 0.357852 | gender_precise: 84.000000 (15512/18432) [144/186]\n",
      "gender_loss: 0.27605611085891724\n",
      "train_loss: 0.276056 | avg_loss: 0.357288 | gender_precise: 84.000000 (15626/18560) [145/186]\n",
      "gender_loss: 0.37434202432632446\n",
      "train_loss: 0.374342 | avg_loss: 0.357405 | gender_precise: 84.000000 (15727/18688) [146/186]\n",
      "gender_loss: 0.28642380237579346\n",
      "train_loss: 0.286424 | avg_loss: 0.356922 | gender_precise: 84.000000 (15841/18816) [147/186]\n",
      "gender_loss: 0.30379754304885864\n",
      "train_loss: 0.303798 | avg_loss: 0.356563 | gender_precise: 84.000000 (15954/18944) [148/186]\n",
      "gender_loss: 0.3104594051837921\n",
      "train_loss: 0.310459 | avg_loss: 0.356254 | gender_precise: 84.000000 (16063/19072) [149/186]\n",
      "gender_loss: 0.47414103150367737\n",
      "train_loss: 0.474141 | avg_loss: 0.357040 | gender_precise: 84.000000 (16163/19200) [150/186]\n",
      "gender_loss: 0.2011512815952301\n",
      "train_loss: 0.201151 | avg_loss: 0.356007 | gender_precise: 84.000000 (16278/19328) [151/186]\n",
      "gender_loss: 0.2746853232383728\n",
      "train_loss: 0.274685 | avg_loss: 0.355472 | gender_precise: 84.000000 (16391/19456) [152/186]\n",
      "gender_loss: 0.24978390336036682\n",
      "train_loss: 0.249784 | avg_loss: 0.354782 | gender_precise: 84.000000 (16506/19584) [153/186]\n",
      "gender_loss: 0.364111065864563\n",
      "train_loss: 0.364111 | avg_loss: 0.354842 | gender_precise: 84.000000 (16614/19712) [154/186]\n",
      "gender_loss: 0.34254398941993713\n",
      "train_loss: 0.342544 | avg_loss: 0.354763 | gender_precise: 84.000000 (16717/19840) [155/186]\n",
      "gender_loss: 0.36058175563812256\n",
      "train_loss: 0.360582 | avg_loss: 0.354800 | gender_precise: 84.000000 (16827/19968) [156/186]\n",
      "gender_loss: 0.2968510687351227\n",
      "train_loss: 0.296851 | avg_loss: 0.354431 | gender_precise: 84.000000 (16940/20096) [157/186]\n",
      "gender_loss: 0.2906537353992462\n",
      "train_loss: 0.290654 | avg_loss: 0.354027 | gender_precise: 84.000000 (17050/20224) [158/186]\n",
      "gender_loss: 0.3063744604587555\n",
      "train_loss: 0.306374 | avg_loss: 0.353728 | gender_precise: 84.000000 (17155/20352) [159/186]\n",
      "gender_loss: 0.2879864573478699\n",
      "train_loss: 0.287986 | avg_loss: 0.353317 | gender_precise: 84.000000 (17268/20480) [160/186]\n",
      "gender_loss: 0.32338327169418335\n",
      "train_loss: 0.323383 | avg_loss: 0.353131 | gender_precise: 84.000000 (17375/20608) [161/186]\n",
      "gender_loss: 0.42025208473205566\n",
      "train_loss: 0.420252 | avg_loss: 0.353545 | gender_precise: 84.000000 (17481/20736) [162/186]\n",
      "gender_loss: 0.32917192578315735\n",
      "train_loss: 0.329172 | avg_loss: 0.353396 | gender_precise: 84.000000 (17587/20864) [163/186]\n",
      "gender_loss: 0.3479996919631958\n",
      "train_loss: 0.348000 | avg_loss: 0.353363 | gender_precise: 84.000000 (17697/20992) [164/186]\n",
      "gender_loss: 0.3592076897621155\n",
      "train_loss: 0.359208 | avg_loss: 0.353398 | gender_precise: 84.000000 (17806/21120) [165/186]\n",
      "gender_loss: 0.41141265630722046\n",
      "train_loss: 0.411413 | avg_loss: 0.353748 | gender_precise: 84.000000 (17913/21248) [166/186]\n",
      "gender_loss: 0.3808715045452118\n",
      "train_loss: 0.380872 | avg_loss: 0.353910 | gender_precise: 84.000000 (18017/21376) [167/186]\n",
      "gender_loss: 0.34639352560043335\n",
      "train_loss: 0.346394 | avg_loss: 0.353865 | gender_precise: 84.000000 (18122/21504) [168/186]\n",
      "gender_loss: 0.3054993748664856\n",
      "train_loss: 0.305499 | avg_loss: 0.353579 | gender_precise: 84.000000 (18234/21632) [169/186]\n",
      "gender_loss: 0.35417482256889343\n",
      "train_loss: 0.354175 | avg_loss: 0.353583 | gender_precise: 84.000000 (18343/21760) [170/186]\n",
      "gender_loss: 0.2997332513332367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.299733 | avg_loss: 0.353268 | gender_precise: 84.000000 (18452/21888) [171/186]\n",
      "gender_loss: 0.301461786031723\n",
      "train_loss: 0.301462 | avg_loss: 0.352967 | gender_precise: 84.000000 (18566/22016) [172/186]\n",
      "gender_loss: 0.3246181905269623\n",
      "train_loss: 0.324618 | avg_loss: 0.352803 | gender_precise: 84.000000 (18675/22144) [173/186]\n",
      "gender_loss: 0.35675206780433655\n",
      "train_loss: 0.356752 | avg_loss: 0.352825 | gender_precise: 84.000000 (18785/22272) [174/186]\n",
      "gender_loss: 0.25802260637283325\n",
      "train_loss: 0.258023 | avg_loss: 0.352284 | gender_precise: 84.000000 (18901/22400) [175/186]\n",
      "gender_loss: 0.35997718572616577\n",
      "train_loss: 0.359977 | avg_loss: 0.352327 | gender_precise: 84.000000 (19010/22528) [176/186]\n",
      "gender_loss: 0.3544620871543884\n",
      "train_loss: 0.354462 | avg_loss: 0.352339 | gender_precise: 84.000000 (19117/22656) [177/186]\n",
      "gender_loss: 0.3253265917301178\n",
      "train_loss: 0.325327 | avg_loss: 0.352188 | gender_precise: 84.000000 (19228/22784) [178/186]\n",
      "gender_loss: 0.33707159757614136\n",
      "train_loss: 0.337072 | avg_loss: 0.352103 | gender_precise: 84.000000 (19338/22912) [179/186]\n",
      "gender_loss: 0.2457166314125061\n",
      "train_loss: 0.245717 | avg_loss: 0.351512 | gender_precise: 84.000000 (19451/23040) [180/186]\n",
      "gender_loss: 0.22784125804901123\n",
      "train_loss: 0.227841 | avg_loss: 0.350829 | gender_precise: 84.000000 (19569/23168) [181/186]\n",
      "gender_loss: 0.2728478014469147\n",
      "train_loss: 0.272848 | avg_loss: 0.350400 | gender_precise: 84.000000 (19681/23296) [182/186]\n",
      "gender_loss: 0.34820541739463806\n",
      "train_loss: 0.348205 | avg_loss: 0.350388 | gender_precise: 84.000000 (19793/23424) [183/186]\n",
      "gender_loss: 0.271459698677063\n",
      "train_loss: 0.271460 | avg_loss: 0.349959 | gender_precise: 84.000000 (19906/23552) [184/186]\n",
      "gender_loss: 0.285767525434494\n",
      "train_loss: 0.285768 | avg_loss: 0.349612 | gender_precise: 84.000000 (20019/23680) [185/186]\n",
      "gender_loss: 0.22262032330036163\n",
      "train_loss: 0.222620 | avg_loss: 0.348930 | gender_precise: 84.000000 (20043/23708) [186/186]\n",
      "\n",
      "Test\n",
      "gender_prec: 81.000000 (104/128) [1/2]\n",
      "gender_prec: 80.000000 (108/134) [2/2]\n",
      "Saving..\n",
      "Number epoch: 4\n",
      "gender_loss: 0.2965875267982483\n",
      "train_loss: 0.296588 | avg_loss: 0.296588 | gender_precise: 86.000000 (111/128) [1/186]\n",
      "gender_loss: 0.3627510964870453\n",
      "train_loss: 0.362751 | avg_loss: 0.329669 | gender_precise: 82.000000 (212/256) [2/186]\n",
      "gender_loss: 0.2688709497451782\n",
      "train_loss: 0.268871 | avg_loss: 0.309403 | gender_precise: 84.000000 (326/384) [3/186]\n",
      "gender_loss: 0.30893057584762573\n",
      "train_loss: 0.308931 | avg_loss: 0.309285 | gender_precise: 84.000000 (435/512) [4/186]\n",
      "gender_loss: 0.2814881205558777\n",
      "train_loss: 0.281488 | avg_loss: 0.303726 | gender_precise: 85.000000 (546/640) [5/186]\n",
      "gender_loss: 0.34688499569892883\n",
      "train_loss: 0.346885 | avg_loss: 0.310919 | gender_precise: 85.000000 (654/768) [6/186]\n",
      "gender_loss: 0.3573073744773865\n",
      "train_loss: 0.357307 | avg_loss: 0.317546 | gender_precise: 85.000000 (765/896) [7/186]\n",
      "gender_loss: 0.30785685777664185\n",
      "train_loss: 0.307857 | avg_loss: 0.316335 | gender_precise: 85.000000 (876/1024) [8/186]\n",
      "gender_loss: 0.34050264954566956\n",
      "train_loss: 0.340503 | avg_loss: 0.319020 | gender_precise: 85.000000 (986/1152) [9/186]\n",
      "gender_loss: 0.3029327690601349\n",
      "train_loss: 0.302933 | avg_loss: 0.317411 | gender_precise: 85.000000 (1096/1280) [10/186]\n",
      "gender_loss: 0.24803346395492554\n",
      "train_loss: 0.248033 | avg_loss: 0.311104 | gender_precise: 86.000000 (1213/1408) [11/186]\n",
      "gender_loss: 0.21734121441841125\n",
      "train_loss: 0.217341 | avg_loss: 0.303291 | gender_precise: 86.000000 (1328/1536) [12/186]\n",
      "gender_loss: 0.27781611680984497\n",
      "train_loss: 0.277816 | avg_loss: 0.301331 | gender_precise: 86.000000 (1440/1664) [13/186]\n",
      "gender_loss: 0.2492862194776535\n",
      "train_loss: 0.249286 | avg_loss: 0.297614 | gender_precise: 86.000000 (1552/1792) [14/186]\n",
      "gender_loss: 0.3622988760471344\n",
      "train_loss: 0.362299 | avg_loss: 0.301926 | gender_precise: 86.000000 (1665/1920) [15/186]\n",
      "gender_loss: 0.22799713909626007\n",
      "train_loss: 0.227997 | avg_loss: 0.297305 | gender_precise: 86.000000 (1781/2048) [16/186]\n",
      "gender_loss: 0.2163114845752716\n",
      "train_loss: 0.216311 | avg_loss: 0.292541 | gender_precise: 86.000000 (1892/2176) [17/186]\n",
      "gender_loss: 0.32910946011543274\n",
      "train_loss: 0.329109 | avg_loss: 0.294573 | gender_precise: 86.000000 (1998/2304) [18/186]\n",
      "gender_loss: 0.34507277607917786\n",
      "train_loss: 0.345073 | avg_loss: 0.297231 | gender_precise: 86.000000 (2109/2432) [19/186]\n",
      "gender_loss: 0.33579039573669434\n",
      "train_loss: 0.335790 | avg_loss: 0.299159 | gender_precise: 86.000000 (2219/2560) [20/186]\n",
      "gender_loss: 0.2273881435394287\n",
      "train_loss: 0.227388 | avg_loss: 0.295741 | gender_precise: 86.000000 (2337/2688) [21/186]\n",
      "gender_loss: 0.30867236852645874\n",
      "train_loss: 0.308672 | avg_loss: 0.296329 | gender_precise: 86.000000 (2446/2816) [22/186]\n",
      "gender_loss: 0.29140445590019226\n",
      "train_loss: 0.291404 | avg_loss: 0.296115 | gender_precise: 86.000000 (2558/2944) [23/186]\n",
      "gender_loss: 0.3097451329231262\n",
      "train_loss: 0.309745 | avg_loss: 0.296683 | gender_precise: 86.000000 (2669/3072) [24/186]\n",
      "gender_loss: 0.28511375188827515\n",
      "train_loss: 0.285114 | avg_loss: 0.296220 | gender_precise: 86.000000 (2781/3200) [25/186]\n",
      "gender_loss: 0.2714885473251343\n",
      "train_loss: 0.271489 | avg_loss: 0.295269 | gender_precise: 86.000000 (2891/3328) [26/186]\n",
      "gender_loss: 0.3783004581928253\n",
      "train_loss: 0.378300 | avg_loss: 0.298344 | gender_precise: 86.000000 (3000/3456) [27/186]\n",
      "gender_loss: 0.28137028217315674\n",
      "train_loss: 0.281370 | avg_loss: 0.297738 | gender_precise: 86.000000 (3111/3584) [28/186]\n",
      "gender_loss: 0.25166940689086914\n",
      "train_loss: 0.251669 | avg_loss: 0.296149 | gender_precise: 86.000000 (3225/3712) [29/186]\n",
      "gender_loss: 0.29823943972587585\n",
      "train_loss: 0.298239 | avg_loss: 0.296219 | gender_precise: 86.000000 (3334/3840) [30/186]\n",
      "gender_loss: 0.31295618414878845\n",
      "train_loss: 0.312956 | avg_loss: 0.296759 | gender_precise: 86.000000 (3445/3968) [31/186]\n",
      "gender_loss: 0.30383825302124023\n",
      "train_loss: 0.303838 | avg_loss: 0.296980 | gender_precise: 86.000000 (3560/4096) [32/186]\n",
      "gender_loss: 0.2828424274921417\n",
      "train_loss: 0.282842 | avg_loss: 0.296552 | gender_precise: 86.000000 (3669/4224) [33/186]\n",
      "gender_loss: 0.3464389443397522\n",
      "train_loss: 0.346439 | avg_loss: 0.298019 | gender_precise: 86.000000 (3778/4352) [34/186]\n",
      "gender_loss: 0.3167199194431305\n",
      "train_loss: 0.316720 | avg_loss: 0.298553 | gender_precise: 86.000000 (3888/4480) [35/186]\n",
      "gender_loss: 0.29132407903671265\n",
      "train_loss: 0.291324 | avg_loss: 0.298352 | gender_precise: 86.000000 (3996/4608) [36/186]\n",
      "gender_loss: 0.2656603157520294\n",
      "train_loss: 0.265660 | avg_loss: 0.297469 | gender_precise: 86.000000 (4106/4736) [37/186]\n",
      "gender_loss: 0.33188942074775696\n",
      "train_loss: 0.331889 | avg_loss: 0.298375 | gender_precise: 86.000000 (4215/4864) [38/186]\n",
      "gender_loss: 0.30907610058784485\n",
      "train_loss: 0.309076 | avg_loss: 0.298649 | gender_precise: 86.000000 (4324/4992) [39/186]\n",
      "gender_loss: 0.39834892749786377\n",
      "train_loss: 0.398349 | avg_loss: 0.301141 | gender_precise: 86.000000 (4432/5120) [40/186]\n",
      "gender_loss: 0.23222698271274567\n",
      "train_loss: 0.232227 | avg_loss: 0.299461 | gender_precise: 86.000000 (4547/5248) [41/186]\n",
      "gender_loss: 0.3338761031627655\n",
      "train_loss: 0.333876 | avg_loss: 0.300280 | gender_precise: 86.000000 (4655/5376) [42/186]\n",
      "gender_loss: 0.3264674246311188\n",
      "train_loss: 0.326467 | avg_loss: 0.300889 | gender_precise: 86.000000 (4760/5504) [43/186]\n",
      "gender_loss: 0.2944476902484894\n",
      "train_loss: 0.294448 | avg_loss: 0.300743 | gender_precise: 86.000000 (4870/5632) [44/186]\n",
      "gender_loss: 0.30915501713752747\n",
      "train_loss: 0.309155 | avg_loss: 0.300930 | gender_precise: 86.000000 (4983/5760) [45/186]\n",
      "gender_loss: 0.2982288897037506\n",
      "train_loss: 0.298229 | avg_loss: 0.300871 | gender_precise: 86.000000 (5094/5888) [46/186]\n",
      "gender_loss: 0.3302999436855316\n",
      "train_loss: 0.330300 | avg_loss: 0.301497 | gender_precise: 86.000000 (5203/6016) [47/186]\n",
      "gender_loss: 0.4018898606300354\n",
      "train_loss: 0.401890 | avg_loss: 0.303589 | gender_precise: 86.000000 (5312/6144) [48/186]\n",
      "gender_loss: 0.44206443428993225\n",
      "train_loss: 0.442064 | avg_loss: 0.306415 | gender_precise: 86.000000 (5412/6272) [49/186]\n",
      "gender_loss: 0.3208377957344055\n",
      "train_loss: 0.320838 | avg_loss: 0.306703 | gender_precise: 86.000000 (5520/6400) [50/186]\n",
      "gender_loss: 0.3800816535949707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.380082 | avg_loss: 0.308142 | gender_precise: 86.000000 (5626/6528) [51/186]\n",
      "gender_loss: 0.23457016050815582\n",
      "train_loss: 0.234570 | avg_loss: 0.306727 | gender_precise: 86.000000 (5741/6656) [52/186]\n",
      "gender_loss: 0.3918714225292206\n",
      "train_loss: 0.391871 | avg_loss: 0.308334 | gender_precise: 86.000000 (5850/6784) [53/186]\n",
      "gender_loss: 0.3059954047203064\n",
      "train_loss: 0.305995 | avg_loss: 0.308290 | gender_precise: 86.000000 (5961/6912) [54/186]\n",
      "gender_loss: 0.25717592239379883\n",
      "train_loss: 0.257176 | avg_loss: 0.307361 | gender_precise: 86.000000 (6074/7040) [55/186]\n",
      "gender_loss: 0.27995750308036804\n",
      "train_loss: 0.279958 | avg_loss: 0.306872 | gender_precise: 86.000000 (6186/7168) [56/186]\n",
      "gender_loss: 0.2967441976070404\n",
      "train_loss: 0.296744 | avg_loss: 0.306694 | gender_precise: 86.000000 (6299/7296) [57/186]\n",
      "gender_loss: 0.289835661649704\n",
      "train_loss: 0.289836 | avg_loss: 0.306403 | gender_precise: 86.000000 (6410/7424) [58/186]\n",
      "gender_loss: 0.3865159749984741\n",
      "train_loss: 0.386516 | avg_loss: 0.307761 | gender_precise: 86.000000 (6518/7552) [59/186]\n",
      "gender_loss: 0.2995930016040802\n",
      "train_loss: 0.299593 | avg_loss: 0.307625 | gender_precise: 86.000000 (6628/7680) [60/186]\n",
      "gender_loss: 0.3154680132865906\n",
      "train_loss: 0.315468 | avg_loss: 0.307753 | gender_precise: 86.000000 (6736/7808) [61/186]\n",
      "gender_loss: 0.28217336535453796\n",
      "train_loss: 0.282173 | avg_loss: 0.307341 | gender_precise: 86.000000 (6851/7936) [62/186]\n",
      "gender_loss: 0.3010973632335663\n",
      "train_loss: 0.301097 | avg_loss: 0.307242 | gender_precise: 86.000000 (6958/8064) [63/186]\n",
      "gender_loss: 0.28723421692848206\n",
      "train_loss: 0.287234 | avg_loss: 0.306929 | gender_precise: 86.000000 (7072/8192) [64/186]\n",
      "gender_loss: 0.18422068655490875\n",
      "train_loss: 0.184221 | avg_loss: 0.305041 | gender_precise: 86.000000 (7190/8320) [65/186]\n",
      "gender_loss: 0.3149265944957733\n",
      "train_loss: 0.314927 | avg_loss: 0.305191 | gender_precise: 86.000000 (7298/8448) [66/186]\n",
      "gender_loss: 0.35134953260421753\n",
      "train_loss: 0.351350 | avg_loss: 0.305880 | gender_precise: 86.000000 (7406/8576) [67/186]\n",
      "gender_loss: 0.31460562348365784\n",
      "train_loss: 0.314606 | avg_loss: 0.306008 | gender_precise: 86.000000 (7518/8704) [68/186]\n",
      "gender_loss: 0.2898918688297272\n",
      "train_loss: 0.289892 | avg_loss: 0.305775 | gender_precise: 86.000000 (7629/8832) [69/186]\n",
      "gender_loss: 0.2810802161693573\n",
      "train_loss: 0.281080 | avg_loss: 0.305422 | gender_precise: 86.000000 (7740/8960) [70/186]\n",
      "gender_loss: 0.3030870258808136\n",
      "train_loss: 0.303087 | avg_loss: 0.305389 | gender_precise: 86.000000 (7850/9088) [71/186]\n",
      "gender_loss: 0.29929813742637634\n",
      "train_loss: 0.299298 | avg_loss: 0.305304 | gender_precise: 86.000000 (7958/9216) [72/186]\n",
      "gender_loss: 0.22408334910869598\n",
      "train_loss: 0.224083 | avg_loss: 0.304192 | gender_precise: 86.000000 (8073/9344) [73/186]\n",
      "gender_loss: 0.3260551393032074\n",
      "train_loss: 0.326055 | avg_loss: 0.304487 | gender_precise: 86.000000 (8182/9472) [74/186]\n",
      "gender_loss: 0.32191091775894165\n",
      "train_loss: 0.321911 | avg_loss: 0.304720 | gender_precise: 86.000000 (8292/9600) [75/186]\n",
      "gender_loss: 0.320266991853714\n",
      "train_loss: 0.320267 | avg_loss: 0.304924 | gender_precise: 86.000000 (8398/9728) [76/186]\n",
      "gender_loss: 0.34333181381225586\n",
      "train_loss: 0.343332 | avg_loss: 0.305423 | gender_precise: 86.000000 (8511/9856) [77/186]\n",
      "gender_loss: 0.29620790481567383\n",
      "train_loss: 0.296208 | avg_loss: 0.305305 | gender_precise: 86.000000 (8624/9984) [78/186]\n",
      "gender_loss: 0.2732866406440735\n",
      "train_loss: 0.273287 | avg_loss: 0.304900 | gender_precise: 86.000000 (8741/10112) [79/186]\n",
      "gender_loss: 0.22897282242774963\n",
      "train_loss: 0.228973 | avg_loss: 0.303951 | gender_precise: 86.000000 (8853/10240) [80/186]\n",
      "gender_loss: 0.30324697494506836\n",
      "train_loss: 0.303247 | avg_loss: 0.303942 | gender_precise: 86.000000 (8965/10368) [81/186]\n",
      "gender_loss: 0.23284316062927246\n",
      "train_loss: 0.232843 | avg_loss: 0.303075 | gender_precise: 86.000000 (9080/10496) [82/186]\n",
      "gender_loss: 0.22636669874191284\n",
      "train_loss: 0.226367 | avg_loss: 0.302151 | gender_precise: 86.000000 (9195/10624) [83/186]\n",
      "gender_loss: 0.30111703276634216\n",
      "train_loss: 0.301117 | avg_loss: 0.302138 | gender_precise: 86.000000 (9309/10752) [84/186]\n",
      "gender_loss: 0.18857775628566742\n",
      "train_loss: 0.188578 | avg_loss: 0.300802 | gender_precise: 86.000000 (9425/10880) [85/186]\n",
      "gender_loss: 0.26768893003463745\n",
      "train_loss: 0.267689 | avg_loss: 0.300417 | gender_precise: 86.000000 (9539/11008) [86/186]\n",
      "gender_loss: 0.22646796703338623\n",
      "train_loss: 0.226468 | avg_loss: 0.299567 | gender_precise: 86.000000 (9657/11136) [87/186]\n",
      "gender_loss: 0.27241796255111694\n",
      "train_loss: 0.272418 | avg_loss: 0.299259 | gender_precise: 86.000000 (9770/11264) [88/186]\n",
      "gender_loss: 0.27740931510925293\n",
      "train_loss: 0.277409 | avg_loss: 0.299013 | gender_precise: 86.000000 (9882/11392) [89/186]\n",
      "gender_loss: 0.18310846388339996\n",
      "train_loss: 0.183108 | avg_loss: 0.297725 | gender_precise: 86.000000 (10001/11520) [90/186]\n",
      "gender_loss: 0.35748887062072754\n",
      "train_loss: 0.357489 | avg_loss: 0.298382 | gender_precise: 86.000000 (10110/11648) [91/186]\n",
      "gender_loss: 0.2893165051937103\n",
      "train_loss: 0.289317 | avg_loss: 0.298284 | gender_precise: 86.000000 (10224/11776) [92/186]\n",
      "gender_loss: 0.3233794569969177\n",
      "train_loss: 0.323379 | avg_loss: 0.298553 | gender_precise: 86.000000 (10341/11904) [93/186]\n",
      "gender_loss: 0.22230355441570282\n",
      "train_loss: 0.222304 | avg_loss: 0.297742 | gender_precise: 86.000000 (10458/12032) [94/186]\n",
      "gender_loss: 0.35727399587631226\n",
      "train_loss: 0.357274 | avg_loss: 0.298369 | gender_precise: 86.000000 (10567/12160) [95/186]\n",
      "gender_loss: 0.33139950037002563\n",
      "train_loss: 0.331400 | avg_loss: 0.298713 | gender_precise: 86.000000 (10678/12288) [96/186]\n",
      "gender_loss: 0.2958970069885254\n",
      "train_loss: 0.295897 | avg_loss: 0.298684 | gender_precise: 86.000000 (10789/12416) [97/186]\n",
      "gender_loss: 0.32774606347084045\n",
      "train_loss: 0.327746 | avg_loss: 0.298980 | gender_precise: 86.000000 (10896/12544) [98/186]\n",
      "gender_loss: 0.2682783603668213\n",
      "train_loss: 0.268278 | avg_loss: 0.298670 | gender_precise: 86.000000 (11007/12672) [99/186]\n",
      "gender_loss: 0.30570149421691895\n",
      "train_loss: 0.305701 | avg_loss: 0.298741 | gender_precise: 86.000000 (11114/12800) [100/186]\n",
      "gender_loss: 0.3294186294078827\n",
      "train_loss: 0.329419 | avg_loss: 0.299044 | gender_precise: 86.000000 (11219/12928) [101/186]\n",
      "gender_loss: 0.26240313053131104\n",
      "train_loss: 0.262403 | avg_loss: 0.298685 | gender_precise: 86.000000 (11329/13056) [102/186]\n",
      "gender_loss: 0.37468141317367554\n",
      "train_loss: 0.374681 | avg_loss: 0.299423 | gender_precise: 86.000000 (11438/13184) [103/186]\n",
      "gender_loss: 0.2595771253108978\n",
      "train_loss: 0.259577 | avg_loss: 0.299040 | gender_precise: 86.000000 (11554/13312) [104/186]\n",
      "gender_loss: 0.24406306445598602\n",
      "train_loss: 0.244063 | avg_loss: 0.298516 | gender_precise: 86.000000 (11669/13440) [105/186]\n",
      "gender_loss: 0.28416818380355835\n",
      "train_loss: 0.284168 | avg_loss: 0.298381 | gender_precise: 86.000000 (11780/13568) [106/186]\n",
      "gender_loss: 0.26915332674980164\n",
      "train_loss: 0.269153 | avg_loss: 0.298108 | gender_precise: 86.000000 (11893/13696) [107/186]\n",
      "gender_loss: 0.22139085829257965\n",
      "train_loss: 0.221391 | avg_loss: 0.297397 | gender_precise: 86.000000 (12008/13824) [108/186]\n",
      "gender_loss: 0.19481423497200012\n",
      "train_loss: 0.194814 | avg_loss: 0.296456 | gender_precise: 86.000000 (12128/13952) [109/186]\n",
      "gender_loss: 0.30065518617630005\n",
      "train_loss: 0.300655 | avg_loss: 0.296494 | gender_precise: 86.000000 (12238/14080) [110/186]\n",
      "gender_loss: 0.2879253625869751\n",
      "train_loss: 0.287925 | avg_loss: 0.296417 | gender_precise: 86.000000 (12349/14208) [111/186]\n",
      "gender_loss: 0.2833702266216278\n",
      "train_loss: 0.283370 | avg_loss: 0.296301 | gender_precise: 86.000000 (12457/14336) [112/186]\n",
      "gender_loss: 0.4447038769721985\n",
      "train_loss: 0.444704 | avg_loss: 0.297614 | gender_precise: 86.000000 (12558/14464) [113/186]\n",
      "gender_loss: 0.3248208165168762\n",
      "train_loss: 0.324821 | avg_loss: 0.297853 | gender_precise: 86.000000 (12668/14592) [114/186]\n",
      "gender_loss: 0.225730761885643\n",
      "train_loss: 0.225731 | avg_loss: 0.297226 | gender_precise: 86.000000 (12785/14720) [115/186]\n",
      "gender_loss: 0.252141535282135\n",
      "train_loss: 0.252142 | avg_loss: 0.296837 | gender_precise: 86.000000 (12900/14848) [116/186]\n",
      "gender_loss: 0.2357919067144394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.235792 | avg_loss: 0.296315 | gender_precise: 86.000000 (13014/14976) [117/186]\n",
      "gender_loss: 0.26432210206985474\n",
      "train_loss: 0.264322 | avg_loss: 0.296044 | gender_precise: 86.000000 (13126/15104) [118/186]\n",
      "gender_loss: 0.23833227157592773\n",
      "train_loss: 0.238332 | avg_loss: 0.295559 | gender_precise: 86.000000 (13240/15232) [119/186]\n",
      "gender_loss: 0.32182577252388\n",
      "train_loss: 0.321826 | avg_loss: 0.295778 | gender_precise: 86.000000 (13348/15360) [120/186]\n",
      "gender_loss: 0.30718323588371277\n",
      "train_loss: 0.307183 | avg_loss: 0.295872 | gender_precise: 86.000000 (13457/15488) [121/186]\n",
      "gender_loss: 0.3066820800304413\n",
      "train_loss: 0.306682 | avg_loss: 0.295961 | gender_precise: 86.000000 (13570/15616) [122/186]\n",
      "gender_loss: 0.34138813614845276\n",
      "train_loss: 0.341388 | avg_loss: 0.296330 | gender_precise: 86.000000 (13679/15744) [123/186]\n",
      "gender_loss: 0.2611689269542694\n",
      "train_loss: 0.261169 | avg_loss: 0.296047 | gender_precise: 86.000000 (13790/15872) [124/186]\n",
      "gender_loss: 0.3410722613334656\n",
      "train_loss: 0.341072 | avg_loss: 0.296407 | gender_precise: 86.000000 (13899/16000) [125/186]\n",
      "gender_loss: 0.3640468120574951\n",
      "train_loss: 0.364047 | avg_loss: 0.296944 | gender_precise: 86.000000 (14007/16128) [126/186]\n",
      "gender_loss: 0.23061306774616241\n",
      "train_loss: 0.230613 | avg_loss: 0.296421 | gender_precise: 86.000000 (14124/16256) [127/186]\n",
      "gender_loss: 0.24844440817832947\n",
      "train_loss: 0.248444 | avg_loss: 0.296046 | gender_precise: 86.000000 (14236/16384) [128/186]\n",
      "gender_loss: 0.30284565687179565\n",
      "train_loss: 0.302846 | avg_loss: 0.296099 | gender_precise: 86.000000 (14348/16512) [129/186]\n",
      "gender_loss: 0.23788709938526154\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, start_epoch+10):\n",
    "    print(\"Number epoch: {}\".format(epoch))\n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
