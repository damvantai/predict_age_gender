{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from cnn_finetune import make_model\n",
    "\n",
    "from net import AGNet\n",
    "from loss import AGLoss\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from datagen import ListDataset\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "test_batch_size = 64\n",
    "epochs = 50\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "dropout = 0.3\n",
    "start_epoch = 0\n",
    "best_correct = 0\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.CenterCrop(150),\n",
    "    transforms.RandomCrop(150, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485,0.456,0.406), (0.229,0.224,0.225)\n",
    "    )\n",
    "])\n",
    "trainset = ListDataset(root='../data/UTKFace/', transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=8)\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.CenterCrop(150),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485,0.456,0.406), (0.229,0.224,0.225))\n",
    "])\n",
    "testset = ListDataset(root='../data/test/', transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = AGNet()\n",
    "net.cuda()\n",
    "criterion = AGLoss()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def accuracy(age_preds, age_targets, gender_preds, gender_targets):\n",
    "def accuracy(gender_preds, gender_targets):\n",
    "\n",
    "#     AGE_TOLERANCE = 3\n",
    "#     age_prob = F.softmax(age_preds)\n",
    "#     age_expect = torch.sum(Variable(torch.arange(1, 117)).cuda() * age_prob, 1)\n",
    "    \n",
    "#     age_correct = ((age_expect - age_targets.float()).abs() < AGE_TOLERANCE).int().sum().cpu().data[0]\n",
    "    \n",
    "    gender_preds = F.sigmoid(gender_preds)\n",
    "    gender_preds = (gender_preds > 0.5).int()\n",
    "    gender_correct = (gender_preds == gender_targets.int()).int().cpu().sum().data[0]\n",
    "    return gender_correct\n",
    "#     return age_correct, gender_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    total = 0\n",
    "    age_correct = 0\n",
    "    gender_correct = 0\n",
    "    for batch_idx, (inputs, age_targets, gender_targets) in enumerate(trainloader):\n",
    "        inputs = Variable(inputs.cuda())\n",
    "        age_targets = Variable(age_targets.cuda())\n",
    "        gender_targets = Variable(gender_targets.cuda())\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # \n",
    "        age_preds, gender_preds = net(inputs)\n",
    "        loss = criterion(gender_preds, gender_targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.data[0]\n",
    "        \n",
    "#         age_correct_i, gender_correct_i = accuracy(age_preds,\n",
    "#                                                   age_targets, gender_preds,\n",
    "#                                                   gender_targets)\n",
    "        gender_correct_i = accuracy(gender_preds, gender_targets)\n",
    "#         age_correct += age_correct_i\n",
    "        gender_correct += gender_correct_i\n",
    "        total += len(inputs)\n",
    "        print('train_loss: %f | avg_loss: %f | gender_precise: %f (%d/%d) [%d/%d]'\n",
    "             % (loss.data[0], train_loss/(batch_idx+1),\n",
    "               100.*gender_correct/total, gender_correct, total,\n",
    "               batch_idx+1, len(trainloader)))\n",
    "#         print('train_loss: %.3f | avg_loss: %.3f | age_prec: %.3f (%d/%d) | gender_prec: %.3f (%d/%d)  [%d/%d]'  \\\n",
    "#             % (loss.data[0], train_loss/(batch_idx+1),      \\\n",
    "#                100.*age_correct/total, age_correct, total,  \\\n",
    "#                100.*gender_correct/total, gender_correct, total,    \\\n",
    "#                batch_idx+1, len(trainloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "def test(epoch):\n",
    "    print('\\nTest')\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    total = 0\n",
    "    age_correct = 0\n",
    "    gender_correct = 0\n",
    "    for batch_idx, (inputs, age_targets, gender_targets) in enumerate(testloader):\n",
    "        inputs = Variable(inputs.cuda())\n",
    "        age_targets = Variable(age_targets.cuda())\n",
    "        gender_targets = Variable(gender_targets.cuda())\n",
    "\n",
    "#         age_preds, gender_preds = net(inputs)\n",
    "        age_preds, gender_preds = net(inputs)\n",
    "#         loss = criterion(age_preds, age_targets, gender_preds, gender_targets)\n",
    "#         loss = criterion(gender_preds, gender_targets)\n",
    "\n",
    "#         test_loss += loss.data[0]\n",
    "        gender_correct_i = accuracy(gender_preds, gender_targets)\n",
    "#         age_correct_i, gender_correct_i = accuracy(\n",
    "#             age_preds, age_targets, gender_preds, gender_targets)\n",
    "#         age_correct += age_correct_i\n",
    "        gender_correct += gender_correct_i\n",
    "        total += len(inputs)\n",
    "        print('gender_prec: %f (%d/%d) [%d/%d]' % (100.*gender_correct/total, gender_correct, total, batch_idx+1, len(testloader)))\n",
    "#         print('test_loss: %f | avg_loss: %f | age_prec: %f (%d/%d) | gender_prec: %f (%d/%d)  [%d/%d]' \\\n",
    "#             % (loss.data[0], test_loss/(batch_idx+1),      \\\n",
    "#                100.*age_correct/total, age_correct, total,  \\\n",
    "#                100.*gender_correct/total, gender_correct, total, \\\n",
    "#                batch_idx+1, len(trainloader)))\n",
    "\n",
    "    # Save checkpoint\n",
    "    global best_correct\n",
    "#     if age_correct + gender_correct > best_correct:\n",
    "    if gender_correct > best_correct:\n",
    "        print('Saving..')\n",
    "        best_correct = gender_correct\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'correct': best_correct,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('../weights/checkpoint'):\n",
    "            os.mkdir('../weights/checkpoint')\n",
    "        torch.save(state, '..weights/checkpoint/ckpt.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neosai/Documents/projects/predict_age_gender/src/loss.py:19: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  print(\"gender_loss: {}\".format(gender_loss.data[0]))\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender_loss: 0.6942108273506165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.694211 | avg_loss: 0.694211 | gender_precise: 39.000000 (50/128) [1/186]\n",
      "gender_loss: 0.6932098269462585\n",
      "train_loss: 0.693210 | avg_loss: 0.693710 | gender_precise: 44.000000 (113/256) [2/186]\n",
      "gender_loss: 0.6929138898849487\n",
      "train_loss: 0.692914 | avg_loss: 0.693445 | gender_precise: 47.000000 (181/384) [3/186]\n",
      "gender_loss: 0.6931552290916443\n",
      "train_loss: 0.693155 | avg_loss: 0.693372 | gender_precise: 47.000000 (245/512) [4/186]\n",
      "gender_loss: 0.6931732296943665\n",
      "train_loss: 0.693173 | avg_loss: 0.693333 | gender_precise: 48.000000 (308/640) [5/186]\n",
      "gender_loss: 0.6933927536010742\n",
      "train_loss: 0.693393 | avg_loss: 0.693343 | gender_precise: 47.000000 (364/768) [6/186]\n",
      "gender_loss: 0.6932075023651123\n",
      "train_loss: 0.693208 | avg_loss: 0.693323 | gender_precise: 47.000000 (424/896) [7/186]\n",
      "gender_loss: 0.693169116973877\n",
      "train_loss: 0.693169 | avg_loss: 0.693304 | gender_precise: 47.000000 (483/1024) [8/186]\n",
      "gender_loss: 0.693134605884552\n",
      "train_loss: 0.693135 | avg_loss: 0.693285 | gender_precise: 47.000000 (547/1152) [9/186]\n",
      "gender_loss: 0.6931548118591309\n",
      "train_loss: 0.693155 | avg_loss: 0.693272 | gender_precise: 47.000000 (610/1280) [10/186]\n",
      "gender_loss: 0.692495584487915\n",
      "train_loss: 0.692496 | avg_loss: 0.693202 | gender_precise: 48.000000 (686/1408) [11/186]\n",
      "gender_loss: 0.6921485662460327\n",
      "train_loss: 0.692149 | avg_loss: 0.693114 | gender_precise: 49.000000 (763/1536) [12/186]\n",
      "gender_loss: 0.6935804486274719\n",
      "train_loss: 0.693580 | avg_loss: 0.693150 | gender_precise: 49.000000 (823/1664) [13/186]\n",
      "gender_loss: 0.693985641002655\n",
      "train_loss: 0.693986 | avg_loss: 0.693210 | gender_precise: 49.000000 (881/1792) [14/186]\n",
      "gender_loss: 0.6934849619865417\n",
      "train_loss: 0.693485 | avg_loss: 0.693228 | gender_precise: 49.000000 (943/1920) [15/186]\n",
      "gender_loss: 0.6948617100715637\n",
      "train_loss: 0.694862 | avg_loss: 0.693330 | gender_precise: 48.000000 (997/2048) [16/186]\n",
      "gender_loss: 0.693011999130249\n",
      "train_loss: 0.693012 | avg_loss: 0.693311 | gender_precise: 48.000000 (1062/2176) [17/186]\n",
      "gender_loss: 0.6928268671035767\n",
      "train_loss: 0.692827 | avg_loss: 0.693284 | gender_precise: 48.000000 (1128/2304) [18/186]\n",
      "gender_loss: 0.6930001974105835\n",
      "train_loss: 0.693000 | avg_loss: 0.693269 | gender_precise: 49.000000 (1193/2432) [19/186]\n",
      "gender_loss: 0.6932118535041809\n",
      "train_loss: 0.693212 | avg_loss: 0.693267 | gender_precise: 49.000000 (1257/2560) [20/186]\n",
      "gender_loss: 0.6926469206809998\n",
      "train_loss: 0.692647 | avg_loss: 0.693237 | gender_precise: 49.000000 (1324/2688) [21/186]\n",
      "gender_loss: 0.6909627914428711\n",
      "train_loss: 0.690963 | avg_loss: 0.693134 | gender_precise: 49.000000 (1400/2816) [22/186]\n",
      "gender_loss: 0.6932128071784973\n",
      "train_loss: 0.693213 | avg_loss: 0.693137 | gender_precise: 49.000000 (1464/2944) [23/186]\n",
      "gender_loss: 0.6919600963592529\n",
      "train_loss: 0.691960 | avg_loss: 0.693088 | gender_precise: 49.000000 (1534/3072) [24/186]\n",
      "gender_loss: 0.6923153400421143\n",
      "train_loss: 0.692315 | avg_loss: 0.693057 | gender_precise: 50.000000 (1602/3200) [25/186]\n",
      "gender_loss: 0.6922876238822937\n",
      "train_loss: 0.692288 | avg_loss: 0.693028 | gender_precise: 50.000000 (1670/3328) [26/186]\n",
      "gender_loss: 0.6908829212188721\n",
      "train_loss: 0.690883 | avg_loss: 0.692948 | gender_precise: 50.000000 (1743/3456) [27/186]\n",
      "gender_loss: 0.6916224360466003\n",
      "train_loss: 0.691622 | avg_loss: 0.692901 | gender_precise: 50.000000 (1813/3584) [28/186]\n",
      "gender_loss: 0.6939062476158142\n",
      "train_loss: 0.693906 | avg_loss: 0.692935 | gender_precise: 50.000000 (1875/3712) [29/186]\n",
      "gender_loss: 0.6913854479789734\n",
      "train_loss: 0.691385 | avg_loss: 0.692884 | gender_precise: 50.000000 (1945/3840) [30/186]\n",
      "gender_loss: 0.6882076859474182\n",
      "train_loss: 0.688208 | avg_loss: 0.692733 | gender_precise: 51.000000 (2024/3968) [31/186]\n",
      "gender_loss: 0.6926563382148743\n",
      "train_loss: 0.692656 | avg_loss: 0.692731 | gender_precise: 51.000000 (2090/4096) [32/186]\n",
      "gender_loss: 0.6898565888404846\n",
      "train_loss: 0.689857 | avg_loss: 0.692644 | gender_precise: 51.000000 (2163/4224) [33/186]\n",
      "gender_loss: 0.6909288167953491\n",
      "train_loss: 0.690929 | avg_loss: 0.692593 | gender_precise: 51.000000 (2233/4352) [34/186]\n",
      "gender_loss: 0.6931052803993225\n",
      "train_loss: 0.693105 | avg_loss: 0.692608 | gender_precise: 51.000000 (2298/4480) [35/186]\n",
      "gender_loss: 0.6951308846473694\n",
      "train_loss: 0.695131 | avg_loss: 0.692678 | gender_precise: 51.000000 (2359/4608) [36/186]\n",
      "gender_loss: 0.6869964003562927\n",
      "train_loss: 0.686996 | avg_loss: 0.692524 | gender_precise: 51.000000 (2436/4736) [37/186]\n",
      "gender_loss: 0.69590163230896\n",
      "train_loss: 0.695902 | avg_loss: 0.692613 | gender_precise: 51.000000 (2496/4864) [38/186]\n",
      "gender_loss: 0.6898568868637085\n",
      "train_loss: 0.689857 | avg_loss: 0.692542 | gender_precise: 51.000000 (2567/4992) [39/186]\n",
      "gender_loss: 0.6891555786132812\n",
      "train_loss: 0.689156 | avg_loss: 0.692458 | gender_precise: 51.000000 (2639/5120) [40/186]\n",
      "gender_loss: 0.6926602721214294\n",
      "train_loss: 0.692660 | avg_loss: 0.692463 | gender_precise: 51.000000 (2705/5248) [41/186]\n",
      "gender_loss: 0.6920579075813293\n",
      "train_loss: 0.692058 | avg_loss: 0.692453 | gender_precise: 51.000000 (2772/5376) [42/186]\n",
      "gender_loss: 0.6913461089134216\n",
      "train_loss: 0.691346 | avg_loss: 0.692427 | gender_precise: 51.000000 (2840/5504) [43/186]\n",
      "gender_loss: 0.6926807165145874\n",
      "train_loss: 0.692681 | avg_loss: 0.692433 | gender_precise: 51.000000 (2906/5632) [44/186]\n",
      "gender_loss: 0.6913365721702576\n",
      "train_loss: 0.691337 | avg_loss: 0.692409 | gender_precise: 51.000000 (2974/5760) [45/186]\n",
      "gender_loss: 0.6941279172897339\n",
      "train_loss: 0.694128 | avg_loss: 0.692446 | gender_precise: 51.000000 (3038/5888) [46/186]\n",
      "gender_loss: 0.6970198750495911\n",
      "train_loss: 0.697020 | avg_loss: 0.692543 | gender_precise: 51.000000 (3098/6016) [47/186]\n",
      "gender_loss: 0.6905726194381714\n",
      "train_loss: 0.690573 | avg_loss: 0.692502 | gender_precise: 51.000000 (3167/6144) [48/186]\n",
      "gender_loss: 0.6912891864776611\n",
      "train_loss: 0.691289 | avg_loss: 0.692478 | gender_precise: 51.000000 (3235/6272) [49/186]\n",
      "gender_loss: 0.6861827373504639\n",
      "train_loss: 0.686183 | avg_loss: 0.692352 | gender_precise: 51.000000 (3310/6400) [50/186]\n",
      "gender_loss: 0.6920019388198853\n",
      "train_loss: 0.692002 | avg_loss: 0.692345 | gender_precise: 51.000000 (3377/6528) [51/186]\n",
      "gender_loss: 0.6912769675254822\n",
      "train_loss: 0.691277 | avg_loss: 0.692324 | gender_precise: 51.000000 (3445/6656) [52/186]\n",
      "gender_loss: 0.6874322295188904\n",
      "train_loss: 0.687432 | avg_loss: 0.692232 | gender_precise: 51.000000 (3518/6784) [53/186]\n",
      "gender_loss: 0.6865911483764648\n",
      "train_loss: 0.686591 | avg_loss: 0.692128 | gender_precise: 51.000000 (3592/6912) [54/186]\n",
      "gender_loss: 0.6896644830703735\n",
      "train_loss: 0.689664 | avg_loss: 0.692083 | gender_precise: 52.000000 (3662/7040) [55/186]\n",
      "gender_loss: 0.6953095197677612\n",
      "train_loss: 0.695310 | avg_loss: 0.692140 | gender_precise: 51.000000 (3725/7168) [56/186]\n",
      "gender_loss: 0.6953524351119995\n",
      "train_loss: 0.695352 | avg_loss: 0.692197 | gender_precise: 51.000000 (3788/7296) [57/186]\n",
      "gender_loss: 0.6870282888412476\n",
      "train_loss: 0.687028 | avg_loss: 0.692107 | gender_precise: 52.000000 (3861/7424) [58/186]\n",
      "gender_loss: 0.689500093460083\n",
      "train_loss: 0.689500 | avg_loss: 0.692063 | gender_precise: 52.000000 (3931/7552) [59/186]\n",
      "gender_loss: 0.6911978125572205\n",
      "train_loss: 0.691198 | avg_loss: 0.692049 | gender_precise: 52.000000 (3999/7680) [60/186]\n",
      "gender_loss: 0.6894174218177795\n",
      "train_loss: 0.689417 | avg_loss: 0.692006 | gender_precise: 52.000000 (4069/7808) [61/186]\n",
      "gender_loss: 0.6813248991966248\n",
      "train_loss: 0.681325 | avg_loss: 0.691833 | gender_precise: 52.000000 (4148/7936) [62/186]\n",
      "gender_loss: 0.6984661817550659\n",
      "train_loss: 0.698466 | avg_loss: 0.691939 | gender_precise: 52.000000 (4208/8064) [63/186]\n",
      "gender_loss: 0.6893345713615417\n",
      "train_loss: 0.689335 | avg_loss: 0.691898 | gender_precise: 52.000000 (4278/8192) [64/186]\n",
      "gender_loss: 0.6968132257461548\n",
      "train_loss: 0.696813 | avg_loss: 0.691974 | gender_precise: 52.000000 (4340/8320) [65/186]\n",
      "gender_loss: 0.6892889738082886\n",
      "train_loss: 0.689289 | avg_loss: 0.691933 | gender_precise: 52.000000 (4410/8448) [66/186]\n",
      "gender_loss: 0.6978164315223694\n",
      "train_loss: 0.697816 | avg_loss: 0.692021 | gender_precise: 52.000000 (4471/8576) [67/186]\n",
      "gender_loss: 0.6940402984619141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.694040 | avg_loss: 0.692051 | gender_precise: 52.000000 (4536/8704) [68/186]\n",
      "gender_loss: 0.6959288120269775\n",
      "train_loss: 0.695929 | avg_loss: 0.692107 | gender_precise: 52.000000 (4599/8832) [69/186]\n",
      "gender_loss: 0.6902096271514893\n",
      "train_loss: 0.690210 | avg_loss: 0.692080 | gender_precise: 52.000000 (4668/8960) [70/186]\n",
      "gender_loss: 0.6978049278259277\n",
      "train_loss: 0.697805 | avg_loss: 0.692160 | gender_precise: 52.000000 (4729/9088) [71/186]\n",
      "gender_loss: 0.6846057772636414\n",
      "train_loss: 0.684606 | avg_loss: 0.692055 | gender_precise: 52.000000 (4804/9216) [72/186]\n",
      "gender_loss: 0.6855738759040833\n",
      "train_loss: 0.685574 | avg_loss: 0.691966 | gender_precise: 52.000000 (4878/9344) [73/186]\n",
      "gender_loss: 0.6949324011802673\n",
      "train_loss: 0.694932 | avg_loss: 0.692007 | gender_precise: 52.000000 (4942/9472) [74/186]\n",
      "gender_loss: 0.6930127143859863\n",
      "train_loss: 0.693013 | avg_loss: 0.692020 | gender_precise: 52.000000 (5008/9600) [75/186]\n",
      "gender_loss: 0.695817232131958\n",
      "train_loss: 0.695817 | avg_loss: 0.692070 | gender_precise: 52.000000 (5071/9728) [76/186]\n",
      "gender_loss: 0.701389491558075\n",
      "train_loss: 0.701389 | avg_loss: 0.692191 | gender_precise: 52.000000 (5128/9856) [77/186]\n",
      "gender_loss: 0.6975230574607849\n",
      "train_loss: 0.697523 | avg_loss: 0.692259 | gender_precise: 51.000000 (5189/9984) [78/186]\n",
      "gender_loss: 0.6884902715682983\n",
      "train_loss: 0.688490 | avg_loss: 0.692212 | gender_precise: 52.000000 (5260/10112) [79/186]\n",
      "gender_loss: 0.6973124742507935\n",
      "train_loss: 0.697312 | avg_loss: 0.692275 | gender_precise: 51.000000 (5321/10240) [80/186]\n",
      "gender_loss: 0.6963902115821838\n",
      "train_loss: 0.696390 | avg_loss: 0.692326 | gender_precise: 51.000000 (5383/10368) [81/186]\n",
      "gender_loss: 0.693707287311554\n",
      "train_loss: 0.693707 | avg_loss: 0.692343 | gender_precise: 51.000000 (5448/10496) [82/186]\n",
      "gender_loss: 0.696885347366333\n",
      "train_loss: 0.696885 | avg_loss: 0.692398 | gender_precise: 51.000000 (5509/10624) [83/186]\n",
      "gender_loss: 0.6943822503089905\n",
      "train_loss: 0.694382 | avg_loss: 0.692421 | gender_precise: 51.000000 (5573/10752) [84/186]\n",
      "gender_loss: 0.6874196529388428\n",
      "train_loss: 0.687420 | avg_loss: 0.692362 | gender_precise: 51.000000 (5646/10880) [85/186]\n",
      "gender_loss: 0.6927955746650696\n",
      "train_loss: 0.692796 | avg_loss: 0.692367 | gender_precise: 51.000000 (5712/11008) [86/186]\n",
      "gender_loss: 0.6986211538314819\n",
      "train_loss: 0.698621 | avg_loss: 0.692439 | gender_precise: 51.000000 (5770/11136) [87/186]\n",
      "gender_loss: 0.6848844289779663\n",
      "train_loss: 0.684884 | avg_loss: 0.692354 | gender_precise: 51.000000 (5847/11264) [88/186]\n",
      "gender_loss: 0.6898968815803528\n",
      "train_loss: 0.689897 | avg_loss: 0.692326 | gender_precise: 51.000000 (5917/11392) [89/186]\n",
      "gender_loss: 0.6968916058540344\n",
      "train_loss: 0.696892 | avg_loss: 0.692377 | gender_precise: 51.000000 (5977/11520) [90/186]\n",
      "gender_loss: 0.6893022060394287\n",
      "train_loss: 0.689302 | avg_loss: 0.692343 | gender_precise: 51.000000 (6048/11648) [91/186]\n",
      "gender_loss: 0.6893347501754761\n",
      "train_loss: 0.689335 | avg_loss: 0.692310 | gender_precise: 51.000000 (6119/11776) [92/186]\n",
      "gender_loss: 0.6940262913703918\n",
      "train_loss: 0.694026 | avg_loss: 0.692329 | gender_precise: 51.000000 (6183/11904) [93/186]\n",
      "gender_loss: 0.6973152756690979\n",
      "train_loss: 0.697315 | avg_loss: 0.692382 | gender_precise: 51.000000 (6242/12032) [94/186]\n",
      "gender_loss: 0.6926615834236145\n",
      "train_loss: 0.692662 | avg_loss: 0.692385 | gender_precise: 51.000000 (6308/12160) [95/186]\n",
      "gender_loss: 0.6862205266952515\n",
      "train_loss: 0.686221 | avg_loss: 0.692320 | gender_precise: 51.000000 (6384/12288) [96/186]\n",
      "gender_loss: 0.6901203989982605\n",
      "train_loss: 0.690120 | avg_loss: 0.692298 | gender_precise: 51.000000 (6454/12416) [97/186]\n",
      "gender_loss: 0.6938599944114685\n",
      "train_loss: 0.693860 | avg_loss: 0.692314 | gender_precise: 51.000000 (6518/12544) [98/186]\n",
      "gender_loss: 0.6971217393875122\n",
      "train_loss: 0.697122 | avg_loss: 0.692362 | gender_precise: 51.000000 (6577/12672) [99/186]\n",
      "gender_loss: 0.6945739984512329\n",
      "train_loss: 0.694574 | avg_loss: 0.692384 | gender_precise: 51.000000 (6640/12800) [100/186]\n",
      "gender_loss: 0.6839596629142761\n",
      "train_loss: 0.683960 | avg_loss: 0.692301 | gender_precise: 51.000000 (6720/12928) [101/186]\n",
      "gender_loss: 0.6932722926139832\n",
      "train_loss: 0.693272 | avg_loss: 0.692311 | gender_precise: 51.000000 (6785/13056) [102/186]\n",
      "gender_loss: 0.6907403469085693\n",
      "train_loss: 0.690740 | avg_loss: 0.692295 | gender_precise: 51.000000 (6854/13184) [103/186]\n",
      "gender_loss: 0.6945642232894897\n",
      "train_loss: 0.694564 | avg_loss: 0.692317 | gender_precise: 51.000000 (6917/13312) [104/186]\n",
      "gender_loss: 0.6907415390014648\n",
      "train_loss: 0.690742 | avg_loss: 0.692302 | gender_precise: 51.000000 (6986/13440) [105/186]\n",
      "gender_loss: 0.6945680379867554\n",
      "train_loss: 0.694568 | avg_loss: 0.692323 | gender_precise: 51.000000 (7049/13568) [106/186]\n",
      "gender_loss: 0.6995711326599121\n",
      "train_loss: 0.699571 | avg_loss: 0.692391 | gender_precise: 51.000000 (7104/13696) [107/186]\n",
      "gender_loss: 0.6895729899406433\n",
      "train_loss: 0.689573 | avg_loss: 0.692365 | gender_precise: 51.000000 (7175/13824) [108/186]\n",
      "gender_loss: 0.6907704472541809\n",
      "train_loss: 0.690770 | avg_loss: 0.692350 | gender_precise: 51.000000 (7244/13952) [109/186]\n",
      "gender_loss: 0.6920053362846375\n",
      "train_loss: 0.692005 | avg_loss: 0.692347 | gender_precise: 51.000000 (7311/14080) [110/186]\n",
      "gender_loss: 0.6919679641723633\n",
      "train_loss: 0.691968 | avg_loss: 0.692344 | gender_precise: 51.000000 (7378/14208) [111/186]\n",
      "gender_loss: 0.6932439208030701\n",
      "train_loss: 0.693244 | avg_loss: 0.692352 | gender_precise: 51.000000 (7443/14336) [112/186]\n",
      "gender_loss: 0.6968117356300354\n",
      "train_loss: 0.696812 | avg_loss: 0.692392 | gender_precise: 51.000000 (7502/14464) [113/186]\n",
      "gender_loss: 0.6890952587127686\n",
      "train_loss: 0.689095 | avg_loss: 0.692363 | gender_precise: 51.000000 (7574/14592) [114/186]\n",
      "gender_loss: 0.6873335838317871\n",
      "train_loss: 0.687334 | avg_loss: 0.692319 | gender_precise: 51.000000 (7649/14720) [115/186]\n",
      "gender_loss: 0.6943804621696472\n",
      "train_loss: 0.694380 | avg_loss: 0.692337 | gender_precise: 51.000000 (7712/14848) [116/186]\n",
      "gender_loss: 0.6966915726661682\n",
      "train_loss: 0.696692 | avg_loss: 0.692374 | gender_precise: 51.000000 (7771/14976) [117/186]\n",
      "gender_loss: 0.6955347657203674\n",
      "train_loss: 0.695535 | avg_loss: 0.692401 | gender_precise: 51.000000 (7832/15104) [118/186]\n",
      "gender_loss: 0.6903378963470459\n",
      "train_loss: 0.690338 | avg_loss: 0.692383 | gender_precise: 51.000000 (7902/15232) [119/186]\n",
      "gender_loss: 0.6914296746253967\n",
      "train_loss: 0.691430 | avg_loss: 0.692375 | gender_precise: 51.000000 (7970/15360) [120/186]\n",
      "gender_loss: 0.6932363510131836\n",
      "train_loss: 0.693236 | avg_loss: 0.692382 | gender_precise: 51.000000 (8035/15488) [121/186]\n",
      "gender_loss: 0.6970391869544983\n",
      "train_loss: 0.697039 | avg_loss: 0.692421 | gender_precise: 51.000000 (8093/15616) [122/186]\n",
      "gender_loss: 0.692069411277771\n",
      "train_loss: 0.692069 | avg_loss: 0.692418 | gender_precise: 51.000000 (8160/15744) [123/186]\n",
      "gender_loss: 0.6903991103172302\n",
      "train_loss: 0.690399 | avg_loss: 0.692401 | gender_precise: 51.000000 (8230/15872) [124/186]\n",
      "gender_loss: 0.6952472925186157\n",
      "train_loss: 0.695247 | avg_loss: 0.692424 | gender_precise: 51.000000 (8291/16000) [125/186]\n",
      "gender_loss: 0.6941225528717041\n",
      "train_loss: 0.694123 | avg_loss: 0.692438 | gender_precise: 51.000000 (8354/16128) [126/186]\n",
      "gender_loss: 0.6951351761817932\n",
      "train_loss: 0.695135 | avg_loss: 0.692459 | gender_precise: 51.000000 (8415/16256) [127/186]\n",
      "gender_loss: 0.6961258053779602\n",
      "train_loss: 0.696126 | avg_loss: 0.692488 | gender_precise: 51.000000 (8474/16384) [128/186]\n",
      "gender_loss: 0.6949379444122314\n",
      "train_loss: 0.694938 | avg_loss: 0.692507 | gender_precise: 51.000000 (8535/16512) [129/186]\n",
      "gender_loss: 0.6921305060386658\n",
      "train_loss: 0.692131 | avg_loss: 0.692504 | gender_precise: 51.000000 (8602/16640) [130/186]\n",
      "gender_loss: 0.6898990869522095\n",
      "train_loss: 0.689899 | avg_loss: 0.692484 | gender_precise: 51.000000 (8674/16768) [131/186]\n",
      "gender_loss: 0.6883069276809692\n",
      "train_loss: 0.688307 | avg_loss: 0.692452 | gender_precise: 51.000000 (8750/16896) [132/186]\n",
      "gender_loss: 0.6912821531295776\n",
      "train_loss: 0.691282 | avg_loss: 0.692443 | gender_precise: 51.000000 (8819/17024) [133/186]\n",
      "gender_loss: 0.6938100457191467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.693810 | avg_loss: 0.692454 | gender_precise: 51.000000 (8882/17152) [134/186]\n",
      "gender_loss: 0.6890815496444702\n",
      "train_loss: 0.689082 | avg_loss: 0.692429 | gender_precise: 51.000000 (8956/17280) [135/186]\n",
      "gender_loss: 0.6939033269882202\n",
      "train_loss: 0.693903 | avg_loss: 0.692439 | gender_precise: 51.000000 (9019/17408) [136/186]\n",
      "gender_loss: 0.6973665952682495\n",
      "train_loss: 0.697367 | avg_loss: 0.692475 | gender_precise: 51.000000 (9074/17536) [137/186]\n",
      "gender_loss: 0.6951184272766113\n",
      "train_loss: 0.695118 | avg_loss: 0.692495 | gender_precise: 51.000000 (9134/17664) [138/186]\n",
      "gender_loss: 0.6882700324058533\n",
      "train_loss: 0.688270 | avg_loss: 0.692464 | gender_precise: 51.000000 (9210/17792) [139/186]\n",
      "gender_loss: 0.6938259601593018\n",
      "train_loss: 0.693826 | avg_loss: 0.692474 | gender_precise: 51.000000 (9273/17920) [140/186]\n",
      "gender_loss: 0.6912797689437866\n",
      "train_loss: 0.691280 | avg_loss: 0.692465 | gender_precise: 51.000000 (9342/18048) [141/186]\n",
      "gender_loss: 0.6963562369346619\n",
      "train_loss: 0.696356 | avg_loss: 0.692493 | gender_precise: 51.000000 (9399/18176) [142/186]\n",
      "gender_loss: 0.6963120102882385\n",
      "train_loss: 0.696312 | avg_loss: 0.692520 | gender_precise: 51.000000 (9456/18304) [143/186]\n",
      "gender_loss: 0.6909928321838379\n",
      "train_loss: 0.690993 | avg_loss: 0.692509 | gender_precise: 51.000000 (9526/18432) [144/186]\n",
      "gender_loss: 0.6922019720077515\n",
      "train_loss: 0.692202 | avg_loss: 0.692507 | gender_precise: 51.000000 (9593/18560) [145/186]\n",
      "gender_loss: 0.6898366808891296\n",
      "train_loss: 0.689837 | avg_loss: 0.692489 | gender_precise: 51.000000 (9666/18688) [146/186]\n",
      "gender_loss: 0.6913938522338867\n",
      "train_loss: 0.691394 | avg_loss: 0.692481 | gender_precise: 51.000000 (9735/18816) [147/186]\n",
      "gender_loss: 0.6910240054130554\n",
      "train_loss: 0.691024 | avg_loss: 0.692471 | gender_precise: 51.000000 (9805/18944) [148/186]\n",
      "gender_loss: 0.6952550411224365\n",
      "train_loss: 0.695255 | avg_loss: 0.692490 | gender_precise: 51.000000 (9864/19072) [149/186]\n",
      "gender_loss: 0.6922051310539246\n",
      "train_loss: 0.692205 | avg_loss: 0.692488 | gender_precise: 51.000000 (9931/19200) [150/186]\n",
      "gender_loss: 0.6921337246894836\n",
      "train_loss: 0.692134 | avg_loss: 0.692486 | gender_precise: 51.000000 (9998/19328) [151/186]\n",
      "gender_loss: 0.6929073929786682\n",
      "train_loss: 0.692907 | avg_loss: 0.692488 | gender_precise: 51.000000 (10063/19456) [152/186]\n",
      "gender_loss: 0.690186083316803\n",
      "train_loss: 0.690186 | avg_loss: 0.692473 | gender_precise: 51.000000 (10135/19584) [153/186]\n",
      "gender_loss: 0.6857335567474365\n",
      "train_loss: 0.685734 | avg_loss: 0.692430 | gender_precise: 51.000000 (10218/19712) [154/186]\n",
      "gender_loss: 0.6904553771018982\n",
      "train_loss: 0.690455 | avg_loss: 0.692417 | gender_precise: 51.000000 (10289/19840) [155/186]\n",
      "gender_loss: 0.6885131001472473\n",
      "train_loss: 0.688513 | avg_loss: 0.692392 | gender_precise: 51.000000 (10364/19968) [156/186]\n",
      "gender_loss: 0.688256561756134\n",
      "train_loss: 0.688257 | avg_loss: 0.692365 | gender_precise: 51.000000 (10439/20096) [157/186]\n",
      "gender_loss: 0.6894285082817078\n",
      "train_loss: 0.689429 | avg_loss: 0.692347 | gender_precise: 51.000000 (10511/20224) [158/186]\n",
      "gender_loss: 0.6892790198326111\n",
      "train_loss: 0.689279 | avg_loss: 0.692328 | gender_precise: 51.000000 (10583/20352) [159/186]\n",
      "gender_loss: 0.689582347869873\n",
      "train_loss: 0.689582 | avg_loss: 0.692310 | gender_precise: 52.000000 (10654/20480) [160/186]\n",
      "gender_loss: 0.6962646245956421\n",
      "train_loss: 0.696265 | avg_loss: 0.692335 | gender_precise: 51.000000 (10714/20608) [161/186]\n",
      "gender_loss: 0.6951253414154053\n",
      "train_loss: 0.695125 | avg_loss: 0.692352 | gender_precise: 51.000000 (10776/20736) [162/186]\n",
      "gender_loss: 0.693929135799408\n",
      "train_loss: 0.693929 | avg_loss: 0.692362 | gender_precise: 51.000000 (10840/20864) [163/186]\n",
      "gender_loss: 0.6898640990257263\n",
      "train_loss: 0.689864 | avg_loss: 0.692347 | gender_precise: 51.000000 (10910/20992) [164/186]\n",
      "gender_loss: 0.6947756409645081\n",
      "train_loss: 0.694776 | avg_loss: 0.692361 | gender_precise: 51.000000 (10973/21120) [165/186]\n",
      "gender_loss: 0.6947073936462402\n",
      "train_loss: 0.694707 | avg_loss: 0.692376 | gender_precise: 51.000000 (11036/21248) [166/186]\n",
      "gender_loss: 0.6889970302581787\n",
      "train_loss: 0.688997 | avg_loss: 0.692355 | gender_precise: 51.000000 (11107/21376) [167/186]\n",
      "gender_loss: 0.696224570274353\n",
      "train_loss: 0.696225 | avg_loss: 0.692378 | gender_precise: 51.000000 (11168/21504) [168/186]\n",
      "gender_loss: 0.6918143630027771\n",
      "train_loss: 0.691814 | avg_loss: 0.692375 | gender_precise: 51.000000 (11235/21632) [169/186]\n",
      "gender_loss: 0.6941593289375305\n",
      "train_loss: 0.694159 | avg_loss: 0.692385 | gender_precise: 51.000000 (11299/21760) [170/186]\n",
      "gender_loss: 0.6934534907341003\n",
      "train_loss: 0.693453 | avg_loss: 0.692392 | gender_precise: 51.000000 (11364/21888) [171/186]\n",
      "gender_loss: 0.6859530210494995\n",
      "train_loss: 0.685953 | avg_loss: 0.692354 | gender_precise: 51.000000 (11439/22016) [172/186]\n",
      "gender_loss: 0.6911369562149048\n",
      "train_loss: 0.691137 | avg_loss: 0.692347 | gender_precise: 51.000000 (11507/22144) [173/186]\n",
      "gender_loss: 0.6835460662841797\n",
      "train_loss: 0.683546 | avg_loss: 0.692297 | gender_precise: 52.000000 (11585/22272) [174/186]\n",
      "gender_loss: 0.6887956857681274\n",
      "train_loss: 0.688796 | avg_loss: 0.692277 | gender_precise: 52.000000 (11656/22400) [175/186]\n",
      "gender_loss: 0.6887660026550293\n",
      "train_loss: 0.688766 | avg_loss: 0.692257 | gender_precise: 52.000000 (11727/22528) [176/186]\n",
      "gender_loss: 0.6935572028160095\n",
      "train_loss: 0.693557 | avg_loss: 0.692264 | gender_precise: 52.000000 (11792/22656) [177/186]\n",
      "gender_loss: 0.6967971324920654\n",
      "train_loss: 0.696797 | avg_loss: 0.692290 | gender_precise: 52.000000 (11853/22784) [178/186]\n",
      "gender_loss: 0.6853339076042175\n",
      "train_loss: 0.685334 | avg_loss: 0.692251 | gender_precise: 52.000000 (11928/22912) [179/186]\n",
      "gender_loss: 0.6969953775405884\n",
      "train_loss: 0.696995 | avg_loss: 0.692277 | gender_precise: 52.000000 (11989/23040) [180/186]\n",
      "gender_loss: 0.6867017149925232\n",
      "train_loss: 0.686702 | avg_loss: 0.692246 | gender_precise: 52.000000 (12062/23168) [181/186]\n",
      "gender_loss: 0.694474458694458\n",
      "train_loss: 0.694474 | avg_loss: 0.692259 | gender_precise: 52.000000 (12126/23296) [182/186]\n",
      "gender_loss: 0.6971619129180908\n",
      "train_loss: 0.697162 | avg_loss: 0.692285 | gender_precise: 52.000000 (12187/23424) [183/186]\n",
      "gender_loss: 0.6988753080368042\n",
      "train_loss: 0.698875 | avg_loss: 0.692321 | gender_precise: 51.000000 (12246/23552) [184/186]\n",
      "gender_loss: 0.6893579959869385\n",
      "train_loss: 0.689358 | avg_loss: 0.692305 | gender_precise: 52.000000 (12316/23680) [185/186]\n",
      "gender_loss: 0.6945289373397827\n",
      "train_loss: 0.694529 | avg_loss: 0.692317 | gender_precise: 52.000000 (12330/23708) [186/186]\n",
      "\n",
      "Test\n",
      "gender_prec: 72.000000 (93/128) [1/2]\n",
      "gender_prec: 71.000000 (96/134) [2/2]\n",
      "Saving..\n",
      "Number epoch: 1\n",
      "gender_loss: 0.6977877020835876\n",
      "train_loss: 0.697788 | avg_loss: 0.697788 | gender_precise: 46.000000 (60/128) [1/186]\n",
      "gender_loss: 0.6894693374633789\n",
      "train_loss: 0.689469 | avg_loss: 0.693629 | gender_precise: 50.000000 (130/256) [2/186]\n",
      "gender_loss: 0.6992571353912354\n",
      "train_loss: 0.699257 | avg_loss: 0.695505 | gender_precise: 48.000000 (188/384) [3/186]\n",
      "gender_loss: 0.6878709197044373\n",
      "train_loss: 0.687871 | avg_loss: 0.693596 | gender_precise: 50.000000 (260/512) [4/186]\n",
      "gender_loss: 0.6936848759651184\n",
      "train_loss: 0.693685 | avg_loss: 0.693614 | gender_precise: 50.000000 (325/640) [5/186]\n",
      "gender_loss: 0.6887977123260498\n",
      "train_loss: 0.688798 | avg_loss: 0.692811 | gender_precise: 51.000000 (396/768) [6/186]\n",
      "gender_loss: 0.6911337971687317\n",
      "train_loss: 0.691134 | avg_loss: 0.692572 | gender_precise: 51.000000 (464/896) [7/186]\n",
      "gender_loss: 0.6912754774093628\n",
      "train_loss: 0.691275 | avg_loss: 0.692410 | gender_precise: 51.000000 (532/1024) [8/186]\n",
      "gender_loss: 0.6872982978820801\n",
      "train_loss: 0.687298 | avg_loss: 0.691842 | gender_precise: 52.000000 (605/1152) [9/186]\n",
      "gender_loss: 0.6988011002540588\n",
      "train_loss: 0.698801 | avg_loss: 0.692538 | gender_precise: 51.000000 (663/1280) [10/186]\n",
      "gender_loss: 0.6924436688423157\n",
      "train_loss: 0.692444 | avg_loss: 0.692529 | gender_precise: 51.000000 (729/1408) [11/186]\n",
      "gender_loss: 0.688112735748291\n",
      "train_loss: 0.688113 | avg_loss: 0.692161 | gender_precise: 52.000000 (801/1536) [12/186]\n",
      "gender_loss: 0.6919190883636475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.691919 | avg_loss: 0.692142 | gender_precise: 52.000000 (868/1664) [13/186]\n",
      "gender_loss: 0.6894540190696716\n",
      "train_loss: 0.689454 | avg_loss: 0.691951 | gender_precise: 52.000000 (938/1792) [14/186]\n",
      "gender_loss: 0.684411883354187\n",
      "train_loss: 0.684412 | avg_loss: 0.691448 | gender_precise: 52.000000 (1015/1920) [15/186]\n",
      "gender_loss: 0.6873265504837036\n",
      "train_loss: 0.687327 | avg_loss: 0.691190 | gender_precise: 53.000000 (1088/2048) [16/186]\n",
      "gender_loss: 0.6839935779571533\n",
      "train_loss: 0.683994 | avg_loss: 0.690767 | gender_precise: 53.000000 (1165/2176) [17/186]\n",
      "gender_loss: 0.693673849105835\n",
      "train_loss: 0.693674 | avg_loss: 0.690928 | gender_precise: 53.000000 (1230/2304) [18/186]\n",
      "gender_loss: 0.6894683837890625\n",
      "train_loss: 0.689468 | avg_loss: 0.690852 | gender_precise: 53.000000 (1300/2432) [19/186]\n",
      "gender_loss: 0.6927663683891296\n",
      "train_loss: 0.692766 | avg_loss: 0.690947 | gender_precise: 53.000000 (1366/2560) [20/186]\n",
      "gender_loss: 0.693443775177002\n",
      "train_loss: 0.693444 | avg_loss: 0.691066 | gender_precise: 53.000000 (1431/2688) [21/186]\n",
      "gender_loss: 0.6902658939361572\n",
      "train_loss: 0.690266 | avg_loss: 0.691030 | gender_precise: 53.000000 (1500/2816) [22/186]\n",
      "gender_loss: 0.6884831190109253\n",
      "train_loss: 0.688483 | avg_loss: 0.690919 | gender_precise: 53.000000 (1571/2944) [23/186]\n",
      "gender_loss: 0.6822971105575562\n",
      "train_loss: 0.682297 | avg_loss: 0.690560 | gender_precise: 53.000000 (1649/3072) [24/186]\n",
      "gender_loss: 0.6946184635162354\n",
      "train_loss: 0.694618 | avg_loss: 0.690722 | gender_precise: 53.000000 (1713/3200) [25/186]\n",
      "gender_loss: 0.6992579698562622\n",
      "train_loss: 0.699258 | avg_loss: 0.691051 | gender_precise: 53.000000 (1772/3328) [26/186]\n",
      "gender_loss: 0.6900303363800049\n",
      "train_loss: 0.690030 | avg_loss: 0.691013 | gender_precise: 53.000000 (1841/3456) [27/186]\n",
      "gender_loss: 0.6918392777442932\n",
      "train_loss: 0.691839 | avg_loss: 0.691042 | gender_precise: 53.000000 (1908/3584) [28/186]\n",
      "gender_loss: 0.69285649061203\n",
      "train_loss: 0.692856 | avg_loss: 0.691105 | gender_precise: 53.000000 (1974/3712) [29/186]\n",
      "gender_loss: 0.6946805119514465\n",
      "train_loss: 0.694681 | avg_loss: 0.691224 | gender_precise: 53.000000 (2038/3840) [30/186]\n",
      "gender_loss: 0.6882075667381287\n",
      "train_loss: 0.688208 | avg_loss: 0.691127 | gender_precise: 53.000000 (2109/3968) [31/186]\n",
      "gender_loss: 0.6862106323242188\n",
      "train_loss: 0.686211 | avg_loss: 0.690973 | gender_precise: 53.000000 (2182/4096) [32/186]\n",
      "gender_loss: 0.691925048828125\n",
      "train_loss: 0.691925 | avg_loss: 0.691002 | gender_precise: 53.000000 (2249/4224) [33/186]\n",
      "gender_loss: 0.7042170763015747\n",
      "train_loss: 0.704217 | avg_loss: 0.691391 | gender_precise: 52.000000 (2303/4352) [34/186]\n",
      "gender_loss: 0.695554792881012\n",
      "train_loss: 0.695555 | avg_loss: 0.691510 | gender_precise: 52.000000 (2366/4480) [35/186]\n",
      "gender_loss: 0.6919504404067993\n",
      "train_loss: 0.691950 | avg_loss: 0.691522 | gender_precise: 52.000000 (2433/4608) [36/186]\n",
      "gender_loss: 0.6909240484237671\n",
      "train_loss: 0.690924 | avg_loss: 0.691506 | gender_precise: 52.000000 (2501/4736) [37/186]\n",
      "gender_loss: 0.6837115287780762\n",
      "train_loss: 0.683712 | avg_loss: 0.691301 | gender_precise: 52.000000 (2577/4864) [38/186]\n",
      "gender_loss: 0.6829853057861328\n",
      "train_loss: 0.682985 | avg_loss: 0.691087 | gender_precise: 53.000000 (2654/4992) [39/186]\n",
      "gender_loss: 0.6818774938583374\n",
      "train_loss: 0.681877 | avg_loss: 0.690857 | gender_precise: 53.000000 (2732/5120) [40/186]\n",
      "gender_loss: 0.6926488280296326\n",
      "train_loss: 0.692649 | avg_loss: 0.690901 | gender_precise: 53.000000 (2798/5248) [41/186]\n",
      "gender_loss: 0.7015113830566406\n",
      "train_loss: 0.701511 | avg_loss: 0.691153 | gender_precise: 53.000000 (2855/5376) [42/186]\n",
      "gender_loss: 0.6965697407722473\n",
      "train_loss: 0.696570 | avg_loss: 0.691279 | gender_precise: 52.000000 (2917/5504) [43/186]\n",
      "gender_loss: 0.690778374671936\n",
      "train_loss: 0.690778 | avg_loss: 0.691268 | gender_precise: 53.000000 (2985/5632) [44/186]\n",
      "gender_loss: 0.6797265410423279\n",
      "train_loss: 0.679727 | avg_loss: 0.691012 | gender_precise: 53.000000 (3065/5760) [45/186]\n",
      "gender_loss: 0.6948049068450928\n",
      "train_loss: 0.694805 | avg_loss: 0.691094 | gender_precise: 53.000000 (3129/5888) [46/186]\n",
      "gender_loss: 0.69771808385849\n",
      "train_loss: 0.697718 | avg_loss: 0.691235 | gender_precise: 53.000000 (3190/6016) [47/186]\n",
      "gender_loss: 0.6994253396987915\n",
      "train_loss: 0.699425 | avg_loss: 0.691406 | gender_precise: 52.000000 (3249/6144) [48/186]\n",
      "gender_loss: 0.7003109455108643\n",
      "train_loss: 0.700311 | avg_loss: 0.691587 | gender_precise: 52.000000 (3307/6272) [49/186]\n",
      "gender_loss: 0.6846678853034973\n",
      "train_loss: 0.684668 | avg_loss: 0.691449 | gender_precise: 52.000000 (3382/6400) [50/186]\n",
      "gender_loss: 0.6908988952636719\n",
      "train_loss: 0.690899 | avg_loss: 0.691438 | gender_precise: 52.000000 (3450/6528) [51/186]\n",
      "gender_loss: 0.6837121844291687\n",
      "train_loss: 0.683712 | avg_loss: 0.691290 | gender_precise: 52.000000 (3526/6656) [52/186]\n",
      "gender_loss: 0.6872227191925049\n",
      "train_loss: 0.687223 | avg_loss: 0.691213 | gender_precise: 53.000000 (3598/6784) [53/186]\n",
      "gender_loss: 0.6964235305786133\n",
      "train_loss: 0.696424 | avg_loss: 0.691309 | gender_precise: 52.000000 (3660/6912) [54/186]\n",
      "gender_loss: 0.6873379945755005\n",
      "train_loss: 0.687338 | avg_loss: 0.691237 | gender_precise: 53.000000 (3732/7040) [55/186]\n",
      "gender_loss: 0.6936035752296448\n",
      "train_loss: 0.693604 | avg_loss: 0.691279 | gender_precise: 52.000000 (3797/7168) [56/186]\n",
      "gender_loss: 0.6924724578857422\n",
      "train_loss: 0.692472 | avg_loss: 0.691300 | gender_precise: 52.000000 (3863/7296) [57/186]\n",
      "gender_loss: 0.6863397359848022\n",
      "train_loss: 0.686340 | avg_loss: 0.691215 | gender_precise: 53.000000 (3936/7424) [58/186]\n",
      "gender_loss: 0.6908339262008667\n",
      "train_loss: 0.690834 | avg_loss: 0.691208 | gender_precise: 53.000000 (4004/7552) [59/186]\n",
      "gender_loss: 0.6898582577705383\n",
      "train_loss: 0.689858 | avg_loss: 0.691186 | gender_precise: 53.000000 (4073/7680) [60/186]\n",
      "gender_loss: 0.682826817035675\n",
      "train_loss: 0.682827 | avg_loss: 0.691049 | gender_precise: 53.000000 (4150/7808) [61/186]\n",
      "gender_loss: 0.6980524659156799\n",
      "train_loss: 0.698052 | avg_loss: 0.691162 | gender_precise: 53.000000 (4210/7936) [62/186]\n",
      "gender_loss: 0.6935538649559021\n",
      "train_loss: 0.693554 | avg_loss: 0.691200 | gender_precise: 53.000000 (4275/8064) [63/186]\n",
      "gender_loss: 0.6963585615158081\n",
      "train_loss: 0.696359 | avg_loss: 0.691280 | gender_precise: 52.000000 (4337/8192) [64/186]\n",
      "gender_loss: 0.6899189352989197\n",
      "train_loss: 0.689919 | avg_loss: 0.691259 | gender_precise: 52.000000 (4406/8320) [65/186]\n",
      "gender_loss: 0.6908911466598511\n",
      "train_loss: 0.690891 | avg_loss: 0.691254 | gender_precise: 52.000000 (4474/8448) [66/186]\n",
      "gender_loss: 0.6942769289016724\n",
      "train_loss: 0.694277 | avg_loss: 0.691299 | gender_precise: 52.000000 (4538/8576) [67/186]\n",
      "gender_loss: 0.6908498406410217\n",
      "train_loss: 0.690850 | avg_loss: 0.691292 | gender_precise: 52.000000 (4606/8704) [68/186]\n",
      "gender_loss: 0.6917897462844849\n",
      "train_loss: 0.691790 | avg_loss: 0.691299 | gender_precise: 52.000000 (4673/8832) [69/186]\n",
      "gender_loss: 0.678135097026825\n",
      "train_loss: 0.678135 | avg_loss: 0.691111 | gender_precise: 53.000000 (4755/8960) [70/186]\n",
      "gender_loss: 0.6936987042427063\n",
      "train_loss: 0.693699 | avg_loss: 0.691148 | gender_precise: 53.000000 (4820/9088) [71/186]\n",
      "gender_loss: 0.6898824572563171\n",
      "train_loss: 0.689882 | avg_loss: 0.691130 | gender_precise: 53.000000 (4889/9216) [72/186]\n",
      "gender_loss: 0.7019349336624146\n",
      "train_loss: 0.701935 | avg_loss: 0.691278 | gender_precise: 52.000000 (4945/9344) [73/186]\n",
      "gender_loss: 0.6908584833145142\n",
      "train_loss: 0.690858 | avg_loss: 0.691273 | gender_precise: 52.000000 (5013/9472) [74/186]\n",
      "gender_loss: 0.692302942276001\n",
      "train_loss: 0.692303 | avg_loss: 0.691286 | gender_precise: 52.000000 (5079/9600) [75/186]\n",
      "gender_loss: 0.6864700317382812\n",
      "train_loss: 0.686470 | avg_loss: 0.691223 | gender_precise: 52.000000 (5152/9728) [76/186]\n",
      "gender_loss: 0.6972529888153076\n",
      "train_loss: 0.697253 | avg_loss: 0.691301 | gender_precise: 52.000000 (5213/9856) [77/186]\n",
      "gender_loss: 0.6934770941734314\n",
      "train_loss: 0.693477 | avg_loss: 0.691329 | gender_precise: 52.000000 (5278/9984) [78/186]\n",
      "gender_loss: 0.6914299726486206\n",
      "train_loss: 0.691430 | avg_loss: 0.691330 | gender_precise: 52.000000 (5345/10112) [79/186]\n",
      "gender_loss: 0.6828085780143738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.682809 | avg_loss: 0.691224 | gender_precise: 52.000000 (5422/10240) [80/186]\n",
      "gender_loss: 0.686247706413269\n",
      "train_loss: 0.686248 | avg_loss: 0.691163 | gender_precise: 52.000000 (5495/10368) [81/186]\n",
      "gender_loss: 0.6826953887939453\n",
      "train_loss: 0.682695 | avg_loss: 0.691059 | gender_precise: 53.000000 (5572/10496) [82/186]\n",
      "gender_loss: 0.6926846504211426\n",
      "train_loss: 0.692685 | avg_loss: 0.691079 | gender_precise: 53.000000 (5638/10624) [83/186]\n",
      "gender_loss: 0.6932688355445862\n",
      "train_loss: 0.693269 | avg_loss: 0.691105 | gender_precise: 53.000000 (5703/10752) [84/186]\n",
      "gender_loss: 0.6951802372932434\n",
      "train_loss: 0.695180 | avg_loss: 0.691153 | gender_precise: 52.000000 (5766/10880) [85/186]\n",
      "gender_loss: 0.6799356937408447\n",
      "train_loss: 0.679936 | avg_loss: 0.691022 | gender_precise: 53.000000 (5846/11008) [86/186]\n",
      "gender_loss: 0.6889631152153015\n",
      "train_loss: 0.688963 | avg_loss: 0.690999 | gender_precise: 53.000000 (5916/11136) [87/186]\n",
      "gender_loss: 0.6860582232475281\n",
      "train_loss: 0.686058 | avg_loss: 0.690943 | gender_precise: 53.000000 (5989/11264) [88/186]\n",
      "gender_loss: 0.6848858594894409\n",
      "train_loss: 0.684886 | avg_loss: 0.690875 | gender_precise: 53.000000 (6063/11392) [89/186]\n",
      "gender_loss: 0.6956198215484619\n",
      "train_loss: 0.695620 | avg_loss: 0.690927 | gender_precise: 53.000000 (6126/11520) [90/186]\n",
      "gender_loss: 0.6982443928718567\n",
      "train_loss: 0.698244 | avg_loss: 0.691008 | gender_precise: 53.000000 (6186/11648) [91/186]\n",
      "gender_loss: 0.6916231513023376\n",
      "train_loss: 0.691623 | avg_loss: 0.691014 | gender_precise: 53.000000 (6253/11776) [92/186]\n",
      "gender_loss: 0.685858964920044\n",
      "train_loss: 0.685859 | avg_loss: 0.690959 | gender_precise: 53.000000 (6326/11904) [93/186]\n",
      "gender_loss: 0.691881000995636\n",
      "train_loss: 0.691881 | avg_loss: 0.690969 | gender_precise: 53.000000 (6393/12032) [94/186]\n",
      "gender_loss: 0.6878454685211182\n",
      "train_loss: 0.687845 | avg_loss: 0.690936 | gender_precise: 53.000000 (6464/12160) [95/186]\n",
      "gender_loss: 0.6817046403884888\n",
      "train_loss: 0.681705 | avg_loss: 0.690840 | gender_precise: 53.000000 (6541/12288) [96/186]\n",
      "gender_loss: 0.6919131278991699\n",
      "train_loss: 0.691913 | avg_loss: 0.690851 | gender_precise: 53.000000 (6608/12416) [97/186]\n",
      "gender_loss: 0.688597559928894\n",
      "train_loss: 0.688598 | avg_loss: 0.690828 | gender_precise: 53.000000 (6678/12544) [98/186]\n",
      "gender_loss: 0.6985464692115784\n",
      "train_loss: 0.698546 | avg_loss: 0.690906 | gender_precise: 53.000000 (6738/12672) [99/186]\n",
      "gender_loss: 0.6903932690620422\n",
      "train_loss: 0.690393 | avg_loss: 0.690901 | gender_precise: 53.000000 (6806/12800) [100/186]\n",
      "gender_loss: 0.6909148693084717\n",
      "train_loss: 0.690915 | avg_loss: 0.690901 | gender_precise: 53.000000 (6874/12928) [101/186]\n",
      "gender_loss: 0.6961445212364197\n",
      "train_loss: 0.696145 | avg_loss: 0.690952 | gender_precise: 53.000000 (6937/13056) [102/186]\n",
      "gender_loss: 0.6962636113166809\n",
      "train_loss: 0.696264 | avg_loss: 0.691004 | gender_precise: 53.000000 (7000/13184) [103/186]\n",
      "gender_loss: 0.6916431188583374\n",
      "train_loss: 0.691643 | avg_loss: 0.691010 | gender_precise: 53.000000 (7067/13312) [104/186]\n",
      "gender_loss: 0.6923969388008118\n",
      "train_loss: 0.692397 | avg_loss: 0.691023 | gender_precise: 53.000000 (7133/13440) [105/186]\n",
      "gender_loss: 0.6825463771820068\n",
      "train_loss: 0.682546 | avg_loss: 0.690943 | gender_precise: 53.000000 (7209/13568) [106/186]\n",
      "gender_loss: 0.6830668449401855\n",
      "train_loss: 0.683067 | avg_loss: 0.690870 | gender_precise: 53.000000 (7284/13696) [107/186]\n",
      "gender_loss: 0.6919207572937012\n",
      "train_loss: 0.691921 | avg_loss: 0.690879 | gender_precise: 53.000000 (7351/13824) [108/186]\n",
      "gender_loss: 0.6886260509490967\n",
      "train_loss: 0.688626 | avg_loss: 0.690859 | gender_precise: 53.000000 (7421/13952) [109/186]\n",
      "gender_loss: 0.7012642025947571\n",
      "train_loss: 0.701264 | avg_loss: 0.690953 | gender_precise: 53.000000 (7479/14080) [110/186]\n",
      "gender_loss: 0.6875758171081543\n",
      "train_loss: 0.687576 | avg_loss: 0.690923 | gender_precise: 53.000000 (7550/14208) [111/186]\n",
      "gender_loss: 0.6907922625541687\n",
      "train_loss: 0.690792 | avg_loss: 0.690922 | gender_precise: 53.000000 (7618/14336) [112/186]\n",
      "gender_loss: 0.6925808787345886\n",
      "train_loss: 0.692581 | avg_loss: 0.690936 | gender_precise: 53.000000 (7684/14464) [113/186]\n",
      "gender_loss: 0.6963930726051331\n",
      "train_loss: 0.696393 | avg_loss: 0.690984 | gender_precise: 53.000000 (7746/14592) [114/186]\n",
      "gender_loss: 0.6865608096122742\n",
      "train_loss: 0.686561 | avg_loss: 0.690946 | gender_precise: 53.000000 (7818/14720) [115/186]\n",
      "gender_loss: 0.6886498332023621\n",
      "train_loss: 0.688650 | avg_loss: 0.690926 | gender_precise: 53.000000 (7888/14848) [116/186]\n",
      "gender_loss: 0.6992626190185547\n",
      "train_loss: 0.699263 | avg_loss: 0.690997 | gender_precise: 53.000000 (7948/14976) [117/186]\n",
      "gender_loss: 0.6941869854927063\n",
      "train_loss: 0.694187 | avg_loss: 0.691024 | gender_precise: 53.000000 (8012/15104) [118/186]\n",
      "gender_loss: 0.699103057384491\n",
      "train_loss: 0.699103 | avg_loss: 0.691092 | gender_precise: 52.000000 (8071/15232) [119/186]\n",
      "gender_loss: 0.6890931129455566\n",
      "train_loss: 0.689093 | avg_loss: 0.691076 | gender_precise: 52.000000 (8140/15360) [120/186]\n",
      "gender_loss: 0.6918145418167114\n",
      "train_loss: 0.691815 | avg_loss: 0.691082 | gender_precise: 52.000000 (8206/15488) [121/186]\n",
      "gender_loss: 0.6954090595245361\n",
      "train_loss: 0.695409 | avg_loss: 0.691117 | gender_precise: 52.000000 (8269/15616) [122/186]\n",
      "gender_loss: 0.6925680041313171\n",
      "train_loss: 0.692568 | avg_loss: 0.691129 | gender_precise: 52.000000 (8335/15744) [123/186]\n",
      "gender_loss: 0.6878700256347656\n",
      "train_loss: 0.687870 | avg_loss: 0.691103 | gender_precise: 52.000000 (8406/15872) [124/186]\n",
      "gender_loss: 0.6995830535888672\n",
      "train_loss: 0.699583 | avg_loss: 0.691171 | gender_precise: 52.000000 (8464/16000) [125/186]\n",
      "gender_loss: 0.6872839331626892\n",
      "train_loss: 0.687284 | avg_loss: 0.691140 | gender_precise: 52.000000 (8535/16128) [126/186]\n",
      "gender_loss: 0.6887999773025513\n",
      "train_loss: 0.688800 | avg_loss: 0.691121 | gender_precise: 52.000000 (8605/16256) [127/186]\n",
      "gender_loss: 0.6930550932884216\n",
      "train_loss: 0.693055 | avg_loss: 0.691136 | gender_precise: 52.000000 (8670/16384) [128/186]\n",
      "gender_loss: 0.6900270581245422\n",
      "train_loss: 0.690027 | avg_loss: 0.691128 | gender_precise: 52.000000 (8739/16512) [129/186]\n",
      "gender_loss: 0.6936261057853699\n",
      "train_loss: 0.693626 | avg_loss: 0.691147 | gender_precise: 52.000000 (8803/16640) [130/186]\n",
      "gender_loss: 0.6892644166946411\n",
      "train_loss: 0.689264 | avg_loss: 0.691133 | gender_precise: 52.000000 (8872/16768) [131/186]\n",
      "gender_loss: 0.6868472099304199\n",
      "train_loss: 0.686847 | avg_loss: 0.691100 | gender_precise: 52.000000 (8944/16896) [132/186]\n",
      "gender_loss: 0.6882665157318115\n",
      "train_loss: 0.688267 | avg_loss: 0.691079 | gender_precise: 52.000000 (9015/17024) [133/186]\n",
      "gender_loss: 0.6968647241592407\n",
      "train_loss: 0.696865 | avg_loss: 0.691122 | gender_precise: 52.000000 (9075/17152) [134/186]\n",
      "gender_loss: 0.693659245967865\n",
      "train_loss: 0.693659 | avg_loss: 0.691141 | gender_precise: 52.000000 (9139/17280) [135/186]\n",
      "gender_loss: 0.6978112459182739\n",
      "train_loss: 0.697811 | avg_loss: 0.691190 | gender_precise: 52.000000 (9197/17408) [136/186]\n",
      "gender_loss: 0.6909196972846985\n",
      "train_loss: 0.690920 | avg_loss: 0.691188 | gender_precise: 52.000000 (9264/17536) [137/186]\n",
      "gender_loss: 0.6929203867912292\n",
      "train_loss: 0.692920 | avg_loss: 0.691200 | gender_precise: 52.000000 (9328/17664) [138/186]\n",
      "gender_loss: 0.691199779510498\n",
      "train_loss: 0.691200 | avg_loss: 0.691200 | gender_precise: 52.000000 (9394/17792) [139/186]\n",
      "gender_loss: 0.6927735209465027\n",
      "train_loss: 0.692774 | avg_loss: 0.691212 | gender_precise: 52.000000 (9459/17920) [140/186]\n",
      "gender_loss: 0.6922417283058167\n",
      "train_loss: 0.692242 | avg_loss: 0.691219 | gender_precise: 52.000000 (9523/18048) [141/186]\n",
      "gender_loss: 0.6898573637008667\n",
      "train_loss: 0.689857 | avg_loss: 0.691209 | gender_precise: 52.000000 (9591/18176) [142/186]\n",
      "gender_loss: 0.6903499364852905\n",
      "train_loss: 0.690350 | avg_loss: 0.691203 | gender_precise: 52.000000 (9659/18304) [143/186]\n",
      "gender_loss: 0.69413822889328\n",
      "train_loss: 0.694138 | avg_loss: 0.691224 | gender_precise: 52.000000 (9721/18432) [144/186]\n",
      "gender_loss: 0.6896570920944214\n",
      "train_loss: 0.689657 | avg_loss: 0.691213 | gender_precise: 52.000000 (9789/18560) [145/186]\n",
      "gender_loss: 0.6859684586524963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.685968 | avg_loss: 0.691177 | gender_precise: 52.000000 (9864/18688) [146/186]\n",
      "gender_loss: 0.6893224716186523\n",
      "train_loss: 0.689322 | avg_loss: 0.691164 | gender_precise: 52.000000 (9933/18816) [147/186]\n",
      "gender_loss: 0.6908865571022034\n",
      "train_loss: 0.690887 | avg_loss: 0.691162 | gender_precise: 52.000000 (10000/18944) [148/186]\n",
      "gender_loss: 0.6979867815971375\n",
      "train_loss: 0.697987 | avg_loss: 0.691208 | gender_precise: 52.000000 (10055/19072) [149/186]\n",
      "gender_loss: 0.6931210160255432\n",
      "train_loss: 0.693121 | avg_loss: 0.691221 | gender_precise: 52.000000 (10118/19200) [150/186]\n",
      "gender_loss: 0.6950445175170898\n",
      "train_loss: 0.695045 | avg_loss: 0.691246 | gender_precise: 52.000000 (10177/19328) [151/186]\n",
      "gender_loss: 0.6912137269973755\n",
      "train_loss: 0.691214 | avg_loss: 0.691246 | gender_precise: 52.000000 (10242/19456) [152/186]\n",
      "gender_loss: 0.6963440775871277\n",
      "train_loss: 0.696344 | avg_loss: 0.691279 | gender_precise: 52.000000 (10300/19584) [153/186]\n",
      "gender_loss: 0.6872273683547974\n",
      "train_loss: 0.687227 | avg_loss: 0.691253 | gender_precise: 52.000000 (10373/19712) [154/186]\n",
      "gender_loss: 0.689001739025116\n",
      "train_loss: 0.689002 | avg_loss: 0.691239 | gender_precise: 52.000000 (10442/19840) [155/186]\n",
      "gender_loss: 0.691332995891571\n",
      "train_loss: 0.691333 | avg_loss: 0.691239 | gender_precise: 52.000000 (10510/19968) [156/186]\n",
      "gender_loss: 0.6891564726829529\n",
      "train_loss: 0.689156 | avg_loss: 0.691226 | gender_precise: 52.000000 (10579/20096) [157/186]\n",
      "gender_loss: 0.6926472187042236\n",
      "train_loss: 0.692647 | avg_loss: 0.691235 | gender_precise: 52.000000 (10639/20224) [158/186]\n",
      "gender_loss: 0.689956784248352\n",
      "train_loss: 0.689957 | avg_loss: 0.691227 | gender_precise: 52.000000 (10707/20352) [159/186]\n",
      "gender_loss: 0.6944899559020996\n",
      "train_loss: 0.694490 | avg_loss: 0.691247 | gender_precise: 52.000000 (10767/20480) [160/186]\n",
      "gender_loss: 0.6917433142662048\n",
      "train_loss: 0.691743 | avg_loss: 0.691250 | gender_precise: 52.000000 (10832/20608) [161/186]\n",
      "gender_loss: 0.6931045651435852\n",
      "train_loss: 0.693105 | avg_loss: 0.691262 | gender_precise: 52.000000 (10894/20736) [162/186]\n",
      "gender_loss: 0.6947882175445557\n",
      "train_loss: 0.694788 | avg_loss: 0.691283 | gender_precise: 52.000000 (10949/20864) [163/186]\n",
      "gender_loss: 0.6900787353515625\n",
      "train_loss: 0.690079 | avg_loss: 0.691276 | gender_precise: 52.000000 (11015/20992) [164/186]\n",
      "gender_loss: 0.6899712681770325\n",
      "train_loss: 0.689971 | avg_loss: 0.691268 | gender_precise: 52.000000 (11082/21120) [165/186]\n",
      "gender_loss: 0.6884194612503052\n",
      "train_loss: 0.688419 | avg_loss: 0.691251 | gender_precise: 52.000000 (11156/21248) [166/186]\n",
      "gender_loss: 0.6889324188232422\n",
      "train_loss: 0.688932 | avg_loss: 0.691237 | gender_precise: 52.000000 (11226/21376) [167/186]\n",
      "gender_loss: 0.6898306608200073\n",
      "train_loss: 0.689831 | avg_loss: 0.691229 | gender_precise: 52.000000 (11292/21504) [168/186]\n",
      "gender_loss: 0.6922156810760498\n",
      "train_loss: 0.692216 | avg_loss: 0.691235 | gender_precise: 52.000000 (11352/21632) [169/186]\n",
      "gender_loss: 0.6883189082145691\n",
      "train_loss: 0.688319 | avg_loss: 0.691217 | gender_precise: 52.000000 (11421/21760) [170/186]\n",
      "gender_loss: 0.6929729580879211\n",
      "train_loss: 0.692973 | avg_loss: 0.691228 | gender_precise: 52.000000 (11483/21888) [171/186]\n",
      "gender_loss: 0.6943699717521667\n",
      "train_loss: 0.694370 | avg_loss: 0.691246 | gender_precise: 52.000000 (11538/22016) [172/186]\n",
      "gender_loss: 0.6895791292190552\n",
      "train_loss: 0.689579 | avg_loss: 0.691236 | gender_precise: 52.000000 (11608/22144) [173/186]\n",
      "gender_loss: 0.6905544996261597\n",
      "train_loss: 0.690554 | avg_loss: 0.691232 | gender_precise: 52.000000 (11670/22272) [174/186]\n",
      "gender_loss: 0.6896349787712097\n",
      "train_loss: 0.689635 | avg_loss: 0.691223 | gender_precise: 52.000000 (11739/22400) [175/186]\n",
      "gender_loss: 0.6918461918830872\n",
      "train_loss: 0.691846 | avg_loss: 0.691227 | gender_precise: 52.000000 (11807/22528) [176/186]\n",
      "gender_loss: 0.6899198889732361\n",
      "train_loss: 0.689920 | avg_loss: 0.691220 | gender_precise: 52.000000 (11879/22656) [177/186]\n",
      "gender_loss: 0.6900296807289124\n",
      "train_loss: 0.690030 | avg_loss: 0.691213 | gender_precise: 52.000000 (11955/22784) [178/186]\n",
      "gender_loss: 0.6915424466133118\n",
      "train_loss: 0.691542 | avg_loss: 0.691215 | gender_precise: 52.000000 (12027/22912) [179/186]\n",
      "gender_loss: 0.6900244355201721\n",
      "train_loss: 0.690024 | avg_loss: 0.691208 | gender_precise: 52.000000 (12100/23040) [180/186]\n",
      "gender_loss: 0.6930293440818787\n",
      "train_loss: 0.693029 | avg_loss: 0.691218 | gender_precise: 52.000000 (12167/23168) [181/186]\n",
      "gender_loss: 0.6884427070617676\n",
      "train_loss: 0.688443 | avg_loss: 0.691203 | gender_precise: 52.000000 (12237/23296) [182/186]\n",
      "gender_loss: 0.6893596649169922\n",
      "train_loss: 0.689360 | avg_loss: 0.691193 | gender_precise: 52.000000 (12309/23424) [183/186]\n",
      "gender_loss: 0.6880949139595032\n",
      "train_loss: 0.688095 | avg_loss: 0.691176 | gender_precise: 52.000000 (12389/23552) [184/186]\n",
      "gender_loss: 0.6877090930938721\n",
      "train_loss: 0.687709 | avg_loss: 0.691157 | gender_precise: 52.000000 (12471/23680) [185/186]\n",
      "gender_loss: 0.6862688660621643\n",
      "train_loss: 0.686269 | avg_loss: 0.691131 | gender_precise: 52.000000 (12490/23708) [186/186]\n",
      "\n",
      "Test\n",
      "gender_prec: 67.000000 (87/128) [1/2]\n",
      "gender_prec: 66.000000 (89/134) [2/2]\n",
      "Number epoch: 2\n",
      "gender_loss: 0.6906821727752686\n",
      "train_loss: 0.690682 | avg_loss: 0.690682 | gender_precise: 56.000000 (72/128) [1/186]\n",
      "gender_loss: 0.6888383626937866\n",
      "train_loss: 0.688838 | avg_loss: 0.689760 | gender_precise: 60.000000 (154/256) [2/186]\n",
      "gender_loss: 0.6895773410797119\n",
      "train_loss: 0.689577 | avg_loss: 0.689699 | gender_precise: 58.000000 (226/384) [3/186]\n",
      "gender_loss: 0.6878302693367004\n",
      "train_loss: 0.687830 | avg_loss: 0.689232 | gender_precise: 60.000000 (308/512) [4/186]\n",
      "gender_loss: 0.6877891421318054\n",
      "train_loss: 0.687789 | avg_loss: 0.688944 | gender_precise: 61.000000 (392/640) [5/186]\n",
      "gender_loss: 0.6868157982826233\n",
      "train_loss: 0.686816 | avg_loss: 0.688589 | gender_precise: 61.000000 (473/768) [6/186]\n",
      "gender_loss: 0.6872316598892212\n",
      "train_loss: 0.687232 | avg_loss: 0.688395 | gender_precise: 61.000000 (555/896) [7/186]\n",
      "gender_loss: 0.6900621652603149\n",
      "train_loss: 0.690062 | avg_loss: 0.688603 | gender_precise: 61.000000 (628/1024) [8/186]\n",
      "gender_loss: 0.6916945576667786\n",
      "train_loss: 0.691695 | avg_loss: 0.688947 | gender_precise: 60.000000 (698/1152) [9/186]\n",
      "gender_loss: 0.6859962344169617\n",
      "train_loss: 0.685996 | avg_loss: 0.688652 | gender_precise: 61.000000 (784/1280) [10/186]\n",
      "gender_loss: 0.6916660666465759\n",
      "train_loss: 0.691666 | avg_loss: 0.688926 | gender_precise: 60.000000 (852/1408) [11/186]\n",
      "gender_loss: 0.6890350580215454\n",
      "train_loss: 0.689035 | avg_loss: 0.688935 | gender_precise: 60.000000 (927/1536) [12/186]\n",
      "gender_loss: 0.686147153377533\n",
      "train_loss: 0.686147 | avg_loss: 0.688720 | gender_precise: 60.000000 (1011/1664) [13/186]\n",
      "gender_loss: 0.6892584562301636\n",
      "train_loss: 0.689258 | avg_loss: 0.688759 | gender_precise: 60.000000 (1084/1792) [14/186]\n",
      "gender_loss: 0.6898660659790039\n",
      "train_loss: 0.689866 | avg_loss: 0.688833 | gender_precise: 60.000000 (1159/1920) [15/186]\n",
      "gender_loss: 0.6862131357192993\n",
      "train_loss: 0.686213 | avg_loss: 0.688669 | gender_precise: 60.000000 (1238/2048) [16/186]\n",
      "gender_loss: 0.6883441209793091\n",
      "train_loss: 0.688344 | avg_loss: 0.688650 | gender_precise: 60.000000 (1318/2176) [17/186]\n",
      "gender_loss: 0.686442494392395\n",
      "train_loss: 0.686442 | avg_loss: 0.688527 | gender_precise: 60.000000 (1400/2304) [18/186]\n",
      "gender_loss: 0.6831042766571045\n",
      "train_loss: 0.683104 | avg_loss: 0.688242 | gender_precise: 61.000000 (1486/2432) [19/186]\n",
      "gender_loss: 0.6889224648475647\n",
      "train_loss: 0.688922 | avg_loss: 0.688276 | gender_precise: 61.000000 (1563/2560) [20/186]\n",
      "gender_loss: 0.6830721497535706\n",
      "train_loss: 0.683072 | avg_loss: 0.688028 | gender_precise: 61.000000 (1648/2688) [21/186]\n",
      "gender_loss: 0.6869175434112549\n",
      "train_loss: 0.686918 | avg_loss: 0.687978 | gender_precise: 61.000000 (1721/2816) [22/186]\n",
      "gender_loss: 0.6882540583610535\n",
      "train_loss: 0.688254 | avg_loss: 0.687990 | gender_precise: 60.000000 (1793/2944) [23/186]\n",
      "gender_loss: 0.684036910533905\n",
      "train_loss: 0.684037 | avg_loss: 0.687825 | gender_precise: 60.000000 (1871/3072) [24/186]\n",
      "gender_loss: 0.6822863817214966\n",
      "train_loss: 0.682286 | avg_loss: 0.687603 | gender_precise: 60.000000 (1948/3200) [25/186]\n",
      "gender_loss: 0.6896753907203674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.689675 | avg_loss: 0.687683 | gender_precise: 60.000000 (2015/3328) [26/186]\n",
      "gender_loss: 0.6835059523582458\n",
      "train_loss: 0.683506 | avg_loss: 0.687528 | gender_precise: 60.000000 (2090/3456) [27/186]\n",
      "gender_loss: 0.6833314895629883\n",
      "train_loss: 0.683331 | avg_loss: 0.687379 | gender_precise: 60.000000 (2164/3584) [28/186]\n",
      "gender_loss: 0.6872897744178772\n",
      "train_loss: 0.687290 | avg_loss: 0.687375 | gender_precise: 60.000000 (2235/3712) [29/186]\n",
      "gender_loss: 0.6788393259048462\n",
      "train_loss: 0.678839 | avg_loss: 0.687091 | gender_precise: 60.000000 (2319/3840) [30/186]\n",
      "gender_loss: 0.6916712522506714\n",
      "train_loss: 0.691671 | avg_loss: 0.687239 | gender_precise: 60.000000 (2387/3968) [31/186]\n",
      "gender_loss: 0.6816034317016602\n",
      "train_loss: 0.681603 | avg_loss: 0.687063 | gender_precise: 60.000000 (2461/4096) [32/186]\n",
      "gender_loss: 0.6876484155654907\n",
      "train_loss: 0.687648 | avg_loss: 0.687080 | gender_precise: 60.000000 (2538/4224) [33/186]\n",
      "gender_loss: 0.6844367384910583\n",
      "train_loss: 0.684437 | avg_loss: 0.687003 | gender_precise: 60.000000 (2614/4352) [34/186]\n",
      "gender_loss: 0.682410478591919\n",
      "train_loss: 0.682410 | avg_loss: 0.686871 | gender_precise: 60.000000 (2691/4480) [35/186]\n",
      "gender_loss: 0.6812569499015808\n",
      "train_loss: 0.681257 | avg_loss: 0.686715 | gender_precise: 60.000000 (2772/4608) [36/186]\n",
      "gender_loss: 0.6782944202423096\n",
      "train_loss: 0.678294 | avg_loss: 0.686488 | gender_precise: 60.000000 (2853/4736) [37/186]\n",
      "gender_loss: 0.6806862354278564\n",
      "train_loss: 0.680686 | avg_loss: 0.686335 | gender_precise: 60.000000 (2931/4864) [38/186]\n",
      "gender_loss: 0.6803567409515381\n",
      "train_loss: 0.680357 | avg_loss: 0.686182 | gender_precise: 60.000000 (3012/4992) [39/186]\n",
      "gender_loss: 0.6828256845474243\n",
      "train_loss: 0.682826 | avg_loss: 0.686098 | gender_precise: 60.000000 (3091/5120) [40/186]\n",
      "gender_loss: 0.6809026002883911\n",
      "train_loss: 0.680903 | avg_loss: 0.685971 | gender_precise: 60.000000 (3170/5248) [41/186]\n",
      "gender_loss: 0.6800780892372131\n",
      "train_loss: 0.680078 | avg_loss: 0.685831 | gender_precise: 60.000000 (3248/5376) [42/186]\n",
      "gender_loss: 0.6759259700775146\n",
      "train_loss: 0.675926 | avg_loss: 0.685601 | gender_precise: 60.000000 (3328/5504) [43/186]\n",
      "gender_loss: 0.6712853908538818\n",
      "train_loss: 0.671285 | avg_loss: 0.685275 | gender_precise: 60.000000 (3414/5632) [44/186]\n",
      "gender_loss: 0.6756746768951416\n",
      "train_loss: 0.675675 | avg_loss: 0.685062 | gender_precise: 60.000000 (3498/5760) [45/186]\n",
      "gender_loss: 0.6740869879722595\n",
      "train_loss: 0.674087 | avg_loss: 0.684823 | gender_precise: 60.000000 (3579/5888) [46/186]\n",
      "gender_loss: 0.6816751956939697\n",
      "train_loss: 0.681675 | avg_loss: 0.684756 | gender_precise: 60.000000 (3655/6016) [47/186]\n",
      "gender_loss: 0.6907488703727722\n",
      "train_loss: 0.690749 | avg_loss: 0.684881 | gender_precise: 60.000000 (3724/6144) [48/186]\n",
      "gender_loss: 0.6761859655380249\n",
      "train_loss: 0.676186 | avg_loss: 0.684704 | gender_precise: 60.000000 (3803/6272) [49/186]\n",
      "gender_loss: 0.6760565042495728\n",
      "train_loss: 0.676057 | avg_loss: 0.684531 | gender_precise: 60.000000 (3880/6400) [50/186]\n",
      "gender_loss: 0.6880611181259155\n",
      "train_loss: 0.688061 | avg_loss: 0.684600 | gender_precise: 60.000000 (3946/6528) [51/186]\n",
      "gender_loss: 0.670923113822937\n",
      "train_loss: 0.670923 | avg_loss: 0.684337 | gender_precise: 60.000000 (4018/6656) [52/186]\n",
      "gender_loss: 0.6802033185958862\n",
      "train_loss: 0.680203 | avg_loss: 0.684259 | gender_precise: 60.000000 (4093/6784) [53/186]\n",
      "gender_loss: 0.6754370927810669\n",
      "train_loss: 0.675437 | avg_loss: 0.684096 | gender_precise: 60.000000 (4171/6912) [54/186]\n",
      "gender_loss: 0.6811172366142273\n",
      "train_loss: 0.681117 | avg_loss: 0.684041 | gender_precise: 60.000000 (4251/7040) [55/186]\n",
      "gender_loss: 0.6736344695091248\n",
      "train_loss: 0.673634 | avg_loss: 0.683856 | gender_precise: 60.000000 (4330/7168) [56/186]\n",
      "gender_loss: 0.6654602885246277\n",
      "train_loss: 0.665460 | avg_loss: 0.683533 | gender_precise: 60.000000 (4410/7296) [57/186]\n",
      "gender_loss: 0.6710498332977295\n",
      "train_loss: 0.671050 | avg_loss: 0.683318 | gender_precise: 60.000000 (4486/7424) [58/186]\n",
      "gender_loss: 0.6553561687469482\n",
      "train_loss: 0.655356 | avg_loss: 0.682844 | gender_precise: 60.000000 (4576/7552) [59/186]\n",
      "gender_loss: 0.6672555804252625\n",
      "train_loss: 0.667256 | avg_loss: 0.682584 | gender_precise: 60.000000 (4657/7680) [60/186]\n",
      "gender_loss: 0.6584056615829468\n",
      "train_loss: 0.658406 | avg_loss: 0.682187 | gender_precise: 60.000000 (4737/7808) [61/186]\n",
      "gender_loss: 0.6725984215736389\n",
      "train_loss: 0.672598 | avg_loss: 0.682033 | gender_precise: 60.000000 (4818/7936) [62/186]\n",
      "gender_loss: 0.6763618588447571\n",
      "train_loss: 0.676362 | avg_loss: 0.681943 | gender_precise: 60.000000 (4890/8064) [63/186]\n",
      "gender_loss: 0.6726943850517273\n",
      "train_loss: 0.672694 | avg_loss: 0.681798 | gender_precise: 60.000000 (4966/8192) [64/186]\n",
      "gender_loss: 0.6651833057403564\n",
      "train_loss: 0.665183 | avg_loss: 0.681543 | gender_precise: 60.000000 (5049/8320) [65/186]\n",
      "gender_loss: 0.6665273308753967\n",
      "train_loss: 0.666527 | avg_loss: 0.681315 | gender_precise: 60.000000 (5133/8448) [66/186]\n",
      "gender_loss: 0.67103111743927\n",
      "train_loss: 0.671031 | avg_loss: 0.681162 | gender_precise: 60.000000 (5217/8576) [67/186]\n",
      "gender_loss: 0.6531144380569458\n",
      "train_loss: 0.653114 | avg_loss: 0.680749 | gender_precise: 60.000000 (5306/8704) [68/186]\n",
      "gender_loss: 0.6605550646781921\n",
      "train_loss: 0.660555 | avg_loss: 0.680457 | gender_precise: 61.000000 (5388/8832) [69/186]\n",
      "gender_loss: 0.667087197303772\n",
      "train_loss: 0.667087 | avg_loss: 0.680266 | gender_precise: 61.000000 (5477/8960) [70/186]\n",
      "gender_loss: 0.6726129651069641\n",
      "train_loss: 0.672613 | avg_loss: 0.680158 | gender_precise: 61.000000 (5556/9088) [71/186]\n",
      "gender_loss: 0.6513074040412903\n",
      "train_loss: 0.651307 | avg_loss: 0.679757 | gender_precise: 61.000000 (5646/9216) [72/186]\n",
      "gender_loss: 0.6477534174919128\n",
      "train_loss: 0.647753 | avg_loss: 0.679319 | gender_precise: 61.000000 (5742/9344) [73/186]\n",
      "gender_loss: 0.6594284176826477\n",
      "train_loss: 0.659428 | avg_loss: 0.679050 | gender_precise: 61.000000 (5824/9472) [74/186]\n",
      "gender_loss: 0.6418906450271606\n",
      "train_loss: 0.641891 | avg_loss: 0.678555 | gender_precise: 61.000000 (5914/9600) [75/186]\n",
      "gender_loss: 0.6574357748031616\n",
      "train_loss: 0.657436 | avg_loss: 0.678277 | gender_precise: 61.000000 (5997/9728) [76/186]\n",
      "gender_loss: 0.6539504528045654\n",
      "train_loss: 0.653950 | avg_loss: 0.677961 | gender_precise: 61.000000 (6080/9856) [77/186]\n",
      "gender_loss: 0.664180338382721\n",
      "train_loss: 0.664180 | avg_loss: 0.677784 | gender_precise: 61.000000 (6164/9984) [78/186]\n",
      "gender_loss: 0.63931804895401\n",
      "train_loss: 0.639318 | avg_loss: 0.677297 | gender_precise: 61.000000 (6254/10112) [79/186]\n",
      "gender_loss: 0.6451135277748108\n",
      "train_loss: 0.645114 | avg_loss: 0.676895 | gender_precise: 61.000000 (6342/10240) [80/186]\n",
      "gender_loss: 0.634411633014679\n",
      "train_loss: 0.634412 | avg_loss: 0.676370 | gender_precise: 61.000000 (6427/10368) [81/186]\n",
      "gender_loss: 0.6780192255973816\n",
      "train_loss: 0.678019 | avg_loss: 0.676390 | gender_precise: 61.000000 (6501/10496) [82/186]\n",
      "gender_loss: 0.6331958174705505\n",
      "train_loss: 0.633196 | avg_loss: 0.675870 | gender_precise: 62.000000 (6590/10624) [83/186]\n",
      "gender_loss: 0.6084293723106384\n",
      "train_loss: 0.608429 | avg_loss: 0.675067 | gender_precise: 62.000000 (6688/10752) [84/186]\n",
      "gender_loss: 0.6288770437240601\n",
      "train_loss: 0.628877 | avg_loss: 0.674524 | gender_precise: 62.000000 (6772/10880) [85/186]\n",
      "gender_loss: 0.6450768709182739\n",
      "train_loss: 0.645077 | avg_loss: 0.674181 | gender_precise: 62.000000 (6860/11008) [86/186]\n",
      "gender_loss: 0.6374543309211731\n",
      "train_loss: 0.637454 | avg_loss: 0.673759 | gender_precise: 62.000000 (6942/11136) [87/186]\n",
      "gender_loss: 0.6047659516334534\n",
      "train_loss: 0.604766 | avg_loss: 0.672975 | gender_precise: 62.000000 (7031/11264) [88/186]\n",
      "gender_loss: 0.6376335620880127\n",
      "train_loss: 0.637634 | avg_loss: 0.672578 | gender_precise: 62.000000 (7109/11392) [89/186]\n",
      "gender_loss: 0.6178040504455566\n",
      "train_loss: 0.617804 | avg_loss: 0.671970 | gender_precise: 62.000000 (7196/11520) [90/186]\n",
      "gender_loss: 0.6244564056396484\n",
      "train_loss: 0.624456 | avg_loss: 0.671447 | gender_precise: 62.000000 (7282/11648) [91/186]\n",
      "gender_loss: 0.6265214085578918\n",
      "train_loss: 0.626521 | avg_loss: 0.670959 | gender_precise: 62.000000 (7366/11776) [92/186]\n",
      "gender_loss: 0.6037329435348511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.603733 | avg_loss: 0.670236 | gender_precise: 62.000000 (7456/11904) [93/186]\n",
      "gender_loss: 0.6167487502098083\n",
      "train_loss: 0.616749 | avg_loss: 0.669667 | gender_precise: 62.000000 (7550/12032) [94/186]\n",
      "gender_loss: 0.6434347629547119\n",
      "train_loss: 0.643435 | avg_loss: 0.669391 | gender_precise: 62.000000 (7632/12160) [95/186]\n",
      "gender_loss: 0.624903678894043\n",
      "train_loss: 0.624904 | avg_loss: 0.668928 | gender_precise: 62.000000 (7722/12288) [96/186]\n",
      "gender_loss: 0.5962358713150024\n",
      "train_loss: 0.596236 | avg_loss: 0.668178 | gender_precise: 62.000000 (7818/12416) [97/186]\n",
      "gender_loss: 0.6144238114356995\n",
      "train_loss: 0.614424 | avg_loss: 0.667630 | gender_precise: 63.000000 (7905/12544) [98/186]\n",
      "gender_loss: 0.6244215965270996\n",
      "train_loss: 0.624422 | avg_loss: 0.667193 | gender_precise: 63.000000 (7989/12672) [99/186]\n",
      "gender_loss: 0.5553866028785706\n",
      "train_loss: 0.555387 | avg_loss: 0.666075 | gender_precise: 63.000000 (8089/12800) [100/186]\n",
      "gender_loss: 0.6009172797203064\n",
      "train_loss: 0.600917 | avg_loss: 0.665430 | gender_precise: 63.000000 (8181/12928) [101/186]\n",
      "gender_loss: 0.579444169998169\n",
      "train_loss: 0.579444 | avg_loss: 0.664587 | gender_precise: 63.000000 (8272/13056) [102/186]\n",
      "gender_loss: 0.5670957565307617\n",
      "train_loss: 0.567096 | avg_loss: 0.663641 | gender_precise: 63.000000 (8368/13184) [103/186]\n",
      "gender_loss: 0.5481047034263611\n",
      "train_loss: 0.548105 | avg_loss: 0.662530 | gender_precise: 63.000000 (8465/13312) [104/186]\n",
      "gender_loss: 0.5410898327827454\n",
      "train_loss: 0.541090 | avg_loss: 0.661373 | gender_precise: 63.000000 (8567/13440) [105/186]\n",
      "gender_loss: 0.5385157465934753\n",
      "train_loss: 0.538516 | avg_loss: 0.660214 | gender_precise: 63.000000 (8665/13568) [106/186]\n",
      "gender_loss: 0.5629931092262268\n",
      "train_loss: 0.562993 | avg_loss: 0.659305 | gender_precise: 63.000000 (8756/13696) [107/186]\n",
      "gender_loss: 0.5524165630340576\n",
      "train_loss: 0.552417 | avg_loss: 0.658316 | gender_precise: 64.000000 (8852/13824) [108/186]\n",
      "gender_loss: 0.5442126393318176\n",
      "train_loss: 0.544213 | avg_loss: 0.657269 | gender_precise: 64.000000 (8945/13952) [109/186]\n",
      "gender_loss: 0.5878554582595825\n",
      "train_loss: 0.587855 | avg_loss: 0.656638 | gender_precise: 64.000000 (9034/14080) [110/186]\n",
      "gender_loss: 0.5391363501548767\n",
      "train_loss: 0.539136 | avg_loss: 0.655579 | gender_precise: 64.000000 (9136/14208) [111/186]\n",
      "gender_loss: 0.525215744972229\n",
      "train_loss: 0.525216 | avg_loss: 0.654415 | gender_precise: 64.000000 (9230/14336) [112/186]\n",
      "gender_loss: 0.5607932209968567\n",
      "train_loss: 0.560793 | avg_loss: 0.653587 | gender_precise: 64.000000 (9325/14464) [113/186]\n",
      "gender_loss: 0.6060155034065247\n",
      "train_loss: 0.606016 | avg_loss: 0.653170 | gender_precise: 64.000000 (9413/14592) [114/186]\n",
      "gender_loss: 0.6168820858001709\n",
      "train_loss: 0.616882 | avg_loss: 0.652854 | gender_precise: 64.000000 (9496/14720) [115/186]\n",
      "gender_loss: 0.6159706115722656\n",
      "train_loss: 0.615971 | avg_loss: 0.652536 | gender_precise: 64.000000 (9582/14848) [116/186]\n",
      "gender_loss: 0.535399854183197\n",
      "train_loss: 0.535400 | avg_loss: 0.651535 | gender_precise: 64.000000 (9679/14976) [117/186]\n",
      "gender_loss: 0.5967593193054199\n",
      "train_loss: 0.596759 | avg_loss: 0.651071 | gender_precise: 64.000000 (9767/15104) [118/186]\n",
      "gender_loss: 0.5318471193313599\n",
      "train_loss: 0.531847 | avg_loss: 0.650069 | gender_precise: 64.000000 (9863/15232) [119/186]\n",
      "gender_loss: 0.6049656867980957\n",
      "train_loss: 0.604966 | avg_loss: 0.649693 | gender_precise: 64.000000 (9949/15360) [120/186]\n",
      "gender_loss: 0.5862309336662292\n",
      "train_loss: 0.586231 | avg_loss: 0.649168 | gender_precise: 64.000000 (10040/15488) [121/186]\n",
      "gender_loss: 0.546064555644989\n",
      "train_loss: 0.546065 | avg_loss: 0.648323 | gender_precise: 64.000000 (10132/15616) [122/186]\n",
      "gender_loss: 0.5368065237998962\n",
      "train_loss: 0.536807 | avg_loss: 0.647417 | gender_precise: 64.000000 (10228/15744) [123/186]\n",
      "gender_loss: 0.514507532119751\n",
      "train_loss: 0.514508 | avg_loss: 0.646345 | gender_precise: 65.000000 (10326/15872) [124/186]\n",
      "gender_loss: 0.5476889610290527\n",
      "train_loss: 0.547689 | avg_loss: 0.645556 | gender_precise: 65.000000 (10422/16000) [125/186]\n",
      "gender_loss: 0.49783065915107727\n",
      "train_loss: 0.497831 | avg_loss: 0.644383 | gender_precise: 65.000000 (10521/16128) [126/186]\n",
      "gender_loss: 0.49500754475593567\n",
      "train_loss: 0.495008 | avg_loss: 0.643207 | gender_precise: 65.000000 (10621/16256) [127/186]\n",
      "gender_loss: 0.5220515727996826\n",
      "train_loss: 0.522052 | avg_loss: 0.642260 | gender_precise: 65.000000 (10717/16384) [128/186]\n",
      "gender_loss: 0.43467357754707336\n",
      "train_loss: 0.434674 | avg_loss: 0.640651 | gender_precise: 65.000000 (10828/16512) [129/186]\n",
      "gender_loss: 0.5706571340560913\n",
      "train_loss: 0.570657 | avg_loss: 0.640113 | gender_precise: 65.000000 (10921/16640) [130/186]\n",
      "gender_loss: 0.5454504489898682\n",
      "train_loss: 0.545450 | avg_loss: 0.639390 | gender_precise: 65.000000 (11014/16768) [131/186]\n",
      "gender_loss: 0.490019291639328\n",
      "train_loss: 0.490019 | avg_loss: 0.638259 | gender_precise: 65.000000 (11115/16896) [132/186]\n",
      "gender_loss: 0.5034734606742859\n",
      "train_loss: 0.503473 | avg_loss: 0.637245 | gender_precise: 65.000000 (11214/17024) [133/186]\n",
      "gender_loss: 0.48125484585762024\n",
      "train_loss: 0.481255 | avg_loss: 0.636081 | gender_precise: 65.000000 (11314/17152) [134/186]\n",
      "gender_loss: 0.5310906171798706\n",
      "train_loss: 0.531091 | avg_loss: 0.635303 | gender_precise: 66.000000 (11411/17280) [135/186]\n",
      "gender_loss: 0.3901337683200836\n",
      "train_loss: 0.390134 | avg_loss: 0.633501 | gender_precise: 66.000000 (11523/17408) [136/186]\n",
      "gender_loss: 0.4532020092010498\n",
      "train_loss: 0.453202 | avg_loss: 0.632185 | gender_precise: 66.000000 (11621/17536) [137/186]\n",
      "gender_loss: 0.523007869720459\n",
      "train_loss: 0.523008 | avg_loss: 0.631394 | gender_precise: 66.000000 (11719/17664) [138/186]\n",
      "gender_loss: 0.5381527543067932\n",
      "train_loss: 0.538153 | avg_loss: 0.630723 | gender_precise: 66.000000 (11808/17792) [139/186]\n",
      "gender_loss: 0.4676380753517151\n",
      "train_loss: 0.467638 | avg_loss: 0.629558 | gender_precise: 66.000000 (11909/17920) [140/186]\n",
      "gender_loss: 0.5066344141960144\n",
      "train_loss: 0.506634 | avg_loss: 0.628686 | gender_precise: 66.000000 (12013/18048) [141/186]\n",
      "gender_loss: 0.5780620574951172\n",
      "train_loss: 0.578062 | avg_loss: 0.628330 | gender_precise: 66.000000 (12102/18176) [142/186]\n",
      "gender_loss: 0.5289793014526367\n",
      "train_loss: 0.528979 | avg_loss: 0.627635 | gender_precise: 66.000000 (12201/18304) [143/186]\n",
      "gender_loss: 0.6012816429138184\n",
      "train_loss: 0.601282 | avg_loss: 0.627452 | gender_precise: 66.000000 (12293/18432) [144/186]\n",
      "gender_loss: 0.5478402376174927\n",
      "train_loss: 0.547840 | avg_loss: 0.626903 | gender_precise: 66.000000 (12394/18560) [145/186]\n",
      "gender_loss: 0.532679557800293\n",
      "train_loss: 0.532680 | avg_loss: 0.626257 | gender_precise: 66.000000 (12491/18688) [146/186]\n",
      "gender_loss: 0.5401504635810852\n",
      "train_loss: 0.540150 | avg_loss: 0.625672 | gender_precise: 66.000000 (12586/18816) [147/186]\n",
      "gender_loss: 0.6015356779098511\n",
      "train_loss: 0.601536 | avg_loss: 0.625509 | gender_precise: 66.000000 (12675/18944) [148/186]\n",
      "gender_loss: 0.492074191570282\n",
      "train_loss: 0.492074 | avg_loss: 0.624613 | gender_precise: 66.000000 (12771/19072) [149/186]\n",
      "gender_loss: 0.5234221816062927\n",
      "train_loss: 0.523422 | avg_loss: 0.623938 | gender_precise: 66.000000 (12863/19200) [150/186]\n",
      "gender_loss: 0.5200764536857605\n",
      "train_loss: 0.520076 | avg_loss: 0.623251 | gender_precise: 67.000000 (12957/19328) [151/186]\n",
      "gender_loss: 0.4941706955432892\n",
      "train_loss: 0.494171 | avg_loss: 0.622401 | gender_precise: 67.000000 (13057/19456) [152/186]\n",
      "gender_loss: 0.4824642241001129\n",
      "train_loss: 0.482464 | avg_loss: 0.621487 | gender_precise: 67.000000 (13160/19584) [153/186]\n",
      "gender_loss: 0.550417423248291\n",
      "train_loss: 0.550417 | avg_loss: 0.621025 | gender_precise: 67.000000 (13258/19712) [154/186]\n",
      "gender_loss: 0.4555763006210327\n",
      "train_loss: 0.455576 | avg_loss: 0.619958 | gender_precise: 67.000000 (13358/19840) [155/186]\n",
      "gender_loss: 0.4782032370567322\n",
      "train_loss: 0.478203 | avg_loss: 0.619049 | gender_precise: 67.000000 (13459/19968) [156/186]\n",
      "gender_loss: 0.4877837002277374\n",
      "train_loss: 0.487784 | avg_loss: 0.618213 | gender_precise: 67.000000 (13557/20096) [157/186]\n",
      "gender_loss: 0.4512713849544525\n",
      "train_loss: 0.451271 | avg_loss: 0.617156 | gender_precise: 67.000000 (13659/20224) [158/186]\n",
      "gender_loss: 0.507548451423645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.507548 | avg_loss: 0.616467 | gender_precise: 67.000000 (13754/20352) [159/186]\n",
      "gender_loss: 0.4338093400001526\n",
      "train_loss: 0.433809 | avg_loss: 0.615325 | gender_precise: 67.000000 (13861/20480) [160/186]\n",
      "gender_loss: 0.4566800892353058\n",
      "train_loss: 0.456680 | avg_loss: 0.614340 | gender_precise: 67.000000 (13959/20608) [161/186]\n",
      "gender_loss: 0.4553655982017517\n",
      "train_loss: 0.455366 | avg_loss: 0.613359 | gender_precise: 67.000000 (14056/20736) [162/186]\n",
      "gender_loss: 0.42951643466949463\n",
      "train_loss: 0.429516 | avg_loss: 0.612231 | gender_precise: 67.000000 (14157/20864) [163/186]\n",
      "gender_loss: 0.39813148975372314\n",
      "train_loss: 0.398131 | avg_loss: 0.610925 | gender_precise: 67.000000 (14264/20992) [164/186]\n",
      "gender_loss: 0.46134722232818604\n",
      "train_loss: 0.461347 | avg_loss: 0.610019 | gender_precise: 68.000000 (14364/21120) [165/186]\n",
      "gender_loss: 0.4579216241836548\n",
      "train_loss: 0.457922 | avg_loss: 0.609103 | gender_precise: 68.000000 (14465/21248) [166/186]\n",
      "gender_loss: 0.439752995967865\n",
      "train_loss: 0.439753 | avg_loss: 0.608089 | gender_precise: 68.000000 (14571/21376) [167/186]\n",
      "gender_loss: 0.4826700687408447\n",
      "train_loss: 0.482670 | avg_loss: 0.607342 | gender_precise: 68.000000 (14669/21504) [168/186]\n",
      "gender_loss: 0.39205625653266907\n",
      "train_loss: 0.392056 | avg_loss: 0.606068 | gender_precise: 68.000000 (14780/21632) [169/186]\n",
      "gender_loss: 0.42669203877449036\n",
      "train_loss: 0.426692 | avg_loss: 0.605013 | gender_precise: 68.000000 (14885/21760) [170/186]\n",
      "gender_loss: 0.5293684601783752\n",
      "train_loss: 0.529368 | avg_loss: 0.604571 | gender_precise: 68.000000 (14984/21888) [171/186]\n",
      "gender_loss: 0.3656642436981201\n",
      "train_loss: 0.365664 | avg_loss: 0.603182 | gender_precise: 68.000000 (15093/22016) [172/186]\n",
      "gender_loss: 0.44101038575172424\n",
      "train_loss: 0.441010 | avg_loss: 0.602244 | gender_precise: 68.000000 (15195/22144) [173/186]\n",
      "gender_loss: 0.40215015411376953\n",
      "train_loss: 0.402150 | avg_loss: 0.601094 | gender_precise: 68.000000 (15299/22272) [174/186]\n",
      "gender_loss: 0.4192781150341034\n",
      "train_loss: 0.419278 | avg_loss: 0.600055 | gender_precise: 68.000000 (15403/22400) [175/186]\n",
      "gender_loss: 0.4696284830570221\n",
      "train_loss: 0.469628 | avg_loss: 0.599314 | gender_precise: 68.000000 (15501/22528) [176/186]\n",
      "gender_loss: 0.4117145240306854\n",
      "train_loss: 0.411715 | avg_loss: 0.598254 | gender_precise: 68.000000 (15602/22656) [177/186]\n",
      "gender_loss: 0.44227302074432373\n",
      "train_loss: 0.442273 | avg_loss: 0.597378 | gender_precise: 68.000000 (15701/22784) [178/186]\n",
      "gender_loss: 0.5455403923988342\n",
      "train_loss: 0.545540 | avg_loss: 0.597089 | gender_precise: 68.000000 (15797/22912) [179/186]\n",
      "gender_loss: 0.430077463388443\n",
      "train_loss: 0.430077 | avg_loss: 0.596161 | gender_precise: 69.000000 (15904/23040) [180/186]\n",
      "gender_loss: 0.44655194878578186\n",
      "train_loss: 0.446552 | avg_loss: 0.595334 | gender_precise: 69.000000 (16005/23168) [181/186]\n",
      "gender_loss: 0.4317358732223511\n",
      "train_loss: 0.431736 | avg_loss: 0.594435 | gender_precise: 69.000000 (16107/23296) [182/186]\n",
      "gender_loss: 0.3752480745315552\n",
      "train_loss: 0.375248 | avg_loss: 0.593237 | gender_precise: 69.000000 (16217/23424) [183/186]\n",
      "gender_loss: 0.43013158440589905\n",
      "train_loss: 0.430132 | avg_loss: 0.592351 | gender_precise: 69.000000 (16321/23552) [184/186]\n",
      "gender_loss: 0.5520778298377991\n",
      "train_loss: 0.552078 | avg_loss: 0.592133 | gender_precise: 69.000000 (16416/23680) [185/186]\n",
      "gender_loss: 0.3970341384410858\n",
      "train_loss: 0.397034 | avg_loss: 0.591084 | gender_precise: 69.000000 (16437/23708) [186/186]\n",
      "\n",
      "Test\n",
      "gender_prec: 76.000000 (98/128) [1/2]\n",
      "gender_prec: 75.000000 (101/134) [2/2]\n",
      "Saving..\n",
      "Number epoch: 3\n",
      "gender_loss: 0.467555969953537\n",
      "train_loss: 0.467556 | avg_loss: 0.467556 | gender_precise: 78.000000 (100/128) [1/186]\n",
      "gender_loss: 0.43396231532096863\n",
      "train_loss: 0.433962 | avg_loss: 0.450759 | gender_precise: 78.000000 (202/256) [2/186]\n",
      "gender_loss: 0.41316482424736023\n",
      "train_loss: 0.413165 | avg_loss: 0.438228 | gender_precise: 79.000000 (304/384) [3/186]\n",
      "gender_loss: 0.3929135799407959\n",
      "train_loss: 0.392914 | avg_loss: 0.426899 | gender_precise: 80.000000 (411/512) [4/186]\n",
      "gender_loss: 0.40644192695617676\n",
      "train_loss: 0.406442 | avg_loss: 0.422808 | gender_precise: 80.000000 (517/640) [5/186]\n",
      "gender_loss: 0.4506203830242157\n",
      "train_loss: 0.450620 | avg_loss: 0.427443 | gender_precise: 80.000000 (618/768) [6/186]\n",
      "gender_loss: 0.43424665927886963\n",
      "train_loss: 0.434247 | avg_loss: 0.428415 | gender_precise: 80.000000 (720/896) [7/186]\n",
      "gender_loss: 0.4391785264015198\n",
      "train_loss: 0.439179 | avg_loss: 0.429761 | gender_precise: 79.000000 (818/1024) [8/186]\n",
      "gender_loss: 0.5393478870391846\n",
      "train_loss: 0.539348 | avg_loss: 0.441937 | gender_precise: 79.000000 (913/1152) [9/186]\n",
      "gender_loss: 0.5174084305763245\n",
      "train_loss: 0.517408 | avg_loss: 0.449484 | gender_precise: 79.000000 (1013/1280) [10/186]\n",
      "gender_loss: 0.37880244851112366\n",
      "train_loss: 0.378802 | avg_loss: 0.443058 | gender_precise: 79.000000 (1119/1408) [11/186]\n",
      "gender_loss: 0.49889469146728516\n",
      "train_loss: 0.498895 | avg_loss: 0.447711 | gender_precise: 79.000000 (1222/1536) [12/186]\n",
      "gender_loss: 0.34030258655548096\n",
      "train_loss: 0.340303 | avg_loss: 0.439449 | gender_precise: 80.000000 (1335/1664) [13/186]\n",
      "gender_loss: 0.4217723608016968\n",
      "train_loss: 0.421772 | avg_loss: 0.438187 | gender_precise: 80.000000 (1437/1792) [14/186]\n",
      "gender_loss: 0.412800133228302\n",
      "train_loss: 0.412800 | avg_loss: 0.436494 | gender_precise: 80.000000 (1540/1920) [15/186]\n",
      "gender_loss: 0.4394600987434387\n",
      "train_loss: 0.439460 | avg_loss: 0.436680 | gender_precise: 80.000000 (1641/2048) [16/186]\n",
      "gender_loss: 0.38662654161453247\n",
      "train_loss: 0.386627 | avg_loss: 0.433735 | gender_precise: 80.000000 (1745/2176) [17/186]\n",
      "gender_loss: 0.33538568019866943\n",
      "train_loss: 0.335386 | avg_loss: 0.428271 | gender_precise: 80.000000 (1854/2304) [18/186]\n",
      "gender_loss: 0.5358148217201233\n",
      "train_loss: 0.535815 | avg_loss: 0.433932 | gender_precise: 80.000000 (1956/2432) [19/186]\n",
      "gender_loss: 0.44577473402023315\n",
      "train_loss: 0.445775 | avg_loss: 0.434524 | gender_precise: 80.000000 (2059/2560) [20/186]\n",
      "gender_loss: 0.3568391799926758\n",
      "train_loss: 0.356839 | avg_loss: 0.430825 | gender_precise: 80.000000 (2171/2688) [21/186]\n",
      "gender_loss: 0.41614624857902527\n",
      "train_loss: 0.416146 | avg_loss: 0.430157 | gender_precise: 80.000000 (2279/2816) [22/186]\n",
      "gender_loss: 0.4245319664478302\n",
      "train_loss: 0.424532 | avg_loss: 0.429913 | gender_precise: 80.000000 (2379/2944) [23/186]\n",
      "gender_loss: 0.41527774930000305\n",
      "train_loss: 0.415278 | avg_loss: 0.429303 | gender_precise: 80.000000 (2482/3072) [24/186]\n",
      "gender_loss: 0.4067036211490631\n",
      "train_loss: 0.406704 | avg_loss: 0.428399 | gender_precise: 80.000000 (2587/3200) [25/186]\n",
      "gender_loss: 0.45038142800331116\n",
      "train_loss: 0.450381 | avg_loss: 0.429244 | gender_precise: 80.000000 (2688/3328) [26/186]\n",
      "gender_loss: 0.39361217617988586\n",
      "train_loss: 0.393612 | avg_loss: 0.427925 | gender_precise: 80.000000 (2791/3456) [27/186]\n",
      "gender_loss: 0.3838001489639282\n",
      "train_loss: 0.383800 | avg_loss: 0.426349 | gender_precise: 80.000000 (2898/3584) [28/186]\n",
      "gender_loss: 0.34260696172714233\n",
      "train_loss: 0.342607 | avg_loss: 0.423461 | gender_precise: 81.000000 (3012/3712) [29/186]\n",
      "gender_loss: 0.4149121940135956\n",
      "train_loss: 0.414912 | avg_loss: 0.423176 | gender_precise: 81.000000 (3116/3840) [30/186]\n",
      "gender_loss: 0.3812345862388611\n",
      "train_loss: 0.381235 | avg_loss: 0.421823 | gender_precise: 81.000000 (3224/3968) [31/186]\n",
      "gender_loss: 0.39582908153533936\n",
      "train_loss: 0.395829 | avg_loss: 0.421011 | gender_precise: 81.000000 (3327/4096) [32/186]\n",
      "gender_loss: 0.3375861942768097\n",
      "train_loss: 0.337586 | avg_loss: 0.418483 | gender_precise: 81.000000 (3434/4224) [33/186]\n",
      "gender_loss: 0.36854538321495056\n",
      "train_loss: 0.368545 | avg_loss: 0.417014 | gender_precise: 81.000000 (3543/4352) [34/186]\n",
      "gender_loss: 0.4043442904949188\n",
      "train_loss: 0.404344 | avg_loss: 0.416652 | gender_precise: 81.000000 (3649/4480) [35/186]\n",
      "gender_loss: 0.3944137990474701\n",
      "train_loss: 0.394414 | avg_loss: 0.416034 | gender_precise: 81.000000 (3755/4608) [36/186]\n",
      "gender_loss: 0.46757858991622925\n",
      "train_loss: 0.467579 | avg_loss: 0.417428 | gender_precise: 81.000000 (3855/4736) [37/186]\n",
      "gender_loss: 0.3888038098812103\n",
      "train_loss: 0.388804 | avg_loss: 0.416674 | gender_precise: 81.000000 (3958/4864) [38/186]\n",
      "gender_loss: 0.3751852810382843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.375185 | avg_loss: 0.415610 | gender_precise: 81.000000 (4067/4992) [39/186]\n",
      "gender_loss: 0.3291642367839813\n",
      "train_loss: 0.329164 | avg_loss: 0.413449 | gender_precise: 81.000000 (4176/5120) [40/186]\n",
      "gender_loss: 0.342203825712204\n",
      "train_loss: 0.342204 | avg_loss: 0.411712 | gender_precise: 81.000000 (4283/5248) [41/186]\n",
      "gender_loss: 0.2798180878162384\n",
      "train_loss: 0.279818 | avg_loss: 0.408571 | gender_precise: 81.000000 (4398/5376) [42/186]\n",
      "gender_loss: 0.34360629320144653\n",
      "train_loss: 0.343606 | avg_loss: 0.407060 | gender_precise: 81.000000 (4507/5504) [43/186]\n",
      "gender_loss: 0.38674548268318176\n",
      "train_loss: 0.386745 | avg_loss: 0.406599 | gender_precise: 81.000000 (4614/5632) [44/186]\n",
      "gender_loss: 0.2982025742530823\n",
      "train_loss: 0.298203 | avg_loss: 0.404190 | gender_precise: 82.000000 (4725/5760) [45/186]\n",
      "gender_loss: 0.37577080726623535\n",
      "train_loss: 0.375771 | avg_loss: 0.403572 | gender_precise: 82.000000 (4830/5888) [46/186]\n",
      "gender_loss: 0.3592092990875244\n",
      "train_loss: 0.359209 | avg_loss: 0.402628 | gender_precise: 82.000000 (4937/6016) [47/186]\n",
      "gender_loss: 0.4107419550418854\n",
      "train_loss: 0.410742 | avg_loss: 0.402797 | gender_precise: 82.000000 (5046/6144) [48/186]\n",
      "gender_loss: 0.33664044737815857\n",
      "train_loss: 0.336640 | avg_loss: 0.401447 | gender_precise: 82.000000 (5155/6272) [49/186]\n",
      "gender_loss: 0.3645005524158478\n",
      "train_loss: 0.364501 | avg_loss: 0.400708 | gender_precise: 82.000000 (5262/6400) [50/186]\n",
      "gender_loss: 0.32690122723579407\n",
      "train_loss: 0.326901 | avg_loss: 0.399261 | gender_precise: 82.000000 (5375/6528) [51/186]\n",
      "gender_loss: 0.3175436556339264\n",
      "train_loss: 0.317544 | avg_loss: 0.397690 | gender_precise: 82.000000 (5488/6656) [52/186]\n",
      "gender_loss: 0.3296763300895691\n",
      "train_loss: 0.329676 | avg_loss: 0.396406 | gender_precise: 82.000000 (5596/6784) [53/186]\n",
      "gender_loss: 0.43966352939605713\n",
      "train_loss: 0.439664 | avg_loss: 0.397207 | gender_precise: 82.000000 (5703/6912) [54/186]\n",
      "gender_loss: 0.3465309739112854\n",
      "train_loss: 0.346531 | avg_loss: 0.396286 | gender_precise: 82.000000 (5812/7040) [55/186]\n",
      "gender_loss: 0.3750144839286804\n",
      "train_loss: 0.375014 | avg_loss: 0.395906 | gender_precise: 82.000000 (5916/7168) [56/186]\n",
      "gender_loss: 0.3402261435985565\n",
      "train_loss: 0.340226 | avg_loss: 0.394929 | gender_precise: 82.000000 (6023/7296) [57/186]\n",
      "gender_loss: 0.3104206621646881\n",
      "train_loss: 0.310421 | avg_loss: 0.393472 | gender_precise: 82.000000 (6134/7424) [58/186]\n",
      "gender_loss: 0.32633766531944275\n",
      "train_loss: 0.326338 | avg_loss: 0.392334 | gender_precise: 82.000000 (6241/7552) [59/186]\n",
      "gender_loss: 0.46183276176452637\n",
      "train_loss: 0.461833 | avg_loss: 0.393493 | gender_precise: 82.000000 (6343/7680) [60/186]\n",
      "gender_loss: 0.27886462211608887\n",
      "train_loss: 0.278865 | avg_loss: 0.391613 | gender_precise: 82.000000 (6461/7808) [61/186]\n",
      "gender_loss: 0.3030344545841217\n",
      "train_loss: 0.303034 | avg_loss: 0.390185 | gender_precise: 82.000000 (6574/7936) [62/186]\n",
      "gender_loss: 0.43079763650894165\n",
      "train_loss: 0.430798 | avg_loss: 0.390829 | gender_precise: 82.000000 (6676/8064) [63/186]\n",
      "gender_loss: 0.31969311833381653\n",
      "train_loss: 0.319693 | avg_loss: 0.389718 | gender_precise: 82.000000 (6788/8192) [64/186]\n",
      "gender_loss: 0.36337175965309143\n",
      "train_loss: 0.363372 | avg_loss: 0.389313 | gender_precise: 82.000000 (6895/8320) [65/186]\n",
      "gender_loss: 0.33851224184036255\n",
      "train_loss: 0.338512 | avg_loss: 0.388543 | gender_precise: 82.000000 (7005/8448) [66/186]\n",
      "gender_loss: 0.34243130683898926\n",
      "train_loss: 0.342431 | avg_loss: 0.387855 | gender_precise: 82.000000 (7108/8576) [67/186]\n",
      "gender_loss: 0.40971624851226807\n",
      "train_loss: 0.409716 | avg_loss: 0.388176 | gender_precise: 82.000000 (7212/8704) [68/186]\n",
      "gender_loss: 0.287727415561676\n",
      "train_loss: 0.287727 | avg_loss: 0.386720 | gender_precise: 82.000000 (7323/8832) [69/186]\n",
      "gender_loss: 0.2892392575740814\n",
      "train_loss: 0.289239 | avg_loss: 0.385328 | gender_precise: 82.000000 (7434/8960) [70/186]\n",
      "gender_loss: 0.31210029125213623\n",
      "train_loss: 0.312100 | avg_loss: 0.384296 | gender_precise: 83.000000 (7546/9088) [71/186]\n",
      "gender_loss: 0.2732909321784973\n",
      "train_loss: 0.273291 | avg_loss: 0.382755 | gender_precise: 83.000000 (7662/9216) [72/186]\n",
      "gender_loss: 0.27918553352355957\n",
      "train_loss: 0.279186 | avg_loss: 0.381336 | gender_precise: 83.000000 (7776/9344) [73/186]\n",
      "gender_loss: 0.3044510781764984\n",
      "train_loss: 0.304451 | avg_loss: 0.380297 | gender_precise: 83.000000 (7884/9472) [74/186]\n",
      "gender_loss: 0.2982095181941986\n",
      "train_loss: 0.298210 | avg_loss: 0.379202 | gender_precise: 83.000000 (7995/9600) [75/186]\n",
      "gender_loss: 0.33042025566101074\n",
      "train_loss: 0.330420 | avg_loss: 0.378561 | gender_precise: 83.000000 (8101/9728) [76/186]\n",
      "gender_loss: 0.2862832546234131\n",
      "train_loss: 0.286283 | avg_loss: 0.377362 | gender_precise: 83.000000 (8213/9856) [77/186]\n",
      "gender_loss: 0.3746188282966614\n",
      "train_loss: 0.374619 | avg_loss: 0.377327 | gender_precise: 83.000000 (8319/9984) [78/186]\n",
      "gender_loss: 0.3293136954307556\n",
      "train_loss: 0.329314 | avg_loss: 0.376719 | gender_precise: 83.000000 (8431/10112) [79/186]\n",
      "gender_loss: 0.42765378952026367\n",
      "train_loss: 0.427654 | avg_loss: 0.377356 | gender_precise: 83.000000 (8537/10240) [80/186]\n",
      "gender_loss: 0.41028186678886414\n",
      "train_loss: 0.410282 | avg_loss: 0.377762 | gender_precise: 83.000000 (8637/10368) [81/186]\n",
      "gender_loss: 0.3206818103790283\n",
      "train_loss: 0.320682 | avg_loss: 0.377066 | gender_precise: 83.000000 (8748/10496) [82/186]\n",
      "gender_loss: 0.28704357147216797\n",
      "train_loss: 0.287044 | avg_loss: 0.375982 | gender_precise: 83.000000 (8859/10624) [83/186]\n",
      "gender_loss: 0.29481592774391174\n",
      "train_loss: 0.294816 | avg_loss: 0.375015 | gender_precise: 83.000000 (8970/10752) [84/186]\n",
      "gender_loss: 0.36057519912719727\n",
      "train_loss: 0.360575 | avg_loss: 0.374846 | gender_precise: 83.000000 (9081/10880) [85/186]\n",
      "gender_loss: 0.46511590480804443\n",
      "train_loss: 0.465116 | avg_loss: 0.375895 | gender_precise: 83.000000 (9177/11008) [86/186]\n",
      "gender_loss: 0.3828538954257965\n",
      "train_loss: 0.382854 | avg_loss: 0.375975 | gender_precise: 83.000000 (9285/11136) [87/186]\n",
      "gender_loss: 0.3354824185371399\n",
      "train_loss: 0.335482 | avg_loss: 0.375515 | gender_precise: 83.000000 (9397/11264) [88/186]\n",
      "gender_loss: 0.35864025354385376\n",
      "train_loss: 0.358640 | avg_loss: 0.375325 | gender_precise: 83.000000 (9507/11392) [89/186]\n",
      "gender_loss: 0.3214394450187683\n",
      "train_loss: 0.321439 | avg_loss: 0.374727 | gender_precise: 83.000000 (9618/11520) [90/186]\n",
      "gender_loss: 0.45462390780448914\n",
      "train_loss: 0.454624 | avg_loss: 0.375605 | gender_precise: 83.000000 (9721/11648) [91/186]\n",
      "gender_loss: 0.34294044971466064\n",
      "train_loss: 0.342940 | avg_loss: 0.375250 | gender_precise: 83.000000 (9829/11776) [92/186]\n",
      "gender_loss: 0.35890159010887146\n",
      "train_loss: 0.358902 | avg_loss: 0.375074 | gender_precise: 83.000000 (9935/11904) [93/186]\n",
      "gender_loss: 0.4142206013202667\n",
      "train_loss: 0.414221 | avg_loss: 0.375490 | gender_precise: 83.000000 (10036/12032) [94/186]\n",
      "gender_loss: 0.2798589766025543\n",
      "train_loss: 0.279859 | avg_loss: 0.374484 | gender_precise: 83.000000 (10149/12160) [95/186]\n",
      "gender_loss: 0.3449002504348755\n",
      "train_loss: 0.344900 | avg_loss: 0.374175 | gender_precise: 83.000000 (10254/12288) [96/186]\n",
      "gender_loss: 0.31019899249076843\n",
      "train_loss: 0.310199 | avg_loss: 0.373516 | gender_precise: 83.000000 (10362/12416) [97/186]\n",
      "gender_loss: 0.37199866771698\n",
      "train_loss: 0.371999 | avg_loss: 0.373500 | gender_precise: 83.000000 (10467/12544) [98/186]\n",
      "gender_loss: 0.3580065965652466\n",
      "train_loss: 0.358007 | avg_loss: 0.373344 | gender_precise: 83.000000 (10576/12672) [99/186]\n",
      "gender_loss: 0.31648433208465576\n",
      "train_loss: 0.316484 | avg_loss: 0.372775 | gender_precise: 83.000000 (10688/12800) [100/186]\n",
      "gender_loss: 0.3224312365055084\n",
      "train_loss: 0.322431 | avg_loss: 0.372277 | gender_precise: 83.000000 (10797/12928) [101/186]\n",
      "gender_loss: 0.35233408212661743\n",
      "train_loss: 0.352334 | avg_loss: 0.372081 | gender_precise: 83.000000 (10905/13056) [102/186]\n",
      "gender_loss: 0.28255289793014526\n",
      "train_loss: 0.282553 | avg_loss: 0.371212 | gender_precise: 83.000000 (11014/13184) [103/186]\n",
      "gender_loss: 0.2944536805152893\n",
      "train_loss: 0.294454 | avg_loss: 0.370474 | gender_precise: 83.000000 (11127/13312) [104/186]\n",
      "gender_loss: 0.3865452706813812\n",
      "train_loss: 0.386545 | avg_loss: 0.370627 | gender_precise: 83.000000 (11233/13440) [105/186]\n",
      "gender_loss: 0.3353002965450287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.335300 | avg_loss: 0.370294 | gender_precise: 83.000000 (11342/13568) [106/186]\n",
      "gender_loss: 0.38431769609451294\n",
      "train_loss: 0.384318 | avg_loss: 0.370425 | gender_precise: 83.000000 (11447/13696) [107/186]\n",
      "gender_loss: 0.2924637496471405\n",
      "train_loss: 0.292464 | avg_loss: 0.369703 | gender_precise: 83.000000 (11557/13824) [108/186]\n",
      "gender_loss: 0.34408560395240784\n",
      "train_loss: 0.344086 | avg_loss: 0.369468 | gender_precise: 83.000000 (11665/13952) [109/186]\n",
      "gender_loss: 0.2321425825357437\n",
      "train_loss: 0.232143 | avg_loss: 0.368220 | gender_precise: 83.000000 (11781/14080) [110/186]\n",
      "gender_loss: 0.28845828771591187\n",
      "train_loss: 0.288458 | avg_loss: 0.367501 | gender_precise: 83.000000 (11891/14208) [111/186]\n",
      "gender_loss: 0.3432818353176117\n",
      "train_loss: 0.343282 | avg_loss: 0.367285 | gender_precise: 83.000000 (11998/14336) [112/186]\n",
      "gender_loss: 0.2802627682685852\n",
      "train_loss: 0.280263 | avg_loss: 0.366515 | gender_precise: 83.000000 (12108/14464) [113/186]\n",
      "gender_loss: 0.31969842314720154\n",
      "train_loss: 0.319698 | avg_loss: 0.366104 | gender_precise: 83.000000 (12221/14592) [114/186]\n",
      "gender_loss: 0.25661274790763855\n",
      "train_loss: 0.256613 | avg_loss: 0.365152 | gender_precise: 83.000000 (12332/14720) [115/186]\n",
      "gender_loss: 0.37085655331611633\n",
      "train_loss: 0.370857 | avg_loss: 0.365201 | gender_precise: 83.000000 (12440/14848) [116/186]\n",
      "gender_loss: 0.3177489638328552\n",
      "train_loss: 0.317749 | avg_loss: 0.364796 | gender_precise: 83.000000 (12551/14976) [117/186]\n",
      "gender_loss: 0.2927560806274414\n",
      "train_loss: 0.292756 | avg_loss: 0.364185 | gender_precise: 83.000000 (12661/15104) [118/186]\n",
      "gender_loss: 0.3110691010951996\n",
      "train_loss: 0.311069 | avg_loss: 0.363739 | gender_precise: 83.000000 (12774/15232) [119/186]\n",
      "gender_loss: 0.38319915533065796\n",
      "train_loss: 0.383199 | avg_loss: 0.363901 | gender_precise: 83.000000 (12887/15360) [120/186]\n",
      "gender_loss: 0.30791568756103516\n",
      "train_loss: 0.307916 | avg_loss: 0.363438 | gender_precise: 83.000000 (12996/15488) [121/186]\n",
      "gender_loss: 0.3335167169570923\n",
      "train_loss: 0.333517 | avg_loss: 0.363193 | gender_precise: 83.000000 (13107/15616) [122/186]\n",
      "gender_loss: 0.3208147883415222\n",
      "train_loss: 0.320815 | avg_loss: 0.362848 | gender_precise: 83.000000 (13218/15744) [123/186]\n",
      "gender_loss: 0.2713260352611542\n",
      "train_loss: 0.271326 | avg_loss: 0.362110 | gender_precise: 83.000000 (13330/15872) [124/186]\n",
      "gender_loss: 0.34602412581443787\n",
      "train_loss: 0.346024 | avg_loss: 0.361982 | gender_precise: 83.000000 (13438/16000) [125/186]\n",
      "gender_loss: 0.29975536465644836\n",
      "train_loss: 0.299755 | avg_loss: 0.361488 | gender_precise: 84.000000 (13549/16128) [126/186]\n",
      "gender_loss: 0.3077034056186676\n",
      "train_loss: 0.307703 | avg_loss: 0.361064 | gender_precise: 84.000000 (13660/16256) [127/186]\n",
      "gender_loss: 0.34271159768104553\n",
      "train_loss: 0.342712 | avg_loss: 0.360921 | gender_precise: 84.000000 (13769/16384) [128/186]\n",
      "gender_loss: 0.26943713426589966\n",
      "train_loss: 0.269437 | avg_loss: 0.360212 | gender_precise: 84.000000 (13877/16512) [129/186]\n",
      "gender_loss: 0.36983656883239746\n",
      "train_loss: 0.369837 | avg_loss: 0.360286 | gender_precise: 84.000000 (13981/16640) [130/186]\n",
      "gender_loss: 0.3435731530189514\n",
      "train_loss: 0.343573 | avg_loss: 0.360158 | gender_precise: 84.000000 (14090/16768) [131/186]\n",
      "gender_loss: 0.3625276982784271\n",
      "train_loss: 0.362528 | avg_loss: 0.360176 | gender_precise: 84.000000 (14202/16896) [132/186]\n",
      "gender_loss: 0.354743093252182\n",
      "train_loss: 0.354743 | avg_loss: 0.360135 | gender_precise: 84.000000 (14309/17024) [133/186]\n",
      "gender_loss: 0.2994810938835144\n",
      "train_loss: 0.299481 | avg_loss: 0.359683 | gender_precise: 84.000000 (14420/17152) [134/186]\n",
      "gender_loss: 0.3127109110355377\n",
      "train_loss: 0.312711 | avg_loss: 0.359335 | gender_precise: 84.000000 (14532/17280) [135/186]\n",
      "gender_loss: 0.2671002745628357\n",
      "train_loss: 0.267100 | avg_loss: 0.358656 | gender_precise: 84.000000 (14645/17408) [136/186]\n",
      "gender_loss: 0.3619661033153534\n",
      "train_loss: 0.361966 | avg_loss: 0.358681 | gender_precise: 84.000000 (14755/17536) [137/186]\n",
      "gender_loss: 0.4234647750854492\n",
      "train_loss: 0.423465 | avg_loss: 0.359150 | gender_precise: 84.000000 (14861/17664) [138/186]\n",
      "gender_loss: 0.4011303186416626\n",
      "train_loss: 0.401130 | avg_loss: 0.359452 | gender_precise: 84.000000 (14966/17792) [139/186]\n",
      "gender_loss: 0.332830011844635\n",
      "train_loss: 0.332830 | avg_loss: 0.359262 | gender_precise: 84.000000 (15077/17920) [140/186]\n",
      "gender_loss: 0.2623389661312103\n",
      "train_loss: 0.262339 | avg_loss: 0.358575 | gender_precise: 84.000000 (15189/18048) [141/186]\n",
      "gender_loss: 0.32197901606559753\n",
      "train_loss: 0.321979 | avg_loss: 0.358317 | gender_precise: 84.000000 (15296/18176) [142/186]\n",
      "gender_loss: 0.3907582461833954\n",
      "train_loss: 0.390758 | avg_loss: 0.358544 | gender_precise: 84.000000 (15401/18304) [143/186]\n",
      "gender_loss: 0.2589990496635437\n",
      "train_loss: 0.258999 | avg_loss: 0.357852 | gender_precise: 84.000000 (15512/18432) [144/186]\n",
      "gender_loss: 0.27605611085891724\n",
      "train_loss: 0.276056 | avg_loss: 0.357288 | gender_precise: 84.000000 (15626/18560) [145/186]\n",
      "gender_loss: 0.37434202432632446\n",
      "train_loss: 0.374342 | avg_loss: 0.357405 | gender_precise: 84.000000 (15727/18688) [146/186]\n",
      "gender_loss: 0.28642380237579346\n",
      "train_loss: 0.286424 | avg_loss: 0.356922 | gender_precise: 84.000000 (15841/18816) [147/186]\n",
      "gender_loss: 0.30379754304885864\n",
      "train_loss: 0.303798 | avg_loss: 0.356563 | gender_precise: 84.000000 (15954/18944) [148/186]\n",
      "gender_loss: 0.3104594051837921\n",
      "train_loss: 0.310459 | avg_loss: 0.356254 | gender_precise: 84.000000 (16063/19072) [149/186]\n",
      "gender_loss: 0.47414103150367737\n",
      "train_loss: 0.474141 | avg_loss: 0.357040 | gender_precise: 84.000000 (16163/19200) [150/186]\n",
      "gender_loss: 0.2011512815952301\n",
      "train_loss: 0.201151 | avg_loss: 0.356007 | gender_precise: 84.000000 (16278/19328) [151/186]\n",
      "gender_loss: 0.2746853232383728\n",
      "train_loss: 0.274685 | avg_loss: 0.355472 | gender_precise: 84.000000 (16391/19456) [152/186]\n",
      "gender_loss: 0.24978390336036682\n",
      "train_loss: 0.249784 | avg_loss: 0.354782 | gender_precise: 84.000000 (16506/19584) [153/186]\n",
      "gender_loss: 0.364111065864563\n",
      "train_loss: 0.364111 | avg_loss: 0.354842 | gender_precise: 84.000000 (16614/19712) [154/186]\n",
      "gender_loss: 0.34254398941993713\n",
      "train_loss: 0.342544 | avg_loss: 0.354763 | gender_precise: 84.000000 (16717/19840) [155/186]\n",
      "gender_loss: 0.36058175563812256\n",
      "train_loss: 0.360582 | avg_loss: 0.354800 | gender_precise: 84.000000 (16827/19968) [156/186]\n",
      "gender_loss: 0.2968510687351227\n",
      "train_loss: 0.296851 | avg_loss: 0.354431 | gender_precise: 84.000000 (16940/20096) [157/186]\n",
      "gender_loss: 0.2906537353992462\n",
      "train_loss: 0.290654 | avg_loss: 0.354027 | gender_precise: 84.000000 (17050/20224) [158/186]\n",
      "gender_loss: 0.3063744604587555\n",
      "train_loss: 0.306374 | avg_loss: 0.353728 | gender_precise: 84.000000 (17155/20352) [159/186]\n",
      "gender_loss: 0.2879864573478699\n",
      "train_loss: 0.287986 | avg_loss: 0.353317 | gender_precise: 84.000000 (17268/20480) [160/186]\n",
      "gender_loss: 0.32338327169418335\n",
      "train_loss: 0.323383 | avg_loss: 0.353131 | gender_precise: 84.000000 (17375/20608) [161/186]\n",
      "gender_loss: 0.42025208473205566\n",
      "train_loss: 0.420252 | avg_loss: 0.353545 | gender_precise: 84.000000 (17481/20736) [162/186]\n",
      "gender_loss: 0.32917192578315735\n",
      "train_loss: 0.329172 | avg_loss: 0.353396 | gender_precise: 84.000000 (17587/20864) [163/186]\n",
      "gender_loss: 0.3479996919631958\n",
      "train_loss: 0.348000 | avg_loss: 0.353363 | gender_precise: 84.000000 (17697/20992) [164/186]\n",
      "gender_loss: 0.3592076897621155\n",
      "train_loss: 0.359208 | avg_loss: 0.353398 | gender_precise: 84.000000 (17806/21120) [165/186]\n",
      "gender_loss: 0.41141265630722046\n",
      "train_loss: 0.411413 | avg_loss: 0.353748 | gender_precise: 84.000000 (17913/21248) [166/186]\n",
      "gender_loss: 0.3808715045452118\n",
      "train_loss: 0.380872 | avg_loss: 0.353910 | gender_precise: 84.000000 (18017/21376) [167/186]\n",
      "gender_loss: 0.34639352560043335\n",
      "train_loss: 0.346394 | avg_loss: 0.353865 | gender_precise: 84.000000 (18122/21504) [168/186]\n",
      "gender_loss: 0.3054993748664856\n",
      "train_loss: 0.305499 | avg_loss: 0.353579 | gender_precise: 84.000000 (18234/21632) [169/186]\n",
      "gender_loss: 0.35417482256889343\n",
      "train_loss: 0.354175 | avg_loss: 0.353583 | gender_precise: 84.000000 (18343/21760) [170/186]\n",
      "gender_loss: 0.2997332513332367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.299733 | avg_loss: 0.353268 | gender_precise: 84.000000 (18452/21888) [171/186]\n",
      "gender_loss: 0.301461786031723\n",
      "train_loss: 0.301462 | avg_loss: 0.352967 | gender_precise: 84.000000 (18566/22016) [172/186]\n",
      "gender_loss: 0.3246181905269623\n",
      "train_loss: 0.324618 | avg_loss: 0.352803 | gender_precise: 84.000000 (18675/22144) [173/186]\n",
      "gender_loss: 0.35675206780433655\n",
      "train_loss: 0.356752 | avg_loss: 0.352825 | gender_precise: 84.000000 (18785/22272) [174/186]\n",
      "gender_loss: 0.25802260637283325\n",
      "train_loss: 0.258023 | avg_loss: 0.352284 | gender_precise: 84.000000 (18901/22400) [175/186]\n",
      "gender_loss: 0.35997718572616577\n",
      "train_loss: 0.359977 | avg_loss: 0.352327 | gender_precise: 84.000000 (19010/22528) [176/186]\n",
      "gender_loss: 0.3544620871543884\n",
      "train_loss: 0.354462 | avg_loss: 0.352339 | gender_precise: 84.000000 (19117/22656) [177/186]\n",
      "gender_loss: 0.3253265917301178\n",
      "train_loss: 0.325327 | avg_loss: 0.352188 | gender_precise: 84.000000 (19228/22784) [178/186]\n",
      "gender_loss: 0.33707159757614136\n",
      "train_loss: 0.337072 | avg_loss: 0.352103 | gender_precise: 84.000000 (19338/22912) [179/186]\n",
      "gender_loss: 0.2457166314125061\n",
      "train_loss: 0.245717 | avg_loss: 0.351512 | gender_precise: 84.000000 (19451/23040) [180/186]\n",
      "gender_loss: 0.22784125804901123\n",
      "train_loss: 0.227841 | avg_loss: 0.350829 | gender_precise: 84.000000 (19569/23168) [181/186]\n",
      "gender_loss: 0.2728478014469147\n",
      "train_loss: 0.272848 | avg_loss: 0.350400 | gender_precise: 84.000000 (19681/23296) [182/186]\n",
      "gender_loss: 0.34820541739463806\n",
      "train_loss: 0.348205 | avg_loss: 0.350388 | gender_precise: 84.000000 (19793/23424) [183/186]\n",
      "gender_loss: 0.271459698677063\n",
      "train_loss: 0.271460 | avg_loss: 0.349959 | gender_precise: 84.000000 (19906/23552) [184/186]\n",
      "gender_loss: 0.285767525434494\n",
      "train_loss: 0.285768 | avg_loss: 0.349612 | gender_precise: 84.000000 (20019/23680) [185/186]\n",
      "gender_loss: 0.22262032330036163\n",
      "train_loss: 0.222620 | avg_loss: 0.348930 | gender_precise: 84.000000 (20043/23708) [186/186]\n",
      "\n",
      "Test\n",
      "gender_prec: 81.000000 (104/128) [1/2]\n",
      "gender_prec: 80.000000 (108/134) [2/2]\n",
      "Saving..\n",
      "Number epoch: 4\n",
      "gender_loss: 0.2965875267982483\n",
      "train_loss: 0.296588 | avg_loss: 0.296588 | gender_precise: 86.000000 (111/128) [1/186]\n",
      "gender_loss: 0.3627510964870453\n",
      "train_loss: 0.362751 | avg_loss: 0.329669 | gender_precise: 82.000000 (212/256) [2/186]\n",
      "gender_loss: 0.2688709497451782\n",
      "train_loss: 0.268871 | avg_loss: 0.309403 | gender_precise: 84.000000 (326/384) [3/186]\n",
      "gender_loss: 0.30893057584762573\n",
      "train_loss: 0.308931 | avg_loss: 0.309285 | gender_precise: 84.000000 (435/512) [4/186]\n",
      "gender_loss: 0.2814881205558777\n",
      "train_loss: 0.281488 | avg_loss: 0.303726 | gender_precise: 85.000000 (546/640) [5/186]\n",
      "gender_loss: 0.34688499569892883\n",
      "train_loss: 0.346885 | avg_loss: 0.310919 | gender_precise: 85.000000 (654/768) [6/186]\n",
      "gender_loss: 0.3573073744773865\n",
      "train_loss: 0.357307 | avg_loss: 0.317546 | gender_precise: 85.000000 (765/896) [7/186]\n",
      "gender_loss: 0.30785685777664185\n",
      "train_loss: 0.307857 | avg_loss: 0.316335 | gender_precise: 85.000000 (876/1024) [8/186]\n",
      "gender_loss: 0.34050264954566956\n",
      "train_loss: 0.340503 | avg_loss: 0.319020 | gender_precise: 85.000000 (986/1152) [9/186]\n",
      "gender_loss: 0.3029327690601349\n",
      "train_loss: 0.302933 | avg_loss: 0.317411 | gender_precise: 85.000000 (1096/1280) [10/186]\n",
      "gender_loss: 0.24803346395492554\n",
      "train_loss: 0.248033 | avg_loss: 0.311104 | gender_precise: 86.000000 (1213/1408) [11/186]\n",
      "gender_loss: 0.21734121441841125\n",
      "train_loss: 0.217341 | avg_loss: 0.303291 | gender_precise: 86.000000 (1328/1536) [12/186]\n",
      "gender_loss: 0.27781611680984497\n",
      "train_loss: 0.277816 | avg_loss: 0.301331 | gender_precise: 86.000000 (1440/1664) [13/186]\n",
      "gender_loss: 0.2492862194776535\n",
      "train_loss: 0.249286 | avg_loss: 0.297614 | gender_precise: 86.000000 (1552/1792) [14/186]\n",
      "gender_loss: 0.3622988760471344\n",
      "train_loss: 0.362299 | avg_loss: 0.301926 | gender_precise: 86.000000 (1665/1920) [15/186]\n",
      "gender_loss: 0.22799713909626007\n",
      "train_loss: 0.227997 | avg_loss: 0.297305 | gender_precise: 86.000000 (1781/2048) [16/186]\n",
      "gender_loss: 0.2163114845752716\n",
      "train_loss: 0.216311 | avg_loss: 0.292541 | gender_precise: 86.000000 (1892/2176) [17/186]\n",
      "gender_loss: 0.32910946011543274\n",
      "train_loss: 0.329109 | avg_loss: 0.294573 | gender_precise: 86.000000 (1998/2304) [18/186]\n",
      "gender_loss: 0.34507277607917786\n",
      "train_loss: 0.345073 | avg_loss: 0.297231 | gender_precise: 86.000000 (2109/2432) [19/186]\n",
      "gender_loss: 0.33579039573669434\n",
      "train_loss: 0.335790 | avg_loss: 0.299159 | gender_precise: 86.000000 (2219/2560) [20/186]\n",
      "gender_loss: 0.2273881435394287\n",
      "train_loss: 0.227388 | avg_loss: 0.295741 | gender_precise: 86.000000 (2337/2688) [21/186]\n",
      "gender_loss: 0.30867236852645874\n",
      "train_loss: 0.308672 | avg_loss: 0.296329 | gender_precise: 86.000000 (2446/2816) [22/186]\n",
      "gender_loss: 0.29140445590019226\n",
      "train_loss: 0.291404 | avg_loss: 0.296115 | gender_precise: 86.000000 (2558/2944) [23/186]\n",
      "gender_loss: 0.3097451329231262\n",
      "train_loss: 0.309745 | avg_loss: 0.296683 | gender_precise: 86.000000 (2669/3072) [24/186]\n",
      "gender_loss: 0.28511375188827515\n",
      "train_loss: 0.285114 | avg_loss: 0.296220 | gender_precise: 86.000000 (2781/3200) [25/186]\n",
      "gender_loss: 0.2714885473251343\n",
      "train_loss: 0.271489 | avg_loss: 0.295269 | gender_precise: 86.000000 (2891/3328) [26/186]\n",
      "gender_loss: 0.3783004581928253\n",
      "train_loss: 0.378300 | avg_loss: 0.298344 | gender_precise: 86.000000 (3000/3456) [27/186]\n",
      "gender_loss: 0.28137028217315674\n",
      "train_loss: 0.281370 | avg_loss: 0.297738 | gender_precise: 86.000000 (3111/3584) [28/186]\n",
      "gender_loss: 0.25166940689086914\n",
      "train_loss: 0.251669 | avg_loss: 0.296149 | gender_precise: 86.000000 (3225/3712) [29/186]\n",
      "gender_loss: 0.29823943972587585\n",
      "train_loss: 0.298239 | avg_loss: 0.296219 | gender_precise: 86.000000 (3334/3840) [30/186]\n",
      "gender_loss: 0.31295618414878845\n",
      "train_loss: 0.312956 | avg_loss: 0.296759 | gender_precise: 86.000000 (3445/3968) [31/186]\n",
      "gender_loss: 0.30383825302124023\n",
      "train_loss: 0.303838 | avg_loss: 0.296980 | gender_precise: 86.000000 (3560/4096) [32/186]\n",
      "gender_loss: 0.2828424274921417\n",
      "train_loss: 0.282842 | avg_loss: 0.296552 | gender_precise: 86.000000 (3669/4224) [33/186]\n",
      "gender_loss: 0.3464389443397522\n",
      "train_loss: 0.346439 | avg_loss: 0.298019 | gender_precise: 86.000000 (3778/4352) [34/186]\n",
      "gender_loss: 0.3167199194431305\n",
      "train_loss: 0.316720 | avg_loss: 0.298553 | gender_precise: 86.000000 (3888/4480) [35/186]\n",
      "gender_loss: 0.29132407903671265\n",
      "train_loss: 0.291324 | avg_loss: 0.298352 | gender_precise: 86.000000 (3996/4608) [36/186]\n",
      "gender_loss: 0.2656603157520294\n",
      "train_loss: 0.265660 | avg_loss: 0.297469 | gender_precise: 86.000000 (4106/4736) [37/186]\n",
      "gender_loss: 0.33188942074775696\n",
      "train_loss: 0.331889 | avg_loss: 0.298375 | gender_precise: 86.000000 (4215/4864) [38/186]\n",
      "gender_loss: 0.30907610058784485\n",
      "train_loss: 0.309076 | avg_loss: 0.298649 | gender_precise: 86.000000 (4324/4992) [39/186]\n",
      "gender_loss: 0.39834892749786377\n",
      "train_loss: 0.398349 | avg_loss: 0.301141 | gender_precise: 86.000000 (4432/5120) [40/186]\n",
      "gender_loss: 0.23222698271274567\n",
      "train_loss: 0.232227 | avg_loss: 0.299461 | gender_precise: 86.000000 (4547/5248) [41/186]\n",
      "gender_loss: 0.3338761031627655\n",
      "train_loss: 0.333876 | avg_loss: 0.300280 | gender_precise: 86.000000 (4655/5376) [42/186]\n",
      "gender_loss: 0.3264674246311188\n",
      "train_loss: 0.326467 | avg_loss: 0.300889 | gender_precise: 86.000000 (4760/5504) [43/186]\n",
      "gender_loss: 0.2944476902484894\n",
      "train_loss: 0.294448 | avg_loss: 0.300743 | gender_precise: 86.000000 (4870/5632) [44/186]\n",
      "gender_loss: 0.30915501713752747\n",
      "train_loss: 0.309155 | avg_loss: 0.300930 | gender_precise: 86.000000 (4983/5760) [45/186]\n",
      "gender_loss: 0.2982288897037506\n",
      "train_loss: 0.298229 | avg_loss: 0.300871 | gender_precise: 86.000000 (5094/5888) [46/186]\n",
      "gender_loss: 0.3302999436855316\n",
      "train_loss: 0.330300 | avg_loss: 0.301497 | gender_precise: 86.000000 (5203/6016) [47/186]\n",
      "gender_loss: 0.4018898606300354\n",
      "train_loss: 0.401890 | avg_loss: 0.303589 | gender_precise: 86.000000 (5312/6144) [48/186]\n",
      "gender_loss: 0.44206443428993225\n",
      "train_loss: 0.442064 | avg_loss: 0.306415 | gender_precise: 86.000000 (5412/6272) [49/186]\n",
      "gender_loss: 0.3208377957344055\n",
      "train_loss: 0.320838 | avg_loss: 0.306703 | gender_precise: 86.000000 (5520/6400) [50/186]\n",
      "gender_loss: 0.3800816535949707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.380082 | avg_loss: 0.308142 | gender_precise: 86.000000 (5626/6528) [51/186]\n",
      "gender_loss: 0.23457016050815582\n",
      "train_loss: 0.234570 | avg_loss: 0.306727 | gender_precise: 86.000000 (5741/6656) [52/186]\n",
      "gender_loss: 0.3918714225292206\n",
      "train_loss: 0.391871 | avg_loss: 0.308334 | gender_precise: 86.000000 (5850/6784) [53/186]\n",
      "gender_loss: 0.3059954047203064\n",
      "train_loss: 0.305995 | avg_loss: 0.308290 | gender_precise: 86.000000 (5961/6912) [54/186]\n",
      "gender_loss: 0.25717592239379883\n",
      "train_loss: 0.257176 | avg_loss: 0.307361 | gender_precise: 86.000000 (6074/7040) [55/186]\n",
      "gender_loss: 0.27995750308036804\n",
      "train_loss: 0.279958 | avg_loss: 0.306872 | gender_precise: 86.000000 (6186/7168) [56/186]\n",
      "gender_loss: 0.2967441976070404\n",
      "train_loss: 0.296744 | avg_loss: 0.306694 | gender_precise: 86.000000 (6299/7296) [57/186]\n",
      "gender_loss: 0.289835661649704\n",
      "train_loss: 0.289836 | avg_loss: 0.306403 | gender_precise: 86.000000 (6410/7424) [58/186]\n",
      "gender_loss: 0.3865159749984741\n",
      "train_loss: 0.386516 | avg_loss: 0.307761 | gender_precise: 86.000000 (6518/7552) [59/186]\n",
      "gender_loss: 0.2995930016040802\n",
      "train_loss: 0.299593 | avg_loss: 0.307625 | gender_precise: 86.000000 (6628/7680) [60/186]\n",
      "gender_loss: 0.3154680132865906\n",
      "train_loss: 0.315468 | avg_loss: 0.307753 | gender_precise: 86.000000 (6736/7808) [61/186]\n",
      "gender_loss: 0.28217336535453796\n",
      "train_loss: 0.282173 | avg_loss: 0.307341 | gender_precise: 86.000000 (6851/7936) [62/186]\n",
      "gender_loss: 0.3010973632335663\n",
      "train_loss: 0.301097 | avg_loss: 0.307242 | gender_precise: 86.000000 (6958/8064) [63/186]\n",
      "gender_loss: 0.28723421692848206\n",
      "train_loss: 0.287234 | avg_loss: 0.306929 | gender_precise: 86.000000 (7072/8192) [64/186]\n",
      "gender_loss: 0.18422068655490875\n",
      "train_loss: 0.184221 | avg_loss: 0.305041 | gender_precise: 86.000000 (7190/8320) [65/186]\n",
      "gender_loss: 0.3149265944957733\n",
      "train_loss: 0.314927 | avg_loss: 0.305191 | gender_precise: 86.000000 (7298/8448) [66/186]\n",
      "gender_loss: 0.35134953260421753\n",
      "train_loss: 0.351350 | avg_loss: 0.305880 | gender_precise: 86.000000 (7406/8576) [67/186]\n",
      "gender_loss: 0.31460562348365784\n",
      "train_loss: 0.314606 | avg_loss: 0.306008 | gender_precise: 86.000000 (7518/8704) [68/186]\n",
      "gender_loss: 0.2898918688297272\n",
      "train_loss: 0.289892 | avg_loss: 0.305775 | gender_precise: 86.000000 (7629/8832) [69/186]\n",
      "gender_loss: 0.2810802161693573\n",
      "train_loss: 0.281080 | avg_loss: 0.305422 | gender_precise: 86.000000 (7740/8960) [70/186]\n",
      "gender_loss: 0.3030870258808136\n",
      "train_loss: 0.303087 | avg_loss: 0.305389 | gender_precise: 86.000000 (7850/9088) [71/186]\n",
      "gender_loss: 0.29929813742637634\n",
      "train_loss: 0.299298 | avg_loss: 0.305304 | gender_precise: 86.000000 (7958/9216) [72/186]\n",
      "gender_loss: 0.22408334910869598\n",
      "train_loss: 0.224083 | avg_loss: 0.304192 | gender_precise: 86.000000 (8073/9344) [73/186]\n",
      "gender_loss: 0.3260551393032074\n",
      "train_loss: 0.326055 | avg_loss: 0.304487 | gender_precise: 86.000000 (8182/9472) [74/186]\n",
      "gender_loss: 0.32191091775894165\n",
      "train_loss: 0.321911 | avg_loss: 0.304720 | gender_precise: 86.000000 (8292/9600) [75/186]\n",
      "gender_loss: 0.320266991853714\n",
      "train_loss: 0.320267 | avg_loss: 0.304924 | gender_precise: 86.000000 (8398/9728) [76/186]\n",
      "gender_loss: 0.34333181381225586\n",
      "train_loss: 0.343332 | avg_loss: 0.305423 | gender_precise: 86.000000 (8511/9856) [77/186]\n",
      "gender_loss: 0.29620790481567383\n",
      "train_loss: 0.296208 | avg_loss: 0.305305 | gender_precise: 86.000000 (8624/9984) [78/186]\n",
      "gender_loss: 0.2732866406440735\n",
      "train_loss: 0.273287 | avg_loss: 0.304900 | gender_precise: 86.000000 (8741/10112) [79/186]\n",
      "gender_loss: 0.22897282242774963\n",
      "train_loss: 0.228973 | avg_loss: 0.303951 | gender_precise: 86.000000 (8853/10240) [80/186]\n",
      "gender_loss: 0.30324697494506836\n",
      "train_loss: 0.303247 | avg_loss: 0.303942 | gender_precise: 86.000000 (8965/10368) [81/186]\n",
      "gender_loss: 0.23284316062927246\n",
      "train_loss: 0.232843 | avg_loss: 0.303075 | gender_precise: 86.000000 (9080/10496) [82/186]\n",
      "gender_loss: 0.22636669874191284\n",
      "train_loss: 0.226367 | avg_loss: 0.302151 | gender_precise: 86.000000 (9195/10624) [83/186]\n",
      "gender_loss: 0.30111703276634216\n",
      "train_loss: 0.301117 | avg_loss: 0.302138 | gender_precise: 86.000000 (9309/10752) [84/186]\n",
      "gender_loss: 0.18857775628566742\n",
      "train_loss: 0.188578 | avg_loss: 0.300802 | gender_precise: 86.000000 (9425/10880) [85/186]\n",
      "gender_loss: 0.26768893003463745\n",
      "train_loss: 0.267689 | avg_loss: 0.300417 | gender_precise: 86.000000 (9539/11008) [86/186]\n",
      "gender_loss: 0.22646796703338623\n",
      "train_loss: 0.226468 | avg_loss: 0.299567 | gender_precise: 86.000000 (9657/11136) [87/186]\n",
      "gender_loss: 0.27241796255111694\n",
      "train_loss: 0.272418 | avg_loss: 0.299259 | gender_precise: 86.000000 (9770/11264) [88/186]\n",
      "gender_loss: 0.27740931510925293\n",
      "train_loss: 0.277409 | avg_loss: 0.299013 | gender_precise: 86.000000 (9882/11392) [89/186]\n",
      "gender_loss: 0.18310846388339996\n",
      "train_loss: 0.183108 | avg_loss: 0.297725 | gender_precise: 86.000000 (10001/11520) [90/186]\n",
      "gender_loss: 0.35748887062072754\n",
      "train_loss: 0.357489 | avg_loss: 0.298382 | gender_precise: 86.000000 (10110/11648) [91/186]\n",
      "gender_loss: 0.2893165051937103\n",
      "train_loss: 0.289317 | avg_loss: 0.298284 | gender_precise: 86.000000 (10224/11776) [92/186]\n",
      "gender_loss: 0.3233794569969177\n",
      "train_loss: 0.323379 | avg_loss: 0.298553 | gender_precise: 86.000000 (10341/11904) [93/186]\n",
      "gender_loss: 0.22230355441570282\n",
      "train_loss: 0.222304 | avg_loss: 0.297742 | gender_precise: 86.000000 (10458/12032) [94/186]\n",
      "gender_loss: 0.35727399587631226\n",
      "train_loss: 0.357274 | avg_loss: 0.298369 | gender_precise: 86.000000 (10567/12160) [95/186]\n",
      "gender_loss: 0.33139950037002563\n",
      "train_loss: 0.331400 | avg_loss: 0.298713 | gender_precise: 86.000000 (10678/12288) [96/186]\n",
      "gender_loss: 0.2958970069885254\n",
      "train_loss: 0.295897 | avg_loss: 0.298684 | gender_precise: 86.000000 (10789/12416) [97/186]\n",
      "gender_loss: 0.32774606347084045\n",
      "train_loss: 0.327746 | avg_loss: 0.298980 | gender_precise: 86.000000 (10896/12544) [98/186]\n",
      "gender_loss: 0.2682783603668213\n",
      "train_loss: 0.268278 | avg_loss: 0.298670 | gender_precise: 86.000000 (11007/12672) [99/186]\n",
      "gender_loss: 0.30570149421691895\n",
      "train_loss: 0.305701 | avg_loss: 0.298741 | gender_precise: 86.000000 (11114/12800) [100/186]\n",
      "gender_loss: 0.3294186294078827\n",
      "train_loss: 0.329419 | avg_loss: 0.299044 | gender_precise: 86.000000 (11219/12928) [101/186]\n",
      "gender_loss: 0.26240313053131104\n",
      "train_loss: 0.262403 | avg_loss: 0.298685 | gender_precise: 86.000000 (11329/13056) [102/186]\n",
      "gender_loss: 0.37468141317367554\n",
      "train_loss: 0.374681 | avg_loss: 0.299423 | gender_precise: 86.000000 (11438/13184) [103/186]\n",
      "gender_loss: 0.2595771253108978\n",
      "train_loss: 0.259577 | avg_loss: 0.299040 | gender_precise: 86.000000 (11554/13312) [104/186]\n",
      "gender_loss: 0.24406306445598602\n",
      "train_loss: 0.244063 | avg_loss: 0.298516 | gender_precise: 86.000000 (11669/13440) [105/186]\n",
      "gender_loss: 0.28416818380355835\n",
      "train_loss: 0.284168 | avg_loss: 0.298381 | gender_precise: 86.000000 (11780/13568) [106/186]\n",
      "gender_loss: 0.26915332674980164\n",
      "train_loss: 0.269153 | avg_loss: 0.298108 | gender_precise: 86.000000 (11893/13696) [107/186]\n",
      "gender_loss: 0.22139085829257965\n",
      "train_loss: 0.221391 | avg_loss: 0.297397 | gender_precise: 86.000000 (12008/13824) [108/186]\n",
      "gender_loss: 0.19481423497200012\n",
      "train_loss: 0.194814 | avg_loss: 0.296456 | gender_precise: 86.000000 (12128/13952) [109/186]\n",
      "gender_loss: 0.30065518617630005\n",
      "train_loss: 0.300655 | avg_loss: 0.296494 | gender_precise: 86.000000 (12238/14080) [110/186]\n",
      "gender_loss: 0.2879253625869751\n",
      "train_loss: 0.287925 | avg_loss: 0.296417 | gender_precise: 86.000000 (12349/14208) [111/186]\n",
      "gender_loss: 0.2833702266216278\n",
      "train_loss: 0.283370 | avg_loss: 0.296301 | gender_precise: 86.000000 (12457/14336) [112/186]\n",
      "gender_loss: 0.4447038769721985\n",
      "train_loss: 0.444704 | avg_loss: 0.297614 | gender_precise: 86.000000 (12558/14464) [113/186]\n",
      "gender_loss: 0.3248208165168762\n",
      "train_loss: 0.324821 | avg_loss: 0.297853 | gender_precise: 86.000000 (12668/14592) [114/186]\n",
      "gender_loss: 0.225730761885643\n",
      "train_loss: 0.225731 | avg_loss: 0.297226 | gender_precise: 86.000000 (12785/14720) [115/186]\n",
      "gender_loss: 0.252141535282135\n",
      "train_loss: 0.252142 | avg_loss: 0.296837 | gender_precise: 86.000000 (12900/14848) [116/186]\n",
      "gender_loss: 0.2357919067144394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.235792 | avg_loss: 0.296315 | gender_precise: 86.000000 (13014/14976) [117/186]\n",
      "gender_loss: 0.26432210206985474\n",
      "train_loss: 0.264322 | avg_loss: 0.296044 | gender_precise: 86.000000 (13126/15104) [118/186]\n",
      "gender_loss: 0.23833227157592773\n",
      "train_loss: 0.238332 | avg_loss: 0.295559 | gender_precise: 86.000000 (13240/15232) [119/186]\n",
      "gender_loss: 0.32182577252388\n",
      "train_loss: 0.321826 | avg_loss: 0.295778 | gender_precise: 86.000000 (13348/15360) [120/186]\n",
      "gender_loss: 0.30718323588371277\n",
      "train_loss: 0.307183 | avg_loss: 0.295872 | gender_precise: 86.000000 (13457/15488) [121/186]\n",
      "gender_loss: 0.3066820800304413\n",
      "train_loss: 0.306682 | avg_loss: 0.295961 | gender_precise: 86.000000 (13570/15616) [122/186]\n",
      "gender_loss: 0.34138813614845276\n",
      "train_loss: 0.341388 | avg_loss: 0.296330 | gender_precise: 86.000000 (13679/15744) [123/186]\n",
      "gender_loss: 0.2611689269542694\n",
      "train_loss: 0.261169 | avg_loss: 0.296047 | gender_precise: 86.000000 (13790/15872) [124/186]\n",
      "gender_loss: 0.3410722613334656\n",
      "train_loss: 0.341072 | avg_loss: 0.296407 | gender_precise: 86.000000 (13899/16000) [125/186]\n",
      "gender_loss: 0.3640468120574951\n",
      "train_loss: 0.364047 | avg_loss: 0.296944 | gender_precise: 86.000000 (14007/16128) [126/186]\n",
      "gender_loss: 0.23061306774616241\n",
      "train_loss: 0.230613 | avg_loss: 0.296421 | gender_precise: 86.000000 (14124/16256) [127/186]\n",
      "gender_loss: 0.24844440817832947\n",
      "train_loss: 0.248444 | avg_loss: 0.296046 | gender_precise: 86.000000 (14236/16384) [128/186]\n",
      "gender_loss: 0.30284565687179565\n",
      "train_loss: 0.302846 | avg_loss: 0.296099 | gender_precise: 86.000000 (14348/16512) [129/186]\n",
      "gender_loss: 0.23788709938526154\n",
      "train_loss: 0.237887 | avg_loss: 0.295651 | gender_precise: 86.000000 (14461/16640) [130/186]\n",
      "gender_loss: 0.2969658374786377\n",
      "train_loss: 0.296966 | avg_loss: 0.295661 | gender_precise: 86.000000 (14576/16768) [131/186]\n",
      "gender_loss: 0.1915699541568756\n",
      "train_loss: 0.191570 | avg_loss: 0.294873 | gender_precise: 86.000000 (14693/16896) [132/186]\n",
      "gender_loss: 0.291946679353714\n",
      "train_loss: 0.291947 | avg_loss: 0.294851 | gender_precise: 86.000000 (14803/17024) [133/186]\n",
      "gender_loss: 0.22376973927021027\n",
      "train_loss: 0.223770 | avg_loss: 0.294320 | gender_precise: 86.000000 (14918/17152) [134/186]\n",
      "gender_loss: 0.19701576232910156\n",
      "train_loss: 0.197016 | avg_loss: 0.293600 | gender_precise: 87.000000 (15036/17280) [135/186]\n",
      "gender_loss: 0.29258665442466736\n",
      "train_loss: 0.292587 | avg_loss: 0.293592 | gender_precise: 87.000000 (15150/17408) [136/186]\n",
      "gender_loss: 0.2617378234863281\n",
      "train_loss: 0.261738 | avg_loss: 0.293360 | gender_precise: 87.000000 (15267/17536) [137/186]\n",
      "gender_loss: 0.20483462512493134\n",
      "train_loss: 0.204835 | avg_loss: 0.292718 | gender_precise: 87.000000 (15385/17664) [138/186]\n",
      "gender_loss: 0.2832837998867035\n",
      "train_loss: 0.283284 | avg_loss: 0.292650 | gender_precise: 87.000000 (15499/17792) [139/186]\n",
      "gender_loss: 0.2920333743095398\n",
      "train_loss: 0.292033 | avg_loss: 0.292646 | gender_precise: 87.000000 (15606/17920) [140/186]\n",
      "gender_loss: 0.29773610830307007\n",
      "train_loss: 0.297736 | avg_loss: 0.292682 | gender_precise: 87.000000 (15718/18048) [141/186]\n",
      "gender_loss: 0.291273295879364\n",
      "train_loss: 0.291273 | avg_loss: 0.292672 | gender_precise: 87.000000 (15829/18176) [142/186]\n",
      "gender_loss: 0.2642193138599396\n",
      "train_loss: 0.264219 | avg_loss: 0.292473 | gender_precise: 87.000000 (15942/18304) [143/186]\n",
      "gender_loss: 0.26469743251800537\n",
      "train_loss: 0.264697 | avg_loss: 0.292280 | gender_precise: 87.000000 (16059/18432) [144/186]\n",
      "gender_loss: 0.21400752663612366\n",
      "train_loss: 0.214008 | avg_loss: 0.291740 | gender_precise: 87.000000 (16177/18560) [145/186]\n",
      "gender_loss: 0.25795504450798035\n",
      "train_loss: 0.257955 | avg_loss: 0.291509 | gender_precise: 87.000000 (16286/18688) [146/186]\n",
      "gender_loss: 0.26541072130203247\n",
      "train_loss: 0.265411 | avg_loss: 0.291331 | gender_precise: 87.000000 (16401/18816) [147/186]\n",
      "gender_loss: 0.21440084278583527\n",
      "train_loss: 0.214401 | avg_loss: 0.290812 | gender_precise: 87.000000 (16519/18944) [148/186]\n",
      "gender_loss: 0.3521535396575928\n",
      "train_loss: 0.352154 | avg_loss: 0.291223 | gender_precise: 87.000000 (16632/19072) [149/186]\n",
      "gender_loss: 0.29765868186950684\n",
      "train_loss: 0.297659 | avg_loss: 0.291266 | gender_precise: 87.000000 (16743/19200) [150/186]\n",
      "gender_loss: 0.30420932173728943\n",
      "train_loss: 0.304209 | avg_loss: 0.291352 | gender_precise: 87.000000 (16857/19328) [151/186]\n",
      "gender_loss: 0.24550092220306396\n",
      "train_loss: 0.245501 | avg_loss: 0.291050 | gender_precise: 87.000000 (16973/19456) [152/186]\n",
      "gender_loss: 0.3260914385318756\n",
      "train_loss: 0.326091 | avg_loss: 0.291279 | gender_precise: 87.000000 (17081/19584) [153/186]\n",
      "gender_loss: 0.2982427477836609\n",
      "train_loss: 0.298243 | avg_loss: 0.291325 | gender_precise: 87.000000 (17194/19712) [154/186]\n",
      "gender_loss: 0.25642064213752747\n",
      "train_loss: 0.256421 | avg_loss: 0.291099 | gender_precise: 87.000000 (17306/19840) [155/186]\n",
      "gender_loss: 0.2778424024581909\n",
      "train_loss: 0.277842 | avg_loss: 0.291014 | gender_precise: 87.000000 (17420/19968) [156/186]\n",
      "gender_loss: 0.29882627725601196\n",
      "train_loss: 0.298826 | avg_loss: 0.291064 | gender_precise: 87.000000 (17529/20096) [157/186]\n",
      "gender_loss: 0.29157382249832153\n",
      "train_loss: 0.291574 | avg_loss: 0.291067 | gender_precise: 87.000000 (17640/20224) [158/186]\n",
      "gender_loss: 0.3423337936401367\n",
      "train_loss: 0.342334 | avg_loss: 0.291390 | gender_precise: 87.000000 (17753/20352) [159/186]\n",
      "gender_loss: 0.272192120552063\n",
      "train_loss: 0.272192 | avg_loss: 0.291270 | gender_precise: 87.000000 (17866/20480) [160/186]\n",
      "gender_loss: 0.30502521991729736\n",
      "train_loss: 0.305025 | avg_loss: 0.291355 | gender_precise: 87.000000 (17975/20608) [161/186]\n",
      "gender_loss: 0.19406147301197052\n",
      "train_loss: 0.194061 | avg_loss: 0.290755 | gender_precise: 87.000000 (18092/20736) [162/186]\n",
      "gender_loss: 0.25298672914505005\n",
      "train_loss: 0.252987 | avg_loss: 0.290523 | gender_precise: 87.000000 (18208/20864) [163/186]\n",
      "gender_loss: 0.29931899905204773\n",
      "train_loss: 0.299319 | avg_loss: 0.290577 | gender_precise: 87.000000 (18319/20992) [164/186]\n",
      "gender_loss: 0.3182922303676605\n",
      "train_loss: 0.318292 | avg_loss: 0.290745 | gender_precise: 87.000000 (18431/21120) [165/186]\n",
      "gender_loss: 0.27005988359451294\n",
      "train_loss: 0.270060 | avg_loss: 0.290620 | gender_precise: 87.000000 (18544/21248) [166/186]\n",
      "gender_loss: 0.3225502371788025\n",
      "train_loss: 0.322550 | avg_loss: 0.290811 | gender_precise: 87.000000 (18654/21376) [167/186]\n",
      "gender_loss: 0.3244805634021759\n",
      "train_loss: 0.324481 | avg_loss: 0.291012 | gender_precise: 87.000000 (18763/21504) [168/186]\n",
      "gender_loss: 0.29195478558540344\n",
      "train_loss: 0.291955 | avg_loss: 0.291017 | gender_precise: 87.000000 (18874/21632) [169/186]\n",
      "gender_loss: 0.20913195610046387\n",
      "train_loss: 0.209132 | avg_loss: 0.290536 | gender_precise: 87.000000 (18991/21760) [170/186]\n",
      "gender_loss: 0.28782904148101807\n",
      "train_loss: 0.287829 | avg_loss: 0.290520 | gender_precise: 87.000000 (19104/21888) [171/186]\n",
      "gender_loss: 0.20286257565021515\n",
      "train_loss: 0.202863 | avg_loss: 0.290010 | gender_precise: 87.000000 (19223/22016) [172/186]\n",
      "gender_loss: 0.2786581218242645\n",
      "train_loss: 0.278658 | avg_loss: 0.289945 | gender_precise: 87.000000 (19333/22144) [173/186]\n",
      "gender_loss: 0.3114292025566101\n",
      "train_loss: 0.311429 | avg_loss: 0.290068 | gender_precise: 87.000000 (19441/22272) [174/186]\n",
      "gender_loss: 0.4069123864173889\n",
      "train_loss: 0.406912 | avg_loss: 0.290736 | gender_precise: 87.000000 (19547/22400) [175/186]\n",
      "gender_loss: 0.3064945936203003\n",
      "train_loss: 0.306495 | avg_loss: 0.290825 | gender_precise: 87.000000 (19658/22528) [176/186]\n",
      "gender_loss: 0.2566137909889221\n",
      "train_loss: 0.256614 | avg_loss: 0.290632 | gender_precise: 87.000000 (19772/22656) [177/186]\n",
      "gender_loss: 0.35912802815437317\n",
      "train_loss: 0.359128 | avg_loss: 0.291017 | gender_precise: 87.000000 (19879/22784) [178/186]\n",
      "gender_loss: 0.3763510286808014\n",
      "train_loss: 0.376351 | avg_loss: 0.291493 | gender_precise: 87.000000 (19983/22912) [179/186]\n",
      "gender_loss: 0.27982231974601746\n",
      "train_loss: 0.279822 | avg_loss: 0.291429 | gender_precise: 87.000000 (20092/23040) [180/186]\n",
      "gender_loss: 0.2873421311378479\n",
      "train_loss: 0.287342 | avg_loss: 0.291406 | gender_precise: 87.000000 (20206/23168) [181/186]\n",
      "gender_loss: 0.32178401947021484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.321784 | avg_loss: 0.291573 | gender_precise: 87.000000 (20314/23296) [182/186]\n",
      "gender_loss: 0.37186306715011597\n",
      "train_loss: 0.371863 | avg_loss: 0.292012 | gender_precise: 87.000000 (20420/23424) [183/186]\n",
      "gender_loss: 0.3048299252986908\n",
      "train_loss: 0.304830 | avg_loss: 0.292081 | gender_precise: 87.000000 (20528/23552) [184/186]\n",
      "gender_loss: 0.26146838068962097\n",
      "train_loss: 0.261468 | avg_loss: 0.291916 | gender_precise: 87.000000 (20638/23680) [185/186]\n",
      "gender_loss: 0.4959561824798584\n",
      "train_loss: 0.495956 | avg_loss: 0.293013 | gender_precise: 87.000000 (20659/23708) [186/186]\n",
      "\n",
      "Test\n",
      "gender_prec: 83.000000 (107/128) [1/2]\n",
      "gender_prec: 83.000000 (112/134) [2/2]\n",
      "Saving..\n",
      "Number epoch: 5\n",
      "gender_loss: 0.2194591909646988\n",
      "train_loss: 0.219459 | avg_loss: 0.219459 | gender_precise: 89.000000 (115/128) [1/186]\n",
      "gender_loss: 0.25508058071136475\n",
      "train_loss: 0.255081 | avg_loss: 0.237270 | gender_precise: 90.000000 (231/256) [2/186]\n",
      "gender_loss: 0.2788529098033905\n",
      "train_loss: 0.278853 | avg_loss: 0.251131 | gender_precise: 89.000000 (345/384) [3/186]\n",
      "gender_loss: 0.37531155347824097\n",
      "train_loss: 0.375312 | avg_loss: 0.282176 | gender_precise: 88.000000 (451/512) [4/186]\n",
      "gender_loss: 0.2986929416656494\n",
      "train_loss: 0.298693 | avg_loss: 0.285479 | gender_precise: 87.000000 (562/640) [5/186]\n",
      "gender_loss: 0.3040901720523834\n",
      "train_loss: 0.304090 | avg_loss: 0.288581 | gender_precise: 87.000000 (673/768) [6/186]\n",
      "gender_loss: 0.2585754990577698\n",
      "train_loss: 0.258575 | avg_loss: 0.284295 | gender_precise: 87.000000 (787/896) [7/186]\n",
      "gender_loss: 0.27810484170913696\n",
      "train_loss: 0.278105 | avg_loss: 0.283521 | gender_precise: 87.000000 (899/1024) [8/186]\n",
      "gender_loss: 0.3139711022377014\n",
      "train_loss: 0.313971 | avg_loss: 0.286904 | gender_precise: 87.000000 (1010/1152) [9/186]\n",
      "gender_loss: 0.32957902550697327\n",
      "train_loss: 0.329579 | avg_loss: 0.291172 | gender_precise: 87.000000 (1121/1280) [10/186]\n",
      "gender_loss: 0.30013665556907654\n",
      "train_loss: 0.300137 | avg_loss: 0.291987 | gender_precise: 87.000000 (1229/1408) [11/186]\n",
      "gender_loss: 0.27112317085266113\n",
      "train_loss: 0.271123 | avg_loss: 0.290248 | gender_precise: 87.000000 (1341/1536) [12/186]\n",
      "gender_loss: 0.2652680575847626\n",
      "train_loss: 0.265268 | avg_loss: 0.288327 | gender_precise: 87.000000 (1453/1664) [13/186]\n",
      "gender_loss: 0.2473972737789154\n",
      "train_loss: 0.247397 | avg_loss: 0.285403 | gender_precise: 87.000000 (1567/1792) [14/186]\n",
      "gender_loss: 0.267439067363739\n",
      "train_loss: 0.267439 | avg_loss: 0.284205 | gender_precise: 87.000000 (1680/1920) [15/186]\n",
      "gender_loss: 0.31021109223365784\n",
      "train_loss: 0.310211 | avg_loss: 0.285831 | gender_precise: 87.000000 (1787/2048) [16/186]\n",
      "gender_loss: 0.2535708546638489\n",
      "train_loss: 0.253571 | avg_loss: 0.283933 | gender_precise: 87.000000 (1902/2176) [17/186]\n",
      "gender_loss: 0.3435569107532501\n",
      "train_loss: 0.343557 | avg_loss: 0.287246 | gender_precise: 87.000000 (2007/2304) [18/186]\n",
      "gender_loss: 0.23896631598472595\n",
      "train_loss: 0.238966 | avg_loss: 0.284705 | gender_precise: 87.000000 (2125/2432) [19/186]\n",
      "gender_loss: 0.3114212453365326\n",
      "train_loss: 0.311421 | avg_loss: 0.286040 | gender_precise: 87.000000 (2236/2560) [20/186]\n",
      "gender_loss: 0.27627032995224\n",
      "train_loss: 0.276270 | avg_loss: 0.285575 | gender_precise: 87.000000 (2352/2688) [21/186]\n",
      "gender_loss: 0.29646357893943787\n",
      "train_loss: 0.296464 | avg_loss: 0.286070 | gender_precise: 87.000000 (2465/2816) [22/186]\n",
      "gender_loss: 0.3077947199344635\n",
      "train_loss: 0.307795 | avg_loss: 0.287015 | gender_precise: 87.000000 (2578/2944) [23/186]\n",
      "gender_loss: 0.32126742601394653\n",
      "train_loss: 0.321267 | avg_loss: 0.288442 | gender_precise: 87.000000 (2685/3072) [24/186]\n",
      "gender_loss: 0.24157240986824036\n",
      "train_loss: 0.241572 | avg_loss: 0.286567 | gender_precise: 87.000000 (2800/3200) [25/186]\n",
      "gender_loss: 0.26933181285858154\n",
      "train_loss: 0.269332 | avg_loss: 0.285904 | gender_precise: 87.000000 (2914/3328) [26/186]\n",
      "gender_loss: 0.25726860761642456\n",
      "train_loss: 0.257269 | avg_loss: 0.284844 | gender_precise: 87.000000 (3028/3456) [27/186]\n",
      "gender_loss: 0.33432379364967346\n",
      "train_loss: 0.334324 | avg_loss: 0.286611 | gender_precise: 87.000000 (3143/3584) [28/186]\n",
      "gender_loss: 0.2100161761045456\n",
      "train_loss: 0.210016 | avg_loss: 0.283970 | gender_precise: 87.000000 (3262/3712) [29/186]\n",
      "gender_loss: 0.31868621706962585\n",
      "train_loss: 0.318686 | avg_loss: 0.285127 | gender_precise: 87.000000 (3375/3840) [30/186]\n",
      "gender_loss: 0.2123768925666809\n",
      "train_loss: 0.212377 | avg_loss: 0.282780 | gender_precise: 87.000000 (3490/3968) [31/186]\n",
      "gender_loss: 0.31832873821258545\n",
      "train_loss: 0.318329 | avg_loss: 0.283891 | gender_precise: 87.000000 (3600/4096) [32/186]\n",
      "gender_loss: 0.19048143923282623\n",
      "train_loss: 0.190481 | avg_loss: 0.281060 | gender_precise: 88.000000 (3718/4224) [33/186]\n",
      "gender_loss: 0.248872771859169\n",
      "train_loss: 0.248873 | avg_loss: 0.280114 | gender_precise: 88.000000 (3833/4352) [34/186]\n",
      "gender_loss: 0.16663393378257751\n",
      "train_loss: 0.166634 | avg_loss: 0.276871 | gender_precise: 88.000000 (3952/4480) [35/186]\n",
      "gender_loss: 0.2820981442928314\n",
      "train_loss: 0.282098 | avg_loss: 0.277017 | gender_precise: 88.000000 (4062/4608) [36/186]\n",
      "gender_loss: 0.20197488367557526\n",
      "train_loss: 0.201975 | avg_loss: 0.274988 | gender_precise: 88.000000 (4177/4736) [37/186]\n",
      "gender_loss: 0.31254130601882935\n",
      "train_loss: 0.312541 | avg_loss: 0.275977 | gender_precise: 88.000000 (4290/4864) [38/186]\n",
      "gender_loss: 0.20069903135299683\n",
      "train_loss: 0.200699 | avg_loss: 0.274046 | gender_precise: 88.000000 (4406/4992) [39/186]\n",
      "gender_loss: 0.2621628940105438\n",
      "train_loss: 0.262163 | avg_loss: 0.273749 | gender_precise: 88.000000 (4517/5120) [40/186]\n",
      "gender_loss: 0.313423752784729\n",
      "train_loss: 0.313424 | avg_loss: 0.274717 | gender_precise: 88.000000 (4626/5248) [41/186]\n",
      "gender_loss: 0.23825642466545105\n",
      "train_loss: 0.238256 | avg_loss: 0.273849 | gender_precise: 88.000000 (4740/5376) [42/186]\n",
      "gender_loss: 0.2997695803642273\n",
      "train_loss: 0.299770 | avg_loss: 0.274452 | gender_precise: 88.000000 (4852/5504) [43/186]\n",
      "gender_loss: 0.25225797295570374\n",
      "train_loss: 0.252258 | avg_loss: 0.273947 | gender_precise: 88.000000 (4969/5632) [44/186]\n",
      "gender_loss: 0.305745393037796\n",
      "train_loss: 0.305745 | avg_loss: 0.274654 | gender_precise: 88.000000 (5076/5760) [45/186]\n",
      "gender_loss: 0.30916136503219604\n",
      "train_loss: 0.309161 | avg_loss: 0.275404 | gender_precise: 88.000000 (5186/5888) [46/186]\n",
      "gender_loss: 0.21737922728061676\n",
      "train_loss: 0.217379 | avg_loss: 0.274170 | gender_precise: 88.000000 (5304/6016) [47/186]\n",
      "gender_loss: 0.27456024289131165\n",
      "train_loss: 0.274560 | avg_loss: 0.274178 | gender_precise: 88.000000 (5413/6144) [48/186]\n",
      "gender_loss: 0.2604725658893585\n",
      "train_loss: 0.260473 | avg_loss: 0.273898 | gender_precise: 88.000000 (5527/6272) [49/186]\n",
      "gender_loss: 0.3502495288848877\n",
      "train_loss: 0.350250 | avg_loss: 0.275425 | gender_precise: 88.000000 (5633/6400) [50/186]\n",
      "gender_loss: 0.2506748139858246\n",
      "train_loss: 0.250675 | avg_loss: 0.274940 | gender_precise: 88.000000 (5748/6528) [51/186]\n",
      "gender_loss: 0.20867526531219482\n",
      "train_loss: 0.208675 | avg_loss: 0.273665 | gender_precise: 88.000000 (5865/6656) [52/186]\n",
      "gender_loss: 0.21986576914787292\n",
      "train_loss: 0.219866 | avg_loss: 0.272650 | gender_precise: 88.000000 (5979/6784) [53/186]\n",
      "gender_loss: 0.22220033407211304\n",
      "train_loss: 0.222200 | avg_loss: 0.271716 | gender_precise: 88.000000 (6094/6912) [54/186]\n",
      "gender_loss: 0.2460336685180664\n",
      "train_loss: 0.246034 | avg_loss: 0.271249 | gender_precise: 88.000000 (6206/7040) [55/186]\n",
      "gender_loss: 0.2992812693119049\n",
      "train_loss: 0.299281 | avg_loss: 0.271750 | gender_precise: 88.000000 (6318/7168) [56/186]\n",
      "gender_loss: 0.3890458047389984\n",
      "train_loss: 0.389046 | avg_loss: 0.273807 | gender_precise: 88.000000 (6428/7296) [57/186]\n",
      "gender_loss: 0.25159475207328796\n",
      "train_loss: 0.251595 | avg_loss: 0.273425 | gender_precise: 88.000000 (6544/7424) [58/186]\n",
      "gender_loss: 0.23969338834285736\n",
      "train_loss: 0.239693 | avg_loss: 0.272853 | gender_precise: 88.000000 (6656/7552) [59/186]\n",
      "gender_loss: 0.23188427090644836\n",
      "train_loss: 0.231884 | avg_loss: 0.272170 | gender_precise: 88.000000 (6770/7680) [60/186]\n",
      "gender_loss: 0.24205021560192108\n",
      "train_loss: 0.242050 | avg_loss: 0.271676 | gender_precise: 88.000000 (6882/7808) [61/186]\n",
      "gender_loss: 0.30117279291152954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.301173 | avg_loss: 0.272152 | gender_precise: 88.000000 (6991/7936) [62/186]\n",
      "gender_loss: 0.2842526435852051\n",
      "train_loss: 0.284253 | avg_loss: 0.272344 | gender_precise: 88.000000 (7100/8064) [63/186]\n",
      "gender_loss: 0.23186907172203064\n",
      "train_loss: 0.231869 | avg_loss: 0.271712 | gender_precise: 88.000000 (7217/8192) [64/186]\n",
      "gender_loss: 0.22669385373592377\n",
      "train_loss: 0.226694 | avg_loss: 0.271019 | gender_precise: 88.000000 (7331/8320) [65/186]\n",
      "gender_loss: 0.29553893208503723\n",
      "train_loss: 0.295539 | avg_loss: 0.271391 | gender_precise: 88.000000 (7443/8448) [66/186]\n",
      "gender_loss: 0.2562289834022522\n",
      "train_loss: 0.256229 | avg_loss: 0.271164 | gender_precise: 88.000000 (7557/8576) [67/186]\n",
      "gender_loss: 0.26393580436706543\n",
      "train_loss: 0.263936 | avg_loss: 0.271058 | gender_precise: 88.000000 (7670/8704) [68/186]\n",
      "gender_loss: 0.3027409017086029\n",
      "train_loss: 0.302741 | avg_loss: 0.271517 | gender_precise: 88.000000 (7780/8832) [69/186]\n",
      "gender_loss: 0.2534095346927643\n",
      "train_loss: 0.253410 | avg_loss: 0.271258 | gender_precise: 88.000000 (7894/8960) [70/186]\n",
      "gender_loss: 0.2857643663883209\n",
      "train_loss: 0.285764 | avg_loss: 0.271463 | gender_precise: 88.000000 (8008/9088) [71/186]\n",
      "gender_loss: 0.21642671525478363\n",
      "train_loss: 0.216427 | avg_loss: 0.270698 | gender_precise: 88.000000 (8120/9216) [72/186]\n",
      "gender_loss: 0.20979246497154236\n",
      "train_loss: 0.209792 | avg_loss: 0.269864 | gender_precise: 88.000000 (8238/9344) [73/186]\n",
      "gender_loss: 0.31383588910102844\n",
      "train_loss: 0.313836 | avg_loss: 0.270458 | gender_precise: 88.000000 (8350/9472) [74/186]\n",
      "gender_loss: 0.2730976641178131\n",
      "train_loss: 0.273098 | avg_loss: 0.270493 | gender_precise: 88.000000 (8460/9600) [75/186]\n",
      "gender_loss: 0.2752052843570709\n",
      "train_loss: 0.275205 | avg_loss: 0.270555 | gender_precise: 88.000000 (8574/9728) [76/186]\n",
      "gender_loss: 0.2992047667503357\n",
      "train_loss: 0.299205 | avg_loss: 0.270927 | gender_precise: 88.000000 (8687/9856) [77/186]\n",
      "gender_loss: 0.27626749873161316\n",
      "train_loss: 0.276267 | avg_loss: 0.270996 | gender_precise: 88.000000 (8800/9984) [78/186]\n",
      "gender_loss: 0.27176210284233093\n",
      "train_loss: 0.271762 | avg_loss: 0.271006 | gender_precise: 88.000000 (8912/10112) [79/186]\n",
      "gender_loss: 0.3475915193557739\n",
      "train_loss: 0.347592 | avg_loss: 0.271963 | gender_precise: 88.000000 (9024/10240) [80/186]\n",
      "gender_loss: 0.29164019227027893\n",
      "train_loss: 0.291640 | avg_loss: 0.272206 | gender_precise: 88.000000 (9135/10368) [81/186]\n",
      "gender_loss: 0.3174760341644287\n",
      "train_loss: 0.317476 | avg_loss: 0.272758 | gender_precise: 88.000000 (9244/10496) [82/186]\n",
      "gender_loss: 0.1759158968925476\n",
      "train_loss: 0.175916 | avg_loss: 0.271591 | gender_precise: 88.000000 (9362/10624) [83/186]\n",
      "gender_loss: 0.25266745686531067\n",
      "train_loss: 0.252667 | avg_loss: 0.271366 | gender_precise: 88.000000 (9477/10752) [84/186]\n",
      "gender_loss: 0.2420313060283661\n",
      "train_loss: 0.242031 | avg_loss: 0.271021 | gender_precise: 88.000000 (9589/10880) [85/186]\n",
      "gender_loss: 0.2827495336532593\n",
      "train_loss: 0.282750 | avg_loss: 0.271157 | gender_precise: 88.000000 (9709/11008) [86/186]\n",
      "gender_loss: 0.29887861013412476\n",
      "train_loss: 0.298879 | avg_loss: 0.271476 | gender_precise: 88.000000 (9819/11136) [87/186]\n",
      "gender_loss: 0.30858537554740906\n",
      "train_loss: 0.308585 | avg_loss: 0.271898 | gender_precise: 88.000000 (9926/11264) [88/186]\n",
      "gender_loss: 0.4074915051460266\n",
      "train_loss: 0.407492 | avg_loss: 0.273421 | gender_precise: 88.000000 (10036/11392) [89/186]\n",
      "gender_loss: 0.27727577090263367\n",
      "train_loss: 0.277276 | avg_loss: 0.273464 | gender_precise: 88.000000 (10147/11520) [90/186]\n",
      "gender_loss: 0.2122989445924759\n",
      "train_loss: 0.212299 | avg_loss: 0.272792 | gender_precise: 88.000000 (10264/11648) [91/186]\n",
      "gender_loss: 0.29275935888290405\n",
      "train_loss: 0.292759 | avg_loss: 0.273009 | gender_precise: 88.000000 (10378/11776) [92/186]\n",
      "gender_loss: 0.26722952723503113\n",
      "train_loss: 0.267230 | avg_loss: 0.272947 | gender_precise: 88.000000 (10487/11904) [93/186]\n",
      "gender_loss: 0.2595103681087494\n",
      "train_loss: 0.259510 | avg_loss: 0.272804 | gender_precise: 88.000000 (10599/12032) [94/186]\n",
      "gender_loss: 0.28961724042892456\n",
      "train_loss: 0.289617 | avg_loss: 0.272981 | gender_precise: 88.000000 (10708/12160) [95/186]\n",
      "gender_loss: 0.21415750682353973\n",
      "train_loss: 0.214158 | avg_loss: 0.272368 | gender_precise: 88.000000 (10824/12288) [96/186]\n",
      "gender_loss: 0.1923743635416031\n",
      "train_loss: 0.192374 | avg_loss: 0.271543 | gender_precise: 88.000000 (10941/12416) [97/186]\n",
      "gender_loss: 0.3828200101852417\n",
      "train_loss: 0.382820 | avg_loss: 0.272679 | gender_precise: 88.000000 (11051/12544) [98/186]\n",
      "gender_loss: 0.24936543405056\n",
      "train_loss: 0.249365 | avg_loss: 0.272443 | gender_precise: 88.000000 (11163/12672) [99/186]\n",
      "gender_loss: 0.2829867899417877\n",
      "train_loss: 0.282987 | avg_loss: 0.272549 | gender_precise: 88.000000 (11273/12800) [100/186]\n",
      "gender_loss: 0.2621081471443176\n",
      "train_loss: 0.262108 | avg_loss: 0.272445 | gender_precise: 88.000000 (11385/12928) [101/186]\n",
      "gender_loss: 0.20622657239437103\n",
      "train_loss: 0.206227 | avg_loss: 0.271796 | gender_precise: 88.000000 (11502/13056) [102/186]\n",
      "gender_loss: 0.23620636761188507\n",
      "train_loss: 0.236206 | avg_loss: 0.271451 | gender_precise: 88.000000 (11616/13184) [103/186]\n",
      "gender_loss: 0.28193724155426025\n",
      "train_loss: 0.281937 | avg_loss: 0.271551 | gender_precise: 88.000000 (11729/13312) [104/186]\n",
      "gender_loss: 0.1822335124015808\n",
      "train_loss: 0.182234 | avg_loss: 0.270701 | gender_precise: 88.000000 (11845/13440) [105/186]\n",
      "gender_loss: 0.257709801197052\n",
      "train_loss: 0.257710 | avg_loss: 0.270578 | gender_precise: 88.000000 (11955/13568) [106/186]\n",
      "gender_loss: 0.2552216053009033\n",
      "train_loss: 0.255222 | avg_loss: 0.270435 | gender_precise: 88.000000 (12073/13696) [107/186]\n",
      "gender_loss: 0.25913819670677185\n",
      "train_loss: 0.259138 | avg_loss: 0.270330 | gender_precise: 88.000000 (12184/13824) [108/186]\n",
      "gender_loss: 0.21099363267421722\n",
      "train_loss: 0.210994 | avg_loss: 0.269786 | gender_precise: 88.000000 (12303/13952) [109/186]\n",
      "gender_loss: 0.19599978625774384\n",
      "train_loss: 0.196000 | avg_loss: 0.269115 | gender_precise: 88.000000 (12420/14080) [110/186]\n",
      "gender_loss: 0.21206475794315338\n",
      "train_loss: 0.212065 | avg_loss: 0.268601 | gender_precise: 88.000000 (12536/14208) [111/186]\n",
      "gender_loss: 0.2610689699649811\n",
      "train_loss: 0.261069 | avg_loss: 0.268534 | gender_precise: 88.000000 (12650/14336) [112/186]\n",
      "gender_loss: 0.15379273891448975\n",
      "train_loss: 0.153793 | avg_loss: 0.267518 | gender_precise: 88.000000 (12771/14464) [113/186]\n",
      "gender_loss: 0.20623178780078888\n",
      "train_loss: 0.206232 | avg_loss: 0.266981 | gender_precise: 88.000000 (12881/14592) [114/186]\n",
      "gender_loss: 0.2239580899477005\n",
      "train_loss: 0.223958 | avg_loss: 0.266607 | gender_precise: 88.000000 (12995/14720) [115/186]\n",
      "gender_loss: 0.1815701425075531\n",
      "train_loss: 0.181570 | avg_loss: 0.265874 | gender_precise: 88.000000 (13114/14848) [116/186]\n",
      "gender_loss: 0.24010872840881348\n",
      "train_loss: 0.240109 | avg_loss: 0.265653 | gender_precise: 88.000000 (13229/14976) [117/186]\n",
      "gender_loss: 0.2357672154903412\n",
      "train_loss: 0.235767 | avg_loss: 0.265400 | gender_precise: 88.000000 (13343/15104) [118/186]\n",
      "gender_loss: 0.2770816385746002\n",
      "train_loss: 0.277082 | avg_loss: 0.265498 | gender_precise: 88.000000 (13457/15232) [119/186]\n",
      "gender_loss: 0.24400395154953003\n",
      "train_loss: 0.244004 | avg_loss: 0.265319 | gender_precise: 88.000000 (13570/15360) [120/186]\n",
      "gender_loss: 0.23810671269893646\n",
      "train_loss: 0.238107 | avg_loss: 0.265094 | gender_precise: 88.000000 (13680/15488) [121/186]\n",
      "gender_loss: 0.27169182896614075\n",
      "train_loss: 0.271692 | avg_loss: 0.265148 | gender_precise: 88.000000 (13797/15616) [122/186]\n",
      "gender_loss: 0.2249850630760193\n",
      "train_loss: 0.224985 | avg_loss: 0.264822 | gender_precise: 88.000000 (13913/15744) [123/186]\n",
      "gender_loss: 0.2596079409122467\n",
      "train_loss: 0.259608 | avg_loss: 0.264780 | gender_precise: 88.000000 (14030/15872) [124/186]\n",
      "gender_loss: 0.21983812749385834\n",
      "train_loss: 0.219838 | avg_loss: 0.264420 | gender_precise: 88.000000 (14144/16000) [125/186]\n",
      "gender_loss: 0.3030076026916504\n",
      "train_loss: 0.303008 | avg_loss: 0.264726 | gender_precise: 88.000000 (14255/16128) [126/186]\n",
      "gender_loss: 0.2581838071346283\n",
      "train_loss: 0.258184 | avg_loss: 0.264675 | gender_precise: 88.000000 (14369/16256) [127/186]\n",
      "gender_loss: 0.2201952487230301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.220195 | avg_loss: 0.264327 | gender_precise: 88.000000 (14484/16384) [128/186]\n",
      "gender_loss: 0.260219544172287\n",
      "train_loss: 0.260220 | avg_loss: 0.264296 | gender_precise: 88.000000 (14597/16512) [129/186]\n",
      "gender_loss: 0.18274301290512085\n",
      "train_loss: 0.182743 | avg_loss: 0.263668 | gender_precise: 88.000000 (14717/16640) [130/186]\n",
      "gender_loss: 0.24205027520656586\n",
      "train_loss: 0.242050 | avg_loss: 0.263503 | gender_precise: 88.000000 (14834/16768) [131/186]\n",
      "gender_loss: 0.22829067707061768\n",
      "train_loss: 0.228291 | avg_loss: 0.263236 | gender_precise: 88.000000 (14952/16896) [132/186]\n",
      "gender_loss: 0.1544123739004135\n",
      "train_loss: 0.154412 | avg_loss: 0.262418 | gender_precise: 88.000000 (15071/17024) [133/186]\n",
      "gender_loss: 0.32840728759765625\n",
      "train_loss: 0.328407 | avg_loss: 0.262911 | gender_precise: 88.000000 (15180/17152) [134/186]\n",
      "gender_loss: 0.36451080441474915\n",
      "train_loss: 0.364511 | avg_loss: 0.263663 | gender_precise: 88.000000 (15285/17280) [135/186]\n",
      "gender_loss: 0.37313899397850037\n",
      "train_loss: 0.373139 | avg_loss: 0.264468 | gender_precise: 88.000000 (15392/17408) [136/186]\n",
      "gender_loss: 0.322169691324234\n",
      "train_loss: 0.322170 | avg_loss: 0.264889 | gender_precise: 88.000000 (15505/17536) [137/186]\n",
      "gender_loss: 0.2121165692806244\n",
      "train_loss: 0.212117 | avg_loss: 0.264507 | gender_precise: 88.000000 (15622/17664) [138/186]\n",
      "gender_loss: 0.25686517357826233\n",
      "train_loss: 0.256865 | avg_loss: 0.264452 | gender_precise: 88.000000 (15735/17792) [139/186]\n",
      "gender_loss: 0.30212047696113586\n",
      "train_loss: 0.302120 | avg_loss: 0.264721 | gender_precise: 88.000000 (15848/17920) [140/186]\n",
      "gender_loss: 0.2046545296907425\n",
      "train_loss: 0.204655 | avg_loss: 0.264295 | gender_precise: 88.000000 (15964/18048) [141/186]\n",
      "gender_loss: 0.2205083668231964\n",
      "train_loss: 0.220508 | avg_loss: 0.263987 | gender_precise: 88.000000 (16079/18176) [142/186]\n",
      "gender_loss: 0.23699942231178284\n",
      "train_loss: 0.236999 | avg_loss: 0.263798 | gender_precise: 88.000000 (16194/18304) [143/186]\n",
      "gender_loss: 0.22066262364387512\n",
      "train_loss: 0.220663 | avg_loss: 0.263498 | gender_precise: 88.000000 (16312/18432) [144/186]\n",
      "gender_loss: 0.2906677722930908\n",
      "train_loss: 0.290668 | avg_loss: 0.263686 | gender_precise: 88.000000 (16420/18560) [145/186]\n",
      "gender_loss: 0.1885128766298294\n",
      "train_loss: 0.188513 | avg_loss: 0.263171 | gender_precise: 88.000000 (16537/18688) [146/186]\n",
      "gender_loss: 0.24003416299819946\n",
      "train_loss: 0.240034 | avg_loss: 0.263014 | gender_precise: 88.000000 (16648/18816) [147/186]\n",
      "gender_loss: 0.26546844840049744\n",
      "train_loss: 0.265468 | avg_loss: 0.263030 | gender_precise: 88.000000 (16758/18944) [148/186]\n",
      "gender_loss: 0.3034997880458832\n",
      "train_loss: 0.303500 | avg_loss: 0.263302 | gender_precise: 88.000000 (16870/19072) [149/186]\n",
      "gender_loss: 0.24643191695213318\n",
      "train_loss: 0.246432 | avg_loss: 0.263189 | gender_precise: 88.000000 (16983/19200) [150/186]\n",
      "gender_loss: 0.23253729939460754\n",
      "train_loss: 0.232537 | avg_loss: 0.262986 | gender_precise: 88.000000 (17099/19328) [151/186]\n",
      "gender_loss: 0.26250889897346497\n",
      "train_loss: 0.262509 | avg_loss: 0.262983 | gender_precise: 88.000000 (17209/19456) [152/186]\n",
      "gender_loss: 0.2211770862340927\n",
      "train_loss: 0.221177 | avg_loss: 0.262710 | gender_precise: 88.000000 (17325/19584) [153/186]\n",
      "gender_loss: 0.32461783289909363\n",
      "train_loss: 0.324618 | avg_loss: 0.263112 | gender_precise: 88.000000 (17435/19712) [154/186]\n",
      "gender_loss: 0.33743250370025635\n",
      "train_loss: 0.337433 | avg_loss: 0.263591 | gender_precise: 88.000000 (17543/19840) [155/186]\n",
      "gender_loss: 0.20370326936244965\n",
      "train_loss: 0.203703 | avg_loss: 0.263208 | gender_precise: 88.000000 (17660/19968) [156/186]\n",
      "gender_loss: 0.3008597791194916\n",
      "train_loss: 0.300860 | avg_loss: 0.263447 | gender_precise: 88.000000 (17768/20096) [157/186]\n",
      "gender_loss: 0.27135220170021057\n",
      "train_loss: 0.271352 | avg_loss: 0.263497 | gender_precise: 88.000000 (17881/20224) [158/186]\n",
      "gender_loss: 0.22598685324192047\n",
      "train_loss: 0.225987 | avg_loss: 0.263261 | gender_precise: 88.000000 (17999/20352) [159/186]\n",
      "gender_loss: 0.2680567800998688\n",
      "train_loss: 0.268057 | avg_loss: 0.263291 | gender_precise: 88.000000 (18108/20480) [160/186]\n",
      "gender_loss: 0.3318648636341095\n",
      "train_loss: 0.331865 | avg_loss: 0.263717 | gender_precise: 88.000000 (18221/20608) [161/186]\n",
      "gender_loss: 0.2467949241399765\n",
      "train_loss: 0.246795 | avg_loss: 0.263613 | gender_precise: 88.000000 (18334/20736) [162/186]\n",
      "gender_loss: 0.182687908411026\n",
      "train_loss: 0.182688 | avg_loss: 0.263116 | gender_precise: 88.000000 (18452/20864) [163/186]\n",
      "gender_loss: 0.22001375257968903\n",
      "train_loss: 0.220014 | avg_loss: 0.262854 | gender_precise: 88.000000 (18569/20992) [164/186]\n",
      "gender_loss: 0.29190894961357117\n",
      "train_loss: 0.291909 | avg_loss: 0.263030 | gender_precise: 88.000000 (18679/21120) [165/186]\n",
      "gender_loss: 0.26175427436828613\n",
      "train_loss: 0.261754 | avg_loss: 0.263022 | gender_precise: 88.000000 (18790/21248) [166/186]\n",
      "gender_loss: 0.25011351704597473\n",
      "train_loss: 0.250114 | avg_loss: 0.262945 | gender_precise: 88.000000 (18899/21376) [167/186]\n",
      "gender_loss: 0.2858152985572815\n",
      "train_loss: 0.285815 | avg_loss: 0.263081 | gender_precise: 88.000000 (19005/21504) [168/186]\n",
      "gender_loss: 0.4134811758995056\n",
      "train_loss: 0.413481 | avg_loss: 0.263971 | gender_precise: 88.000000 (19109/21632) [169/186]\n",
      "gender_loss: 0.2019282579421997\n",
      "train_loss: 0.201928 | avg_loss: 0.263606 | gender_precise: 88.000000 (19224/21760) [170/186]\n",
      "gender_loss: 0.22696177661418915\n",
      "train_loss: 0.226962 | avg_loss: 0.263392 | gender_precise: 88.000000 (19338/21888) [171/186]\n",
      "gender_loss: 0.2571122646331787\n",
      "train_loss: 0.257112 | avg_loss: 0.263355 | gender_precise: 88.000000 (19451/22016) [172/186]\n",
      "gender_loss: 0.16892597079277039\n",
      "train_loss: 0.168926 | avg_loss: 0.262809 | gender_precise: 88.000000 (19573/22144) [173/186]\n",
      "gender_loss: 0.22155606746673584\n",
      "train_loss: 0.221556 | avg_loss: 0.262572 | gender_precise: 88.000000 (19689/22272) [174/186]\n",
      "gender_loss: 0.2539222538471222\n",
      "train_loss: 0.253922 | avg_loss: 0.262523 | gender_precise: 88.000000 (19805/22400) [175/186]\n",
      "gender_loss: 0.2582589387893677\n",
      "train_loss: 0.258259 | avg_loss: 0.262498 | gender_precise: 88.000000 (19920/22528) [176/186]\n",
      "gender_loss: 0.1874699890613556\n",
      "train_loss: 0.187470 | avg_loss: 0.262075 | gender_precise: 88.000000 (20041/22656) [177/186]\n",
      "gender_loss: 0.2618371546268463\n",
      "train_loss: 0.261837 | avg_loss: 0.262073 | gender_precise: 88.000000 (20153/22784) [178/186]\n",
      "gender_loss: 0.18887995183467865\n",
      "train_loss: 0.188880 | avg_loss: 0.261664 | gender_precise: 88.000000 (20267/22912) [179/186]\n",
      "gender_loss: 0.2822943925857544\n",
      "train_loss: 0.282294 | avg_loss: 0.261779 | gender_precise: 88.000000 (20376/23040) [180/186]\n",
      "gender_loss: 0.21728084981441498\n",
      "train_loss: 0.217281 | avg_loss: 0.261533 | gender_precise: 88.000000 (20491/23168) [181/186]\n",
      "gender_loss: 0.25278976559638977\n",
      "train_loss: 0.252790 | avg_loss: 0.261485 | gender_precise: 88.000000 (20606/23296) [182/186]\n",
      "gender_loss: 0.2760460078716278\n",
      "train_loss: 0.276046 | avg_loss: 0.261565 | gender_precise: 88.000000 (20717/23424) [183/186]\n",
      "gender_loss: 0.3695223331451416\n",
      "train_loss: 0.369522 | avg_loss: 0.262151 | gender_precise: 88.000000 (20824/23552) [184/186]\n",
      "gender_loss: 0.27626097202301025\n",
      "train_loss: 0.276261 | avg_loss: 0.262228 | gender_precise: 88.000000 (20934/23680) [185/186]\n",
      "gender_loss: 0.1366129070520401\n",
      "train_loss: 0.136613 | avg_loss: 0.261552 | gender_precise: 88.000000 (20961/23708) [186/186]\n",
      "\n",
      "Test\n",
      "gender_prec: 84.000000 (108/128) [1/2]\n",
      "gender_prec: 85.000000 (114/134) [2/2]\n",
      "Saving..\n",
      "Number epoch: 6\n",
      "gender_loss: 0.24007157981395721\n",
      "train_loss: 0.240072 | avg_loss: 0.240072 | gender_precise: 87.000000 (112/128) [1/186]\n",
      "gender_loss: 0.2774813771247864\n",
      "train_loss: 0.277481 | avg_loss: 0.258776 | gender_precise: 89.000000 (228/256) [2/186]\n",
      "gender_loss: 0.3127659857273102\n",
      "train_loss: 0.312766 | avg_loss: 0.276773 | gender_precise: 88.000000 (341/384) [3/186]\n",
      "gender_loss: 0.2061864733695984\n",
      "train_loss: 0.206186 | avg_loss: 0.259126 | gender_precise: 89.000000 (458/512) [4/186]\n",
      "gender_loss: 0.1770070642232895\n",
      "train_loss: 0.177007 | avg_loss: 0.242703 | gender_precise: 89.000000 (573/640) [5/186]\n",
      "gender_loss: 0.3409309983253479\n",
      "train_loss: 0.340931 | avg_loss: 0.259074 | gender_precise: 88.000000 (681/768) [6/186]\n",
      "gender_loss: 0.2575541138648987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.257554 | avg_loss: 0.258857 | gender_precise: 88.000000 (795/896) [7/186]\n",
      "gender_loss: 0.39671632647514343\n",
      "train_loss: 0.396716 | avg_loss: 0.276089 | gender_precise: 88.000000 (906/1024) [8/186]\n",
      "gender_loss: 0.3173665702342987\n",
      "train_loss: 0.317367 | avg_loss: 0.280676 | gender_precise: 88.000000 (1017/1152) [9/186]\n",
      "gender_loss: 0.29883673787117004\n",
      "train_loss: 0.298837 | avg_loss: 0.282492 | gender_precise: 88.000000 (1131/1280) [10/186]\n",
      "gender_loss: 0.2512652277946472\n",
      "train_loss: 0.251265 | avg_loss: 0.279653 | gender_precise: 88.000000 (1246/1408) [11/186]\n",
      "gender_loss: 0.21312062442302704\n",
      "train_loss: 0.213121 | avg_loss: 0.274109 | gender_precise: 88.000000 (1361/1536) [12/186]\n",
      "gender_loss: 0.29095640778541565\n",
      "train_loss: 0.290956 | avg_loss: 0.275405 | gender_precise: 88.000000 (1473/1664) [13/186]\n",
      "gender_loss: 0.2684505879878998\n",
      "train_loss: 0.268451 | avg_loss: 0.274908 | gender_precise: 88.000000 (1585/1792) [14/186]\n",
      "gender_loss: 0.309044748544693\n",
      "train_loss: 0.309045 | avg_loss: 0.277184 | gender_precise: 88.000000 (1697/1920) [15/186]\n",
      "gender_loss: 0.19765222072601318\n",
      "train_loss: 0.197652 | avg_loss: 0.272213 | gender_precise: 88.000000 (1814/2048) [16/186]\n",
      "gender_loss: 0.16950486600399017\n",
      "train_loss: 0.169505 | avg_loss: 0.266171 | gender_precise: 88.000000 (1931/2176) [17/186]\n",
      "gender_loss: 0.2353648543357849\n",
      "train_loss: 0.235365 | avg_loss: 0.264460 | gender_precise: 88.000000 (2047/2304) [18/186]\n",
      "gender_loss: 0.24147672951221466\n",
      "train_loss: 0.241477 | avg_loss: 0.263250 | gender_precise: 88.000000 (2161/2432) [19/186]\n",
      "gender_loss: 0.2306307703256607\n",
      "train_loss: 0.230631 | avg_loss: 0.261619 | gender_precise: 88.000000 (2276/2560) [20/186]\n",
      "gender_loss: 0.20060127973556519\n",
      "train_loss: 0.200601 | avg_loss: 0.258714 | gender_precise: 89.000000 (2393/2688) [21/186]\n",
      "gender_loss: 0.26727840304374695\n",
      "train_loss: 0.267278 | avg_loss: 0.259103 | gender_precise: 88.000000 (2502/2816) [22/186]\n",
      "gender_loss: 0.22342711687088013\n",
      "train_loss: 0.223427 | avg_loss: 0.257552 | gender_precise: 88.000000 (2618/2944) [23/186]\n",
      "gender_loss: 0.17228859663009644\n",
      "train_loss: 0.172289 | avg_loss: 0.253999 | gender_precise: 89.000000 (2737/3072) [24/186]\n",
      "gender_loss: 0.3166678249835968\n",
      "train_loss: 0.316668 | avg_loss: 0.256506 | gender_precise: 88.000000 (2846/3200) [25/186]\n",
      "gender_loss: 0.16297674179077148\n",
      "train_loss: 0.162977 | avg_loss: 0.252909 | gender_precise: 89.000000 (2964/3328) [26/186]\n",
      "gender_loss: 0.20858293771743774\n",
      "train_loss: 0.208583 | avg_loss: 0.251267 | gender_precise: 89.000000 (3081/3456) [27/186]\n",
      "gender_loss: 0.268002986907959\n",
      "train_loss: 0.268003 | avg_loss: 0.251865 | gender_precise: 89.000000 (3191/3584) [28/186]\n",
      "gender_loss: 0.32216760516166687\n",
      "train_loss: 0.322168 | avg_loss: 0.254289 | gender_precise: 88.000000 (3303/3712) [29/186]\n",
      "gender_loss: 0.18125145137310028\n",
      "train_loss: 0.181251 | avg_loss: 0.251854 | gender_precise: 89.000000 (3421/3840) [30/186]\n",
      "gender_loss: 0.22263798117637634\n",
      "train_loss: 0.222638 | avg_loss: 0.250912 | gender_precise: 89.000000 (3538/3968) [31/186]\n",
      "gender_loss: 0.13668687641620636\n",
      "train_loss: 0.136687 | avg_loss: 0.247342 | gender_precise: 89.000000 (3659/4096) [32/186]\n",
      "gender_loss: 0.2866846024990082\n",
      "train_loss: 0.286685 | avg_loss: 0.248535 | gender_precise: 89.000000 (3765/4224) [33/186]\n",
      "gender_loss: 0.2404291331768036\n",
      "train_loss: 0.240429 | avg_loss: 0.248296 | gender_precise: 89.000000 (3880/4352) [34/186]\n",
      "gender_loss: 0.24017873406410217\n",
      "train_loss: 0.240179 | avg_loss: 0.248064 | gender_precise: 89.000000 (3993/4480) [35/186]\n",
      "gender_loss: 0.2419758290052414\n",
      "train_loss: 0.241976 | avg_loss: 0.247895 | gender_precise: 89.000000 (4105/4608) [36/186]\n",
      "gender_loss: 0.23828884959220886\n",
      "train_loss: 0.238289 | avg_loss: 0.247635 | gender_precise: 89.000000 (4219/4736) [37/186]\n",
      "gender_loss: 0.2369673252105713\n",
      "train_loss: 0.236967 | avg_loss: 0.247355 | gender_precise: 89.000000 (4336/4864) [38/186]\n",
      "gender_loss: 0.1814400851726532\n",
      "train_loss: 0.181440 | avg_loss: 0.245665 | gender_precise: 89.000000 (4456/4992) [39/186]\n",
      "gender_loss: 0.19649635255336761\n",
      "train_loss: 0.196496 | avg_loss: 0.244435 | gender_precise: 89.000000 (4574/5120) [40/186]\n",
      "gender_loss: 0.3374069035053253\n",
      "train_loss: 0.337407 | avg_loss: 0.246703 | gender_precise: 89.000000 (4680/5248) [41/186]\n",
      "gender_loss: 0.3354572057723999\n",
      "train_loss: 0.335457 | avg_loss: 0.248816 | gender_precise: 89.000000 (4788/5376) [42/186]\n",
      "gender_loss: 0.2722768485546112\n",
      "train_loss: 0.272277 | avg_loss: 0.249362 | gender_precise: 89.000000 (4905/5504) [43/186]\n",
      "gender_loss: 0.4077501595020294\n",
      "train_loss: 0.407750 | avg_loss: 0.252961 | gender_precise: 89.000000 (5014/5632) [44/186]\n",
      "gender_loss: 0.3001140356063843\n",
      "train_loss: 0.300114 | avg_loss: 0.254009 | gender_precise: 88.000000 (5126/5760) [45/186]\n",
      "gender_loss: 0.2981378436088562\n",
      "train_loss: 0.298138 | avg_loss: 0.254969 | gender_precise: 88.000000 (5240/5888) [46/186]\n",
      "gender_loss: 0.21886257827281952\n",
      "train_loss: 0.218863 | avg_loss: 0.254200 | gender_precise: 89.000000 (5357/6016) [47/186]\n",
      "gender_loss: 0.19947996735572815\n",
      "train_loss: 0.199480 | avg_loss: 0.253060 | gender_precise: 89.000000 (5472/6144) [48/186]\n",
      "gender_loss: 0.29835185408592224\n",
      "train_loss: 0.298352 | avg_loss: 0.253985 | gender_precise: 88.000000 (5580/6272) [49/186]\n",
      "gender_loss: 0.20226213335990906\n",
      "train_loss: 0.202262 | avg_loss: 0.252950 | gender_precise: 89.000000 (5698/6400) [50/186]\n",
      "gender_loss: 0.27161625027656555\n",
      "train_loss: 0.271616 | avg_loss: 0.253316 | gender_precise: 88.000000 (5807/6528) [51/186]\n",
      "gender_loss: 0.2247418910264969\n",
      "train_loss: 0.224742 | avg_loss: 0.252767 | gender_precise: 88.000000 (5922/6656) [52/186]\n",
      "gender_loss: 0.2245386689901352\n",
      "train_loss: 0.224539 | avg_loss: 0.252234 | gender_precise: 88.000000 (6037/6784) [53/186]\n",
      "gender_loss: 0.1954083889722824\n",
      "train_loss: 0.195408 | avg_loss: 0.251182 | gender_precise: 89.000000 (6155/6912) [54/186]\n",
      "gender_loss: 0.17988458275794983\n",
      "train_loss: 0.179885 | avg_loss: 0.249886 | gender_precise: 89.000000 (6273/7040) [55/186]\n",
      "gender_loss: 0.22977738082408905\n",
      "train_loss: 0.229777 | avg_loss: 0.249526 | gender_precise: 89.000000 (6390/7168) [56/186]\n",
      "gender_loss: 0.23383009433746338\n",
      "train_loss: 0.233830 | avg_loss: 0.249251 | gender_precise: 89.000000 (6499/7296) [57/186]\n",
      "gender_loss: 0.2722809314727783\n",
      "train_loss: 0.272281 | avg_loss: 0.249648 | gender_precise: 89.000000 (6615/7424) [58/186]\n",
      "gender_loss: 0.18863560259342194\n",
      "train_loss: 0.188636 | avg_loss: 0.248614 | gender_precise: 89.000000 (6732/7552) [59/186]\n",
      "gender_loss: 0.3397449553012848\n",
      "train_loss: 0.339745 | avg_loss: 0.250133 | gender_precise: 89.000000 (6840/7680) [60/186]\n",
      "gender_loss: 0.2109672725200653\n",
      "train_loss: 0.210967 | avg_loss: 0.249491 | gender_precise: 89.000000 (6959/7808) [61/186]\n",
      "gender_loss: 0.2220521867275238\n",
      "train_loss: 0.222052 | avg_loss: 0.249048 | gender_precise: 89.000000 (7072/7936) [62/186]\n",
      "gender_loss: 0.26117074489593506\n",
      "train_loss: 0.261171 | avg_loss: 0.249241 | gender_precise: 89.000000 (7189/8064) [63/186]\n",
      "gender_loss: 0.21754103899002075\n",
      "train_loss: 0.217541 | avg_loss: 0.248745 | gender_precise: 89.000000 (7305/8192) [64/186]\n",
      "gender_loss: 0.2540263831615448\n",
      "train_loss: 0.254026 | avg_loss: 0.248827 | gender_precise: 89.000000 (7417/8320) [65/186]\n",
      "gender_loss: 0.2191961705684662\n",
      "train_loss: 0.219196 | avg_loss: 0.248378 | gender_precise: 89.000000 (7535/8448) [66/186]\n",
      "gender_loss: 0.2584240138530731\n",
      "train_loss: 0.258424 | avg_loss: 0.248528 | gender_precise: 89.000000 (7653/8576) [67/186]\n",
      "gender_loss: 0.28263378143310547\n",
      "train_loss: 0.282634 | avg_loss: 0.249029 | gender_precise: 89.000000 (7762/8704) [68/186]\n",
      "gender_loss: 0.2430325746536255\n",
      "train_loss: 0.243033 | avg_loss: 0.248942 | gender_precise: 89.000000 (7879/8832) [69/186]\n",
      "gender_loss: 0.18006950616836548\n",
      "train_loss: 0.180070 | avg_loss: 0.247958 | gender_precise: 89.000000 (7995/8960) [70/186]\n",
      "gender_loss: 0.3468332886695862\n",
      "train_loss: 0.346833 | avg_loss: 0.249351 | gender_precise: 89.000000 (8110/9088) [71/186]\n",
      "gender_loss: 0.35668063163757324\n",
      "train_loss: 0.356681 | avg_loss: 0.250842 | gender_precise: 89.000000 (8218/9216) [72/186]\n",
      "gender_loss: 0.2928788363933563\n",
      "train_loss: 0.292879 | avg_loss: 0.251417 | gender_precise: 89.000000 (8332/9344) [73/186]\n",
      "gender_loss: 0.2555992007255554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.255599 | avg_loss: 0.251474 | gender_precise: 89.000000 (8447/9472) [74/186]\n",
      "gender_loss: 0.2262522280216217\n",
      "train_loss: 0.226252 | avg_loss: 0.251138 | gender_precise: 89.000000 (8558/9600) [75/186]\n",
      "gender_loss: 0.2440306395292282\n",
      "train_loss: 0.244031 | avg_loss: 0.251044 | gender_precise: 89.000000 (8672/9728) [76/186]\n",
      "gender_loss: 0.3024007976055145\n",
      "train_loss: 0.302401 | avg_loss: 0.251711 | gender_precise: 89.000000 (8779/9856) [77/186]\n",
      "gender_loss: 0.3301714062690735\n",
      "train_loss: 0.330171 | avg_loss: 0.252717 | gender_precise: 89.000000 (8891/9984) [78/186]\n",
      "gender_loss: 0.29227879643440247\n",
      "train_loss: 0.292279 | avg_loss: 0.253218 | gender_precise: 89.000000 (9003/10112) [79/186]\n",
      "gender_loss: 0.2532590627670288\n",
      "train_loss: 0.253259 | avg_loss: 0.253218 | gender_precise: 88.000000 (9113/10240) [80/186]\n",
      "gender_loss: 0.23357656598091125\n",
      "train_loss: 0.233577 | avg_loss: 0.252976 | gender_precise: 89.000000 (9229/10368) [81/186]\n",
      "gender_loss: 0.23660892248153687\n",
      "train_loss: 0.236609 | avg_loss: 0.252776 | gender_precise: 89.000000 (9343/10496) [82/186]\n",
      "gender_loss: 0.25284022092819214\n",
      "train_loss: 0.252840 | avg_loss: 0.252777 | gender_precise: 89.000000 (9457/10624) [83/186]\n",
      "gender_loss: 0.192747563123703\n",
      "train_loss: 0.192748 | avg_loss: 0.252062 | gender_precise: 89.000000 (9574/10752) [84/186]\n",
      "gender_loss: 0.22035856544971466\n",
      "train_loss: 0.220359 | avg_loss: 0.251689 | gender_precise: 89.000000 (9688/10880) [85/186]\n",
      "gender_loss: 0.2434072494506836\n",
      "train_loss: 0.243407 | avg_loss: 0.251593 | gender_precise: 89.000000 (9804/11008) [86/186]\n",
      "gender_loss: 0.31560343503952026\n",
      "train_loss: 0.315603 | avg_loss: 0.252329 | gender_precise: 88.000000 (9911/11136) [87/186]\n",
      "gender_loss: 0.23138150572776794\n",
      "train_loss: 0.231382 | avg_loss: 0.252091 | gender_precise: 89.000000 (10028/11264) [88/186]\n",
      "gender_loss: 0.3020927906036377\n",
      "train_loss: 0.302093 | avg_loss: 0.252653 | gender_precise: 89.000000 (10142/11392) [89/186]\n",
      "gender_loss: 0.19816365838050842\n",
      "train_loss: 0.198164 | avg_loss: 0.252047 | gender_precise: 89.000000 (10261/11520) [90/186]\n",
      "gender_loss: 0.151352196931839\n",
      "train_loss: 0.151352 | avg_loss: 0.250941 | gender_precise: 89.000000 (10382/11648) [91/186]\n",
      "gender_loss: 0.26104193925857544\n",
      "train_loss: 0.261042 | avg_loss: 0.251050 | gender_precise: 89.000000 (10493/11776) [92/186]\n",
      "gender_loss: 0.2678186893463135\n",
      "train_loss: 0.267819 | avg_loss: 0.251231 | gender_precise: 89.000000 (10610/11904) [93/186]\n",
      "gender_loss: 0.25110557675361633\n",
      "train_loss: 0.251106 | avg_loss: 0.251229 | gender_precise: 89.000000 (10727/12032) [94/186]\n",
      "gender_loss: 0.27774718403816223\n",
      "train_loss: 0.277747 | avg_loss: 0.251509 | gender_precise: 89.000000 (10839/12160) [95/186]\n",
      "gender_loss: 0.20712730288505554\n",
      "train_loss: 0.207127 | avg_loss: 0.251046 | gender_precise: 89.000000 (10958/12288) [96/186]\n",
      "gender_loss: 0.17470750212669373\n",
      "train_loss: 0.174708 | avg_loss: 0.250259 | gender_precise: 89.000000 (11077/12416) [97/186]\n",
      "gender_loss: 0.23248450458049774\n",
      "train_loss: 0.232485 | avg_loss: 0.250078 | gender_precise: 89.000000 (11191/12544) [98/186]\n",
      "gender_loss: 0.2687860429286957\n",
      "train_loss: 0.268786 | avg_loss: 0.250267 | gender_precise: 89.000000 (11303/12672) [99/186]\n",
      "gender_loss: 0.2630833089351654\n",
      "train_loss: 0.263083 | avg_loss: 0.250395 | gender_precise: 89.000000 (11418/12800) [100/186]\n",
      "gender_loss: 0.22871588170528412\n",
      "train_loss: 0.228716 | avg_loss: 0.250180 | gender_precise: 89.000000 (11531/12928) [101/186]\n",
      "gender_loss: 0.2557525932788849\n",
      "train_loss: 0.255753 | avg_loss: 0.250235 | gender_precise: 89.000000 (11646/13056) [102/186]\n",
      "gender_loss: 0.20110099017620087\n",
      "train_loss: 0.201101 | avg_loss: 0.249758 | gender_precise: 89.000000 (11760/13184) [103/186]\n",
      "gender_loss: 0.2912074625492096\n",
      "train_loss: 0.291207 | avg_loss: 0.250157 | gender_precise: 89.000000 (11871/13312) [104/186]\n",
      "gender_loss: 0.2956969439983368\n",
      "train_loss: 0.295697 | avg_loss: 0.250590 | gender_precise: 89.000000 (11979/13440) [105/186]\n",
      "gender_loss: 0.25907424092292786\n",
      "train_loss: 0.259074 | avg_loss: 0.250670 | gender_precise: 89.000000 (12094/13568) [106/186]\n",
      "gender_loss: 0.24017266929149628\n",
      "train_loss: 0.240173 | avg_loss: 0.250572 | gender_precise: 89.000000 (12207/13696) [107/186]\n",
      "gender_loss: 0.334054172039032\n",
      "train_loss: 0.334054 | avg_loss: 0.251345 | gender_precise: 89.000000 (12318/13824) [108/186]\n",
      "gender_loss: 0.25100642442703247\n",
      "train_loss: 0.251006 | avg_loss: 0.251342 | gender_precise: 89.000000 (12435/13952) [109/186]\n",
      "gender_loss: 0.32368937134742737\n",
      "train_loss: 0.323689 | avg_loss: 0.252000 | gender_precise: 89.000000 (12548/14080) [110/186]\n",
      "gender_loss: 0.1897142082452774\n",
      "train_loss: 0.189714 | avg_loss: 0.251439 | gender_precise: 89.000000 (12666/14208) [111/186]\n",
      "gender_loss: 0.28129488229751587\n",
      "train_loss: 0.281295 | avg_loss: 0.251705 | gender_precise: 89.000000 (12778/14336) [112/186]\n",
      "gender_loss: 0.19315804541110992\n",
      "train_loss: 0.193158 | avg_loss: 0.251187 | gender_precise: 89.000000 (12896/14464) [113/186]\n",
      "gender_loss: 0.15646801888942719\n",
      "train_loss: 0.156468 | avg_loss: 0.250356 | gender_precise: 89.000000 (13016/14592) [114/186]\n",
      "gender_loss: 0.2696806490421295\n",
      "train_loss: 0.269681 | avg_loss: 0.250524 | gender_precise: 89.000000 (13125/14720) [115/186]\n",
      "gender_loss: 0.20085512101650238\n",
      "train_loss: 0.200855 | avg_loss: 0.250096 | gender_precise: 89.000000 (13240/14848) [116/186]\n",
      "gender_loss: 0.23817135393619537\n",
      "train_loss: 0.238171 | avg_loss: 0.249994 | gender_precise: 89.000000 (13353/14976) [117/186]\n",
      "gender_loss: 0.19767634570598602\n",
      "train_loss: 0.197676 | avg_loss: 0.249551 | gender_precise: 89.000000 (13467/15104) [118/186]\n",
      "gender_loss: 0.25435084104537964\n",
      "train_loss: 0.254351 | avg_loss: 0.249591 | gender_precise: 89.000000 (13580/15232) [119/186]\n",
      "gender_loss: 0.1929260641336441\n",
      "train_loss: 0.192926 | avg_loss: 0.249119 | gender_precise: 89.000000 (13698/15360) [120/186]\n",
      "gender_loss: 0.2704426646232605\n",
      "train_loss: 0.270443 | avg_loss: 0.249295 | gender_precise: 89.000000 (13810/15488) [121/186]\n",
      "gender_loss: 0.21870307624340057\n",
      "train_loss: 0.218703 | avg_loss: 0.249044 | gender_precise: 89.000000 (13925/15616) [122/186]\n",
      "gender_loss: 0.23479369282722473\n",
      "train_loss: 0.234794 | avg_loss: 0.248929 | gender_precise: 89.000000 (14038/15744) [123/186]\n",
      "gender_loss: 0.3286442458629608\n",
      "train_loss: 0.328644 | avg_loss: 0.249571 | gender_precise: 89.000000 (14148/15872) [124/186]\n",
      "gender_loss: 0.23268403112888336\n",
      "train_loss: 0.232684 | avg_loss: 0.249436 | gender_precise: 89.000000 (14260/16000) [125/186]\n",
      "gender_loss: 0.2780391573905945\n",
      "train_loss: 0.278039 | avg_loss: 0.249663 | gender_precise: 89.000000 (14369/16128) [126/186]\n",
      "gender_loss: 0.26426178216934204\n",
      "train_loss: 0.264262 | avg_loss: 0.249778 | gender_precise: 89.000000 (14484/16256) [127/186]\n",
      "gender_loss: 0.27985894680023193\n",
      "train_loss: 0.279859 | avg_loss: 0.250013 | gender_precise: 89.000000 (14599/16384) [128/186]\n",
      "gender_loss: 0.18410487473011017\n",
      "train_loss: 0.184105 | avg_loss: 0.249502 | gender_precise: 89.000000 (14716/16512) [129/186]\n",
      "gender_loss: 0.22141236066818237\n",
      "train_loss: 0.221412 | avg_loss: 0.249286 | gender_precise: 89.000000 (14827/16640) [130/186]\n",
      "gender_loss: 0.2345794290304184\n",
      "train_loss: 0.234579 | avg_loss: 0.249174 | gender_precise: 89.000000 (14943/16768) [131/186]\n",
      "gender_loss: 0.2952660918235779\n",
      "train_loss: 0.295266 | avg_loss: 0.249523 | gender_precise: 89.000000 (15056/16896) [132/186]\n",
      "gender_loss: 0.22483128309249878\n",
      "train_loss: 0.224831 | avg_loss: 0.249338 | gender_precise: 89.000000 (15168/17024) [133/186]\n",
      "gender_loss: 0.21863949298858643\n",
      "train_loss: 0.218639 | avg_loss: 0.249108 | gender_precise: 89.000000 (15284/17152) [134/186]\n",
      "gender_loss: 0.25398728251457214\n",
      "train_loss: 0.253987 | avg_loss: 0.249145 | gender_precise: 89.000000 (15398/17280) [135/186]\n",
      "gender_loss: 0.2837504744529724\n",
      "train_loss: 0.283750 | avg_loss: 0.249399 | gender_precise: 89.000000 (15511/17408) [136/186]\n",
      "gender_loss: 0.34128060936927795\n",
      "train_loss: 0.341281 | avg_loss: 0.250070 | gender_precise: 89.000000 (15613/17536) [137/186]\n",
      "gender_loss: 0.23032128810882568\n",
      "train_loss: 0.230321 | avg_loss: 0.249927 | gender_precise: 89.000000 (15728/17664) [138/186]\n",
      "gender_loss: 0.250354140996933\n",
      "train_loss: 0.250354 | avg_loss: 0.249930 | gender_precise: 89.000000 (15837/17792) [139/186]\n",
      "gender_loss: 0.12910883128643036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.129109 | avg_loss: 0.249067 | gender_precise: 89.000000 (15958/17920) [140/186]\n",
      "gender_loss: 0.25953051447868347\n",
      "train_loss: 0.259531 | avg_loss: 0.249141 | gender_precise: 89.000000 (16072/18048) [141/186]\n",
      "gender_loss: 0.2018292099237442\n",
      "train_loss: 0.201829 | avg_loss: 0.248808 | gender_precise: 89.000000 (16188/18176) [142/186]\n",
      "gender_loss: 0.23034578561782837\n",
      "train_loss: 0.230346 | avg_loss: 0.248679 | gender_precise: 89.000000 (16303/18304) [143/186]\n",
      "gender_loss: 0.2305193841457367\n",
      "train_loss: 0.230519 | avg_loss: 0.248552 | gender_precise: 89.000000 (16414/18432) [144/186]\n",
      "gender_loss: 0.1971980333328247\n",
      "train_loss: 0.197198 | avg_loss: 0.248198 | gender_precise: 89.000000 (16534/18560) [145/186]\n",
      "gender_loss: 0.2137671709060669\n",
      "train_loss: 0.213767 | avg_loss: 0.247962 | gender_precise: 89.000000 (16651/18688) [146/186]\n",
      "gender_loss: 0.21601779758930206\n",
      "train_loss: 0.216018 | avg_loss: 0.247745 | gender_precise: 89.000000 (16766/18816) [147/186]\n",
      "gender_loss: 0.20359687507152557\n",
      "train_loss: 0.203597 | avg_loss: 0.247447 | gender_precise: 89.000000 (16883/18944) [148/186]\n",
      "gender_loss: 0.22911784052848816\n",
      "train_loss: 0.229118 | avg_loss: 0.247324 | gender_precise: 89.000000 (16997/19072) [149/186]\n",
      "gender_loss: 0.21942684054374695\n",
      "train_loss: 0.219427 | avg_loss: 0.247138 | gender_precise: 89.000000 (17111/19200) [150/186]\n",
      "gender_loss: 0.17122989892959595\n",
      "train_loss: 0.171230 | avg_loss: 0.246635 | gender_precise: 89.000000 (17231/19328) [151/186]\n",
      "gender_loss: 0.19995684921741486\n",
      "train_loss: 0.199957 | avg_loss: 0.246328 | gender_precise: 89.000000 (17347/19456) [152/186]\n",
      "gender_loss: 0.19503961503505707\n",
      "train_loss: 0.195040 | avg_loss: 0.245993 | gender_precise: 89.000000 (17465/19584) [153/186]\n",
      "gender_loss: 0.2592816948890686\n",
      "train_loss: 0.259282 | avg_loss: 0.246079 | gender_precise: 89.000000 (17575/19712) [154/186]\n",
      "gender_loss: 0.22750481963157654\n",
      "train_loss: 0.227505 | avg_loss: 0.245959 | gender_precise: 89.000000 (17690/19840) [155/186]\n",
      "gender_loss: 0.33116981387138367\n",
      "train_loss: 0.331170 | avg_loss: 0.246505 | gender_precise: 89.000000 (17800/19968) [156/186]\n",
      "gender_loss: 0.23463913798332214\n",
      "train_loss: 0.234639 | avg_loss: 0.246430 | gender_precise: 89.000000 (17913/20096) [157/186]\n",
      "gender_loss: 0.18548884987831116\n",
      "train_loss: 0.185489 | avg_loss: 0.246044 | gender_precise: 89.000000 (18032/20224) [158/186]\n",
      "gender_loss: 0.27383801341056824\n",
      "train_loss: 0.273838 | avg_loss: 0.246219 | gender_precise: 89.000000 (18146/20352) [159/186]\n",
      "gender_loss: 0.3231123089790344\n",
      "train_loss: 0.323112 | avg_loss: 0.246700 | gender_precise: 89.000000 (18259/20480) [160/186]\n",
      "gender_loss: 0.252428263425827\n",
      "train_loss: 0.252428 | avg_loss: 0.246735 | gender_precise: 89.000000 (18371/20608) [161/186]\n",
      "gender_loss: 0.23459506034851074\n",
      "train_loss: 0.234595 | avg_loss: 0.246660 | gender_precise: 89.000000 (18487/20736) [162/186]\n",
      "gender_loss: 0.24725227057933807\n",
      "train_loss: 0.247252 | avg_loss: 0.246664 | gender_precise: 89.000000 (18603/20864) [163/186]\n",
      "gender_loss: 0.2899913787841797\n",
      "train_loss: 0.289991 | avg_loss: 0.246928 | gender_precise: 89.000000 (18711/20992) [164/186]\n",
      "gender_loss: 0.14856261014938354\n",
      "train_loss: 0.148563 | avg_loss: 0.246332 | gender_precise: 89.000000 (18837/21120) [165/186]\n",
      "gender_loss: 0.2546727955341339\n",
      "train_loss: 0.254673 | avg_loss: 0.246382 | gender_precise: 89.000000 (18950/21248) [166/186]\n",
      "gender_loss: 0.14901001751422882\n",
      "train_loss: 0.149010 | avg_loss: 0.245799 | gender_precise: 89.000000 (19069/21376) [167/186]\n",
      "gender_loss: 0.3049544095993042\n",
      "train_loss: 0.304954 | avg_loss: 0.246151 | gender_precise: 89.000000 (19182/21504) [168/186]\n",
      "gender_loss: 0.2207024246454239\n",
      "train_loss: 0.220702 | avg_loss: 0.246001 | gender_precise: 89.000000 (19297/21632) [169/186]\n",
      "gender_loss: 0.2055331915616989\n",
      "train_loss: 0.205533 | avg_loss: 0.245763 | gender_precise: 89.000000 (19415/21760) [170/186]\n",
      "gender_loss: 0.21948294341564178\n",
      "train_loss: 0.219483 | avg_loss: 0.245609 | gender_precise: 89.000000 (19530/21888) [171/186]\n",
      "gender_loss: 0.3637377917766571\n",
      "train_loss: 0.363738 | avg_loss: 0.246296 | gender_precise: 89.000000 (19635/22016) [172/186]\n",
      "gender_loss: 0.2572939097881317\n",
      "train_loss: 0.257294 | avg_loss: 0.246359 | gender_precise: 89.000000 (19752/22144) [173/186]\n",
      "gender_loss: 0.2718000113964081\n",
      "train_loss: 0.271800 | avg_loss: 0.246505 | gender_precise: 89.000000 (19866/22272) [174/186]\n",
      "gender_loss: 0.18677693605422974\n",
      "train_loss: 0.186777 | avg_loss: 0.246164 | gender_precise: 89.000000 (19982/22400) [175/186]\n",
      "gender_loss: 0.23555120825767517\n",
      "train_loss: 0.235551 | avg_loss: 0.246104 | gender_precise: 89.000000 (20096/22528) [176/186]\n",
      "gender_loss: 0.21278877556324005\n",
      "train_loss: 0.212789 | avg_loss: 0.245916 | gender_precise: 89.000000 (20214/22656) [177/186]\n",
      "gender_loss: 0.20832030475139618\n",
      "train_loss: 0.208320 | avg_loss: 0.245704 | gender_precise: 89.000000 (20330/22784) [178/186]\n",
      "gender_loss: 0.3505360186100006\n",
      "train_loss: 0.350536 | avg_loss: 0.246290 | gender_precise: 89.000000 (20439/22912) [179/186]\n",
      "gender_loss: 0.23130498826503754\n",
      "train_loss: 0.231305 | avg_loss: 0.246207 | gender_precise: 89.000000 (20555/23040) [180/186]\n",
      "gender_loss: 0.23289854824543\n",
      "train_loss: 0.232899 | avg_loss: 0.246133 | gender_precise: 89.000000 (20670/23168) [181/186]\n",
      "gender_loss: 0.2867034375667572\n",
      "train_loss: 0.286703 | avg_loss: 0.246356 | gender_precise: 89.000000 (20778/23296) [182/186]\n",
      "gender_loss: 0.2567611634731293\n",
      "train_loss: 0.256761 | avg_loss: 0.246413 | gender_precise: 89.000000 (20892/23424) [183/186]\n",
      "gender_loss: 0.21635308861732483\n",
      "train_loss: 0.216353 | avg_loss: 0.246250 | gender_precise: 89.000000 (21005/23552) [184/186]\n",
      "gender_loss: 0.17984841763973236\n",
      "train_loss: 0.179848 | avg_loss: 0.245891 | gender_precise: 89.000000 (21121/23680) [185/186]\n",
      "gender_loss: 0.29173117876052856\n",
      "train_loss: 0.291731 | avg_loss: 0.246137 | gender_precise: 89.000000 (21145/23708) [186/186]\n",
      "\n",
      "Test\n",
      "gender_prec: 85.000000 (109/128) [1/2]\n",
      "gender_prec: 85.000000 (115/134) [2/2]\n",
      "Saving..\n",
      "Number epoch: 7\n",
      "gender_loss: 0.17445312440395355\n",
      "train_loss: 0.174453 | avg_loss: 0.174453 | gender_precise: 92.000000 (119/128) [1/186]\n",
      "gender_loss: 0.1788455694913864\n",
      "train_loss: 0.178846 | avg_loss: 0.176649 | gender_precise: 91.000000 (235/256) [2/186]\n",
      "gender_loss: 0.2504097819328308\n",
      "train_loss: 0.250410 | avg_loss: 0.201236 | gender_precise: 91.000000 (352/384) [3/186]\n",
      "gender_loss: 0.22123491764068604\n",
      "train_loss: 0.221235 | avg_loss: 0.206236 | gender_precise: 91.000000 (467/512) [4/186]\n",
      "gender_loss: 0.2503361105918884\n",
      "train_loss: 0.250336 | avg_loss: 0.215056 | gender_precise: 90.000000 (579/640) [5/186]\n",
      "gender_loss: 0.24577419459819794\n",
      "train_loss: 0.245774 | avg_loss: 0.220176 | gender_precise: 90.000000 (694/768) [6/186]\n",
      "gender_loss: 0.31999853253364563\n",
      "train_loss: 0.319999 | avg_loss: 0.234436 | gender_precise: 89.000000 (806/896) [7/186]\n",
      "gender_loss: 0.3033623695373535\n",
      "train_loss: 0.303362 | avg_loss: 0.243052 | gender_precise: 89.000000 (914/1024) [8/186]\n",
      "gender_loss: 0.2025972306728363\n",
      "train_loss: 0.202597 | avg_loss: 0.238557 | gender_precise: 89.000000 (1028/1152) [9/186]\n",
      "gender_loss: 0.3146708309650421\n",
      "train_loss: 0.314671 | avg_loss: 0.246168 | gender_precise: 88.000000 (1135/1280) [10/186]\n",
      "gender_loss: 0.28465431928634644\n",
      "train_loss: 0.284654 | avg_loss: 0.249667 | gender_precise: 88.000000 (1246/1408) [11/186]\n",
      "gender_loss: 0.21614527702331543\n",
      "train_loss: 0.216145 | avg_loss: 0.246874 | gender_precise: 88.000000 (1364/1536) [12/186]\n",
      "gender_loss: 0.24437814950942993\n",
      "train_loss: 0.244378 | avg_loss: 0.246682 | gender_precise: 88.000000 (1479/1664) [13/186]\n",
      "gender_loss: 0.23684775829315186\n",
      "train_loss: 0.236848 | avg_loss: 0.245979 | gender_precise: 88.000000 (1591/1792) [14/186]\n",
      "gender_loss: 0.206193208694458\n",
      "train_loss: 0.206193 | avg_loss: 0.243327 | gender_precise: 88.000000 (1708/1920) [15/186]\n",
      "gender_loss: 0.2728237509727478\n",
      "train_loss: 0.272824 | avg_loss: 0.245170 | gender_precise: 88.000000 (1822/2048) [16/186]\n",
      "gender_loss: 0.18906576931476593\n",
      "train_loss: 0.189066 | avg_loss: 0.241870 | gender_precise: 89.000000 (1941/2176) [17/186]\n",
      "gender_loss: 0.29612797498703003\n",
      "train_loss: 0.296128 | avg_loss: 0.244884 | gender_precise: 89.000000 (2053/2304) [18/186]\n",
      "gender_loss: 0.17477723956108093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.174777 | avg_loss: 0.241195 | gender_precise: 89.000000 (2174/2432) [19/186]\n",
      "gender_loss: 0.2635890543460846\n",
      "train_loss: 0.263589 | avg_loss: 0.242314 | gender_precise: 89.000000 (2288/2560) [20/186]\n",
      "gender_loss: 0.22506996989250183\n",
      "train_loss: 0.225070 | avg_loss: 0.241493 | gender_precise: 89.000000 (2403/2688) [21/186]\n",
      "gender_loss: 0.17380118370056152\n",
      "train_loss: 0.173801 | avg_loss: 0.238416 | gender_precise: 89.000000 (2522/2816) [22/186]\n",
      "gender_loss: 0.20562775433063507\n",
      "train_loss: 0.205628 | avg_loss: 0.236991 | gender_precise: 89.000000 (2642/2944) [23/186]\n",
      "gender_loss: 0.18245644867420197\n",
      "train_loss: 0.182456 | avg_loss: 0.234718 | gender_precise: 89.000000 (2757/3072) [24/186]\n",
      "gender_loss: 0.2809452414512634\n",
      "train_loss: 0.280945 | avg_loss: 0.236567 | gender_precise: 89.000000 (2871/3200) [25/186]\n",
      "gender_loss: 0.2625579237937927\n",
      "train_loss: 0.262558 | avg_loss: 0.237567 | gender_precise: 89.000000 (2985/3328) [26/186]\n",
      "gender_loss: 0.2589667737483978\n",
      "train_loss: 0.258967 | avg_loss: 0.238360 | gender_precise: 89.000000 (3101/3456) [27/186]\n",
      "gender_loss: 0.2516767680644989\n",
      "train_loss: 0.251677 | avg_loss: 0.238835 | gender_precise: 89.000000 (3216/3584) [28/186]\n",
      "gender_loss: 0.206766277551651\n",
      "train_loss: 0.206766 | avg_loss: 0.237729 | gender_precise: 89.000000 (3330/3712) [29/186]\n",
      "gender_loss: 0.2297849953174591\n",
      "train_loss: 0.229785 | avg_loss: 0.237465 | gender_precise: 89.000000 (3441/3840) [30/186]\n",
      "gender_loss: 0.25779494643211365\n",
      "train_loss: 0.257795 | avg_loss: 0.238120 | gender_precise: 89.000000 (3557/3968) [31/186]\n",
      "gender_loss: 0.24491339921951294\n",
      "train_loss: 0.244913 | avg_loss: 0.238333 | gender_precise: 89.000000 (3671/4096) [32/186]\n",
      "gender_loss: 0.3173842132091522\n",
      "train_loss: 0.317384 | avg_loss: 0.240728 | gender_precise: 89.000000 (3781/4224) [33/186]\n",
      "gender_loss: 0.2057431936264038\n",
      "train_loss: 0.205743 | avg_loss: 0.239699 | gender_precise: 89.000000 (3896/4352) [34/186]\n",
      "gender_loss: 0.2999185621738434\n",
      "train_loss: 0.299919 | avg_loss: 0.241420 | gender_precise: 89.000000 (4010/4480) [35/186]\n",
      "gender_loss: 0.3189403712749481\n",
      "train_loss: 0.318940 | avg_loss: 0.243573 | gender_precise: 89.000000 (4120/4608) [36/186]\n",
      "gender_loss: 0.21432489156723022\n",
      "train_loss: 0.214325 | avg_loss: 0.242783 | gender_precise: 89.000000 (4238/4736) [37/186]\n",
      "gender_loss: 0.3187285363674164\n",
      "train_loss: 0.318729 | avg_loss: 0.244781 | gender_precise: 89.000000 (4350/4864) [38/186]\n",
      "gender_loss: 0.2787160575389862\n",
      "train_loss: 0.278716 | avg_loss: 0.245651 | gender_precise: 89.000000 (4462/4992) [39/186]\n",
      "gender_loss: 0.19880618155002594\n",
      "train_loss: 0.198806 | avg_loss: 0.244480 | gender_precise: 89.000000 (4578/5120) [40/186]\n",
      "gender_loss: 0.24057133495807648\n",
      "train_loss: 0.240571 | avg_loss: 0.244385 | gender_precise: 89.000000 (4690/5248) [41/186]\n",
      "gender_loss: 0.2348875254392624\n",
      "train_loss: 0.234888 | avg_loss: 0.244159 | gender_precise: 89.000000 (4805/5376) [42/186]\n",
      "gender_loss: 0.2437143623828888\n",
      "train_loss: 0.243714 | avg_loss: 0.244148 | gender_precise: 89.000000 (4918/5504) [43/186]\n",
      "gender_loss: 0.22833311557769775\n",
      "train_loss: 0.228333 | avg_loss: 0.243789 | gender_precise: 89.000000 (5032/5632) [44/186]\n",
      "gender_loss: 0.2055400162935257\n",
      "train_loss: 0.205540 | avg_loss: 0.242939 | gender_precise: 89.000000 (5149/5760) [45/186]\n",
      "gender_loss: 0.24952532351016998\n",
      "train_loss: 0.249525 | avg_loss: 0.243082 | gender_precise: 89.000000 (5260/5888) [46/186]\n",
      "gender_loss: 0.19370651245117188\n",
      "train_loss: 0.193707 | avg_loss: 0.242032 | gender_precise: 89.000000 (5376/6016) [47/186]\n",
      "gender_loss: 0.16627883911132812\n",
      "train_loss: 0.166279 | avg_loss: 0.240453 | gender_precise: 89.000000 (5495/6144) [48/186]\n",
      "gender_loss: 0.2849884033203125\n",
      "train_loss: 0.284988 | avg_loss: 0.241362 | gender_precise: 89.000000 (5607/6272) [49/186]\n",
      "gender_loss: 0.2166440337896347\n",
      "train_loss: 0.216644 | avg_loss: 0.240868 | gender_precise: 89.000000 (5723/6400) [50/186]\n",
      "gender_loss: 0.29091790318489075\n",
      "train_loss: 0.290918 | avg_loss: 0.241849 | gender_precise: 89.000000 (5834/6528) [51/186]\n",
      "gender_loss: 0.21622692048549652\n",
      "train_loss: 0.216227 | avg_loss: 0.241357 | gender_precise: 89.000000 (5949/6656) [52/186]\n",
      "gender_loss: 0.15712469816207886\n",
      "train_loss: 0.157125 | avg_loss: 0.239767 | gender_precise: 89.000000 (6067/6784) [53/186]\n",
      "gender_loss: 0.2685375511646271\n",
      "train_loss: 0.268538 | avg_loss: 0.240300 | gender_precise: 89.000000 (6175/6912) [54/186]\n",
      "gender_loss: 0.17771278321743011\n",
      "train_loss: 0.177713 | avg_loss: 0.239162 | gender_precise: 89.000000 (6291/7040) [55/186]\n",
      "gender_loss: 0.19104143977165222\n",
      "train_loss: 0.191041 | avg_loss: 0.238303 | gender_precise: 89.000000 (6413/7168) [56/186]\n",
      "gender_loss: 0.2524285316467285\n",
      "train_loss: 0.252429 | avg_loss: 0.238551 | gender_precise: 89.000000 (6526/7296) [57/186]\n",
      "gender_loss: 0.24000611901283264\n",
      "train_loss: 0.240006 | avg_loss: 0.238576 | gender_precise: 89.000000 (6636/7424) [58/186]\n",
      "gender_loss: 0.1878814846277237\n",
      "train_loss: 0.187881 | avg_loss: 0.237716 | gender_precise: 89.000000 (6754/7552) [59/186]\n",
      "gender_loss: 0.14523999392986298\n",
      "train_loss: 0.145240 | avg_loss: 0.236175 | gender_precise: 89.000000 (6876/7680) [60/186]\n",
      "gender_loss: 0.28911906480789185\n",
      "train_loss: 0.289119 | avg_loss: 0.237043 | gender_precise: 89.000000 (6987/7808) [61/186]\n",
      "gender_loss: 0.2644440829753876\n",
      "train_loss: 0.264444 | avg_loss: 0.237485 | gender_precise: 89.000000 (7104/7936) [62/186]\n",
      "gender_loss: 0.21659864485263824\n",
      "train_loss: 0.216599 | avg_loss: 0.237154 | gender_precise: 89.000000 (7220/8064) [63/186]\n",
      "gender_loss: 0.23077507317066193\n",
      "train_loss: 0.230775 | avg_loss: 0.237054 | gender_precise: 89.000000 (7332/8192) [64/186]\n",
      "gender_loss: 0.2305963784456253\n",
      "train_loss: 0.230596 | avg_loss: 0.236955 | gender_precise: 89.000000 (7447/8320) [65/186]\n",
      "gender_loss: 0.21960322558879852\n",
      "train_loss: 0.219603 | avg_loss: 0.236692 | gender_precise: 89.000000 (7568/8448) [66/186]\n",
      "gender_loss: 0.23307430744171143\n",
      "train_loss: 0.233074 | avg_loss: 0.236638 | gender_precise: 89.000000 (7685/8576) [67/186]\n",
      "gender_loss: 0.17331044375896454\n",
      "train_loss: 0.173310 | avg_loss: 0.235706 | gender_precise: 89.000000 (7803/8704) [68/186]\n",
      "gender_loss: 0.1736859679222107\n",
      "train_loss: 0.173686 | avg_loss: 0.234808 | gender_precise: 89.000000 (7923/8832) [69/186]\n",
      "gender_loss: 0.27054446935653687\n",
      "train_loss: 0.270544 | avg_loss: 0.235318 | gender_precise: 89.000000 (8036/8960) [70/186]\n",
      "gender_loss: 0.24596431851387024\n",
      "train_loss: 0.245964 | avg_loss: 0.235468 | gender_precise: 89.000000 (8149/9088) [71/186]\n",
      "gender_loss: 0.20365479588508606\n",
      "train_loss: 0.203655 | avg_loss: 0.235026 | gender_precise: 89.000000 (8266/9216) [72/186]\n",
      "gender_loss: 0.2547435164451599\n",
      "train_loss: 0.254744 | avg_loss: 0.235296 | gender_precise: 89.000000 (8382/9344) [73/186]\n",
      "gender_loss: 0.3375788629055023\n",
      "train_loss: 0.337579 | avg_loss: 0.236678 | gender_precise: 89.000000 (8492/9472) [74/186]\n",
      "gender_loss: 0.20116552710533142\n",
      "train_loss: 0.201166 | avg_loss: 0.236205 | gender_precise: 89.000000 (8608/9600) [75/186]\n",
      "gender_loss: 0.1995607167482376\n",
      "train_loss: 0.199561 | avg_loss: 0.235723 | gender_precise: 89.000000 (8724/9728) [76/186]\n",
      "gender_loss: 0.25746867060661316\n",
      "train_loss: 0.257469 | avg_loss: 0.236005 | gender_precise: 89.000000 (8835/9856) [77/186]\n",
      "gender_loss: 0.3056744933128357\n",
      "train_loss: 0.305674 | avg_loss: 0.236898 | gender_precise: 89.000000 (8943/9984) [78/186]\n",
      "gender_loss: 0.26836615800857544\n",
      "train_loss: 0.268366 | avg_loss: 0.237297 | gender_precise: 89.000000 (9056/10112) [79/186]\n",
      "gender_loss: 0.17081975936889648\n",
      "train_loss: 0.170820 | avg_loss: 0.236466 | gender_precise: 89.000000 (9174/10240) [80/186]\n",
      "gender_loss: 0.25686115026474\n",
      "train_loss: 0.256861 | avg_loss: 0.236718 | gender_precise: 89.000000 (9288/10368) [81/186]\n",
      "gender_loss: 0.23674827814102173\n",
      "train_loss: 0.236748 | avg_loss: 0.236718 | gender_precise: 89.000000 (9403/10496) [82/186]\n",
      "gender_loss: 0.21989285945892334\n",
      "train_loss: 0.219893 | avg_loss: 0.236515 | gender_precise: 89.000000 (9519/10624) [83/186]\n",
      "gender_loss: 0.2020157426595688\n",
      "train_loss: 0.202016 | avg_loss: 0.236104 | gender_precise: 89.000000 (9637/10752) [84/186]\n",
      "gender_loss: 0.23421300947666168\n",
      "train_loss: 0.234213 | avg_loss: 0.236082 | gender_precise: 89.000000 (9757/10880) [85/186]\n",
      "gender_loss: 0.27216997742652893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.272170 | avg_loss: 0.236502 | gender_precise: 89.000000 (9869/11008) [86/186]\n",
      "gender_loss: 0.20990726351737976\n",
      "train_loss: 0.209907 | avg_loss: 0.236196 | gender_precise: 89.000000 (9984/11136) [87/186]\n",
      "gender_loss: 0.15229357779026031\n",
      "train_loss: 0.152294 | avg_loss: 0.235243 | gender_precise: 89.000000 (10106/11264) [88/186]\n",
      "gender_loss: 0.15265733003616333\n",
      "train_loss: 0.152657 | avg_loss: 0.234315 | gender_precise: 89.000000 (10223/11392) [89/186]\n",
      "gender_loss: 0.09379303455352783\n",
      "train_loss: 0.093793 | avg_loss: 0.232753 | gender_precise: 89.000000 (10346/11520) [90/186]\n",
      "gender_loss: 0.3141777217388153\n",
      "train_loss: 0.314178 | avg_loss: 0.233648 | gender_precise: 89.000000 (10456/11648) [91/186]\n",
      "gender_loss: 0.19466377794742584\n",
      "train_loss: 0.194664 | avg_loss: 0.233224 | gender_precise: 89.000000 (10572/11776) [92/186]\n",
      "gender_loss: 0.19589197635650635\n",
      "train_loss: 0.195892 | avg_loss: 0.232823 | gender_precise: 89.000000 (10690/11904) [93/186]\n",
      "gender_loss: 0.24761676788330078\n",
      "train_loss: 0.247617 | avg_loss: 0.232980 | gender_precise: 89.000000 (10802/12032) [94/186]\n",
      "gender_loss: 0.1704881638288498\n",
      "train_loss: 0.170488 | avg_loss: 0.232323 | gender_precise: 89.000000 (10921/12160) [95/186]\n",
      "gender_loss: 0.20103135704994202\n",
      "train_loss: 0.201031 | avg_loss: 0.231997 | gender_precise: 89.000000 (11041/12288) [96/186]\n",
      "gender_loss: 0.17995816469192505\n",
      "train_loss: 0.179958 | avg_loss: 0.231460 | gender_precise: 89.000000 (11156/12416) [97/186]\n",
      "gender_loss: 0.21293029189109802\n",
      "train_loss: 0.212930 | avg_loss: 0.231271 | gender_precise: 89.000000 (11274/12544) [98/186]\n",
      "gender_loss: 0.21277275681495667\n",
      "train_loss: 0.212773 | avg_loss: 0.231084 | gender_precise: 89.000000 (11387/12672) [99/186]\n",
      "gender_loss: 0.15635034441947937\n",
      "train_loss: 0.156350 | avg_loss: 0.230337 | gender_precise: 89.000000 (11507/12800) [100/186]\n",
      "gender_loss: 0.2567194402217865\n",
      "train_loss: 0.256719 | avg_loss: 0.230598 | gender_precise: 89.000000 (11621/12928) [101/186]\n",
      "gender_loss: 0.21078361570835114\n",
      "train_loss: 0.210784 | avg_loss: 0.230404 | gender_precise: 89.000000 (11735/13056) [102/186]\n",
      "gender_loss: 0.19884778559207916\n",
      "train_loss: 0.198848 | avg_loss: 0.230098 | gender_precise: 89.000000 (11852/13184) [103/186]\n",
      "gender_loss: 0.15939456224441528\n",
      "train_loss: 0.159395 | avg_loss: 0.229418 | gender_precise: 89.000000 (11972/13312) [104/186]\n",
      "gender_loss: 0.2639685273170471\n",
      "train_loss: 0.263969 | avg_loss: 0.229747 | gender_precise: 89.000000 (12089/13440) [105/186]\n",
      "gender_loss: 0.23047716915607452\n",
      "train_loss: 0.230477 | avg_loss: 0.229754 | gender_precise: 89.000000 (12203/13568) [106/186]\n",
      "gender_loss: 0.26944786310195923\n",
      "train_loss: 0.269448 | avg_loss: 0.230125 | gender_precise: 89.000000 (12316/13696) [107/186]\n",
      "gender_loss: 0.3323046565055847\n",
      "train_loss: 0.332305 | avg_loss: 0.231071 | gender_precise: 89.000000 (12429/13824) [108/186]\n",
      "gender_loss: 0.23904310166835785\n",
      "train_loss: 0.239043 | avg_loss: 0.231144 | gender_precise: 89.000000 (12544/13952) [109/186]\n",
      "gender_loss: 0.2896060645580292\n",
      "train_loss: 0.289606 | avg_loss: 0.231675 | gender_precise: 89.000000 (12656/14080) [110/186]\n",
      "gender_loss: 0.2905430495738983\n",
      "train_loss: 0.290543 | avg_loss: 0.232206 | gender_precise: 89.000000 (12770/14208) [111/186]\n",
      "gender_loss: 0.19776581227779388\n",
      "train_loss: 0.197766 | avg_loss: 0.231898 | gender_precise: 89.000000 (12890/14336) [112/186]\n",
      "gender_loss: 0.18517416715621948\n",
      "train_loss: 0.185174 | avg_loss: 0.231485 | gender_precise: 89.000000 (13010/14464) [113/186]\n",
      "gender_loss: 0.24101589620113373\n",
      "train_loss: 0.241016 | avg_loss: 0.231568 | gender_precise: 89.000000 (13126/14592) [114/186]\n",
      "gender_loss: 0.26234158873558044\n",
      "train_loss: 0.262342 | avg_loss: 0.231836 | gender_precise: 89.000000 (13238/14720) [115/186]\n",
      "gender_loss: 0.13922126591205597\n",
      "train_loss: 0.139221 | avg_loss: 0.231037 | gender_precise: 89.000000 (13361/14848) [116/186]\n",
      "gender_loss: 0.23733480274677277\n",
      "train_loss: 0.237335 | avg_loss: 0.231091 | gender_precise: 89.000000 (13477/14976) [117/186]\n",
      "gender_loss: 0.24846529960632324\n",
      "train_loss: 0.248465 | avg_loss: 0.231239 | gender_precise: 89.000000 (13589/15104) [118/186]\n",
      "gender_loss: 0.2267066389322281\n",
      "train_loss: 0.226707 | avg_loss: 0.231200 | gender_precise: 89.000000 (13700/15232) [119/186]\n",
      "gender_loss: 0.16795936226844788\n",
      "train_loss: 0.167959 | avg_loss: 0.230673 | gender_precise: 89.000000 (13818/15360) [120/186]\n",
      "gender_loss: 0.208692729473114\n",
      "train_loss: 0.208693 | avg_loss: 0.230492 | gender_precise: 89.000000 (13935/15488) [121/186]\n",
      "gender_loss: 0.2574598491191864\n",
      "train_loss: 0.257460 | avg_loss: 0.230713 | gender_precise: 89.000000 (14047/15616) [122/186]\n",
      "gender_loss: 0.23199410736560822\n",
      "train_loss: 0.231994 | avg_loss: 0.230723 | gender_precise: 89.000000 (14160/15744) [123/186]\n",
      "gender_loss: 0.15216489136219025\n",
      "train_loss: 0.152165 | avg_loss: 0.230090 | gender_precise: 89.000000 (14279/15872) [124/186]\n",
      "gender_loss: 0.2782885432243347\n",
      "train_loss: 0.278289 | avg_loss: 0.230475 | gender_precise: 89.000000 (14391/16000) [125/186]\n",
      "gender_loss: 0.20193472504615784\n",
      "train_loss: 0.201935 | avg_loss: 0.230249 | gender_precise: 89.000000 (14506/16128) [126/186]\n",
      "gender_loss: 0.21281780302524567\n",
      "train_loss: 0.212818 | avg_loss: 0.230112 | gender_precise: 89.000000 (14624/16256) [127/186]\n",
      "gender_loss: 0.21225965023040771\n",
      "train_loss: 0.212260 | avg_loss: 0.229972 | gender_precise: 89.000000 (14742/16384) [128/186]\n",
      "gender_loss: 0.2419343888759613\n",
      "train_loss: 0.241934 | avg_loss: 0.230065 | gender_precise: 89.000000 (14858/16512) [129/186]\n",
      "gender_loss: 0.19578099250793457\n",
      "train_loss: 0.195781 | avg_loss: 0.229801 | gender_precise: 90.000000 (14979/16640) [130/186]\n",
      "gender_loss: 0.2757800817489624\n",
      "train_loss: 0.275780 | avg_loss: 0.230152 | gender_precise: 89.000000 (15091/16768) [131/186]\n",
      "gender_loss: 0.16838563978672028\n",
      "train_loss: 0.168386 | avg_loss: 0.229684 | gender_precise: 90.000000 (15211/16896) [132/186]\n",
      "gender_loss: 0.28391140699386597\n",
      "train_loss: 0.283911 | avg_loss: 0.230092 | gender_precise: 89.000000 (15319/17024) [133/186]\n",
      "gender_loss: 0.2213272750377655\n",
      "train_loss: 0.221327 | avg_loss: 0.230026 | gender_precise: 89.000000 (15434/17152) [134/186]\n",
      "gender_loss: 0.29971736669540405\n",
      "train_loss: 0.299717 | avg_loss: 0.230543 | gender_precise: 89.000000 (15543/17280) [135/186]\n",
      "gender_loss: 0.19843842089176178\n",
      "train_loss: 0.198438 | avg_loss: 0.230307 | gender_precise: 89.000000 (15663/17408) [136/186]\n",
      "gender_loss: 0.2102801650762558\n",
      "train_loss: 0.210280 | avg_loss: 0.230160 | gender_precise: 89.000000 (15777/17536) [137/186]\n",
      "gender_loss: 0.2312464565038681\n",
      "train_loss: 0.231246 | avg_loss: 0.230168 | gender_precise: 89.000000 (15893/17664) [138/186]\n",
      "gender_loss: 0.22399091720581055\n",
      "train_loss: 0.223991 | avg_loss: 0.230124 | gender_precise: 89.000000 (16010/17792) [139/186]\n",
      "gender_loss: 0.22296686470508575\n",
      "train_loss: 0.222967 | avg_loss: 0.230073 | gender_precise: 90.000000 (16130/17920) [140/186]\n",
      "gender_loss: 0.3775508403778076\n",
      "train_loss: 0.377551 | avg_loss: 0.231119 | gender_precise: 89.000000 (16241/18048) [141/186]\n",
      "gender_loss: 0.17872081696987152\n",
      "train_loss: 0.178721 | avg_loss: 0.230750 | gender_precise: 89.000000 (16358/18176) [142/186]\n",
      "gender_loss: 0.1799471378326416\n",
      "train_loss: 0.179947 | avg_loss: 0.230394 | gender_precise: 90.000000 (16475/18304) [143/186]\n",
      "gender_loss: 0.29203513264656067\n",
      "train_loss: 0.292035 | avg_loss: 0.230823 | gender_precise: 89.000000 (16586/18432) [144/186]\n",
      "gender_loss: 0.19403906166553497\n",
      "train_loss: 0.194039 | avg_loss: 0.230569 | gender_precise: 89.000000 (16700/18560) [145/186]\n",
      "gender_loss: 0.2505791485309601\n",
      "train_loss: 0.250579 | avg_loss: 0.230706 | gender_precise: 89.000000 (16812/18688) [146/186]\n",
      "gender_loss: 0.2967618703842163\n",
      "train_loss: 0.296762 | avg_loss: 0.231155 | gender_precise: 89.000000 (16921/18816) [147/186]\n",
      "gender_loss: 0.2051684409379959\n",
      "train_loss: 0.205168 | avg_loss: 0.230980 | gender_precise: 89.000000 (17040/18944) [148/186]\n",
      "gender_loss: 0.15702319145202637\n",
      "train_loss: 0.157023 | avg_loss: 0.230483 | gender_precise: 89.000000 (17159/19072) [149/186]\n",
      "gender_loss: 0.2469182163476944\n",
      "train_loss: 0.246918 | avg_loss: 0.230593 | gender_precise: 89.000000 (17277/19200) [150/186]\n",
      "gender_loss: 0.2166881561279297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.216688 | avg_loss: 0.230501 | gender_precise: 89.000000 (17392/19328) [151/186]\n",
      "gender_loss: 0.23247294127941132\n",
      "train_loss: 0.232473 | avg_loss: 0.230514 | gender_precise: 89.000000 (17506/19456) [152/186]\n",
      "gender_loss: 0.18652494251728058\n",
      "train_loss: 0.186525 | avg_loss: 0.230226 | gender_precise: 89.000000 (17625/19584) [153/186]\n",
      "gender_loss: 0.19300997257232666\n",
      "train_loss: 0.193010 | avg_loss: 0.229985 | gender_precise: 89.000000 (17740/19712) [154/186]\n",
      "gender_loss: 0.24178621172904968\n",
      "train_loss: 0.241786 | avg_loss: 0.230061 | gender_precise: 90.000000 (17856/19840) [155/186]\n",
      "gender_loss: 0.15296149253845215\n",
      "train_loss: 0.152961 | avg_loss: 0.229566 | gender_precise: 90.000000 (17975/19968) [156/186]\n",
      "gender_loss: 0.22947129607200623\n",
      "train_loss: 0.229471 | avg_loss: 0.229566 | gender_precise: 90.000000 (18092/20096) [157/186]\n",
      "gender_loss: 0.24041748046875\n",
      "train_loss: 0.240417 | avg_loss: 0.229635 | gender_precise: 90.000000 (18205/20224) [158/186]\n",
      "gender_loss: 0.24890053272247314\n",
      "train_loss: 0.248901 | avg_loss: 0.229756 | gender_precise: 90.000000 (18318/20352) [159/186]\n",
      "gender_loss: 0.2142694890499115\n",
      "train_loss: 0.214269 | avg_loss: 0.229659 | gender_precise: 90.000000 (18435/20480) [160/186]\n",
      "gender_loss: 0.2692146599292755\n",
      "train_loss: 0.269215 | avg_loss: 0.229905 | gender_precise: 89.000000 (18547/20608) [161/186]\n",
      "gender_loss: 0.22105923295021057\n",
      "train_loss: 0.221059 | avg_loss: 0.229850 | gender_precise: 89.000000 (18662/20736) [162/186]\n",
      "gender_loss: 0.23068547248840332\n",
      "train_loss: 0.230685 | avg_loss: 0.229855 | gender_precise: 89.000000 (18774/20864) [163/186]\n",
      "gender_loss: 0.3039001226425171\n",
      "train_loss: 0.303900 | avg_loss: 0.230307 | gender_precise: 89.000000 (18882/20992) [164/186]\n",
      "gender_loss: 0.2537023425102234\n",
      "train_loss: 0.253702 | avg_loss: 0.230448 | gender_precise: 89.000000 (18999/21120) [165/186]\n",
      "gender_loss: 0.30036333203315735\n",
      "train_loss: 0.300363 | avg_loss: 0.230870 | gender_precise: 89.000000 (19113/21248) [166/186]\n",
      "gender_loss: 0.30613166093826294\n",
      "train_loss: 0.306132 | avg_loss: 0.231320 | gender_precise: 89.000000 (19226/21376) [167/186]\n",
      "gender_loss: 0.26837053894996643\n",
      "train_loss: 0.268371 | avg_loss: 0.231541 | gender_precise: 89.000000 (19343/21504) [168/186]\n",
      "gender_loss: 0.21809203922748566\n",
      "train_loss: 0.218092 | avg_loss: 0.231461 | gender_precise: 89.000000 (19460/21632) [169/186]\n",
      "gender_loss: 0.24216961860656738\n",
      "train_loss: 0.242170 | avg_loss: 0.231524 | gender_precise: 89.000000 (19569/21760) [170/186]\n",
      "gender_loss: 0.32342222332954407\n",
      "train_loss: 0.323422 | avg_loss: 0.232062 | gender_precise: 89.000000 (19680/21888) [171/186]\n",
      "gender_loss: 0.24836894869804382\n",
      "train_loss: 0.248369 | avg_loss: 0.232156 | gender_precise: 89.000000 (19798/22016) [172/186]\n",
      "gender_loss: 0.19097447395324707\n",
      "train_loss: 0.190974 | avg_loss: 0.231918 | gender_precise: 89.000000 (19918/22144) [173/186]\n",
      "gender_loss: 0.242563396692276\n",
      "train_loss: 0.242563 | avg_loss: 0.231980 | gender_precise: 89.000000 (20030/22272) [174/186]\n",
      "gender_loss: 0.2523851990699768\n",
      "train_loss: 0.252385 | avg_loss: 0.232096 | gender_precise: 89.000000 (20146/22400) [175/186]\n",
      "gender_loss: 0.17399457097053528\n",
      "train_loss: 0.173995 | avg_loss: 0.231766 | gender_precise: 89.000000 (20263/22528) [176/186]\n",
      "gender_loss: 0.20666344463825226\n",
      "train_loss: 0.206663 | avg_loss: 0.231624 | gender_precise: 89.000000 (20380/22656) [177/186]\n",
      "gender_loss: 0.208099827170372\n",
      "train_loss: 0.208100 | avg_loss: 0.231492 | gender_precise: 89.000000 (20496/22784) [178/186]\n",
      "gender_loss: 0.19634319841861725\n",
      "train_loss: 0.196343 | avg_loss: 0.231296 | gender_precise: 89.000000 (20613/22912) [179/186]\n",
      "gender_loss: 0.22856664657592773\n",
      "train_loss: 0.228567 | avg_loss: 0.231281 | gender_precise: 89.000000 (20728/23040) [180/186]\n",
      "gender_loss: 0.27737635374069214\n",
      "train_loss: 0.277376 | avg_loss: 0.231535 | gender_precise: 89.000000 (20839/23168) [181/186]\n",
      "gender_loss: 0.2306494563817978\n",
      "train_loss: 0.230649 | avg_loss: 0.231530 | gender_precise: 89.000000 (20956/23296) [182/186]\n",
      "gender_loss: 0.20112186670303345\n",
      "train_loss: 0.201122 | avg_loss: 0.231364 | gender_precise: 89.000000 (21072/23424) [183/186]\n",
      "gender_loss: 0.2583889663219452\n",
      "train_loss: 0.258389 | avg_loss: 0.231511 | gender_precise: 89.000000 (21187/23552) [184/186]\n",
      "gender_loss: 0.25488966703414917\n",
      "train_loss: 0.254890 | avg_loss: 0.231637 | gender_precise: 89.000000 (21300/23680) [185/186]\n",
      "gender_loss: 0.1489032804965973\n",
      "train_loss: 0.148903 | avg_loss: 0.231193 | gender_precise: 89.000000 (21326/23708) [186/186]\n",
      "\n",
      "Test\n",
      "gender_prec: 81.000000 (104/128) [1/2]\n",
      "gender_prec: 81.000000 (109/134) [2/2]\n",
      "Number epoch: 8\n",
      "gender_loss: 0.22104105353355408\n",
      "train_loss: 0.221041 | avg_loss: 0.221041 | gender_precise: 87.000000 (112/128) [1/186]\n",
      "gender_loss: 0.2228057086467743\n",
      "train_loss: 0.222806 | avg_loss: 0.221923 | gender_precise: 89.000000 (228/256) [2/186]\n",
      "gender_loss: 0.11366906017065048\n",
      "train_loss: 0.113669 | avg_loss: 0.185839 | gender_precise: 91.000000 (351/384) [3/186]\n",
      "gender_loss: 0.25465577840805054\n",
      "train_loss: 0.254656 | avg_loss: 0.203043 | gender_precise: 90.000000 (465/512) [4/186]\n",
      "gender_loss: 0.19214579463005066\n",
      "train_loss: 0.192146 | avg_loss: 0.200863 | gender_precise: 91.000000 (585/640) [5/186]\n",
      "gender_loss: 0.16780410706996918\n",
      "train_loss: 0.167804 | avg_loss: 0.195354 | gender_precise: 92.000000 (707/768) [6/186]\n",
      "gender_loss: 0.20477277040481567\n",
      "train_loss: 0.204773 | avg_loss: 0.196699 | gender_precise: 92.000000 (826/896) [7/186]\n",
      "gender_loss: 0.26960793137550354\n",
      "train_loss: 0.269608 | avg_loss: 0.205813 | gender_precise: 91.000000 (940/1024) [8/186]\n",
      "gender_loss: 0.2088412344455719\n",
      "train_loss: 0.208841 | avg_loss: 0.206149 | gender_precise: 91.000000 (1057/1152) [9/186]\n",
      "gender_loss: 0.2139347344636917\n",
      "train_loss: 0.213935 | avg_loss: 0.206928 | gender_precise: 91.000000 (1172/1280) [10/186]\n",
      "gender_loss: 0.1977011114358902\n",
      "train_loss: 0.197701 | avg_loss: 0.206089 | gender_precise: 91.000000 (1289/1408) [11/186]\n",
      "gender_loss: 0.2632089853286743\n",
      "train_loss: 0.263209 | avg_loss: 0.210849 | gender_precise: 91.000000 (1407/1536) [12/186]\n",
      "gender_loss: 0.22526301443576813\n",
      "train_loss: 0.225263 | avg_loss: 0.211958 | gender_precise: 91.000000 (1524/1664) [13/186]\n",
      "gender_loss: 0.21599824726581573\n",
      "train_loss: 0.215998 | avg_loss: 0.212246 | gender_precise: 91.000000 (1640/1792) [14/186]\n",
      "gender_loss: 0.26222237944602966\n",
      "train_loss: 0.262222 | avg_loss: 0.215578 | gender_precise: 91.000000 (1756/1920) [15/186]\n",
      "gender_loss: 0.35545453429222107\n",
      "train_loss: 0.355455 | avg_loss: 0.224320 | gender_precise: 91.000000 (1865/2048) [16/186]\n",
      "gender_loss: 0.3291621208190918\n",
      "train_loss: 0.329162 | avg_loss: 0.230488 | gender_precise: 90.000000 (1971/2176) [17/186]\n",
      "gender_loss: 0.19112971425056458\n",
      "train_loss: 0.191130 | avg_loss: 0.228301 | gender_precise: 90.000000 (2089/2304) [18/186]\n",
      "gender_loss: 0.17490452527999878\n",
      "train_loss: 0.174905 | avg_loss: 0.225491 | gender_precise: 90.000000 (2206/2432) [19/186]\n",
      "gender_loss: 0.24822485446929932\n",
      "train_loss: 0.248225 | avg_loss: 0.226627 | gender_precise: 90.000000 (2319/2560) [20/186]\n",
      "gender_loss: 0.27792662382125854\n",
      "train_loss: 0.277927 | avg_loss: 0.229070 | gender_precise: 90.000000 (2435/2688) [21/186]\n",
      "gender_loss: 0.29929566383361816\n",
      "train_loss: 0.299296 | avg_loss: 0.232262 | gender_precise: 90.000000 (2542/2816) [22/186]\n",
      "gender_loss: 0.19801123440265656\n",
      "train_loss: 0.198011 | avg_loss: 0.230773 | gender_precise: 90.000000 (2660/2944) [23/186]\n",
      "gender_loss: 0.1843479424715042\n",
      "train_loss: 0.184348 | avg_loss: 0.228839 | gender_precise: 90.000000 (2779/3072) [24/186]\n",
      "gender_loss: 0.15143410861492157\n",
      "train_loss: 0.151434 | avg_loss: 0.225742 | gender_precise: 90.000000 (2900/3200) [25/186]\n",
      "gender_loss: 0.23275226354599\n",
      "train_loss: 0.232752 | avg_loss: 0.226012 | gender_precise: 90.000000 (3014/3328) [26/186]\n",
      "gender_loss: 0.1788010150194168\n",
      "train_loss: 0.178801 | avg_loss: 0.224264 | gender_precise: 90.000000 (3133/3456) [27/186]\n",
      "gender_loss: 0.29051992297172546\n",
      "train_loss: 0.290520 | avg_loss: 0.226630 | gender_precise: 90.000000 (3246/3584) [28/186]\n",
      "gender_loss: 0.18788014352321625\n",
      "train_loss: 0.187880 | avg_loss: 0.225294 | gender_precise: 90.000000 (3367/3712) [29/186]\n",
      "gender_loss: 0.23414243757724762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.234142 | avg_loss: 0.225589 | gender_precise: 90.000000 (3484/3840) [30/186]\n",
      "gender_loss: 0.19985570013523102\n",
      "train_loss: 0.199856 | avg_loss: 0.224758 | gender_precise: 90.000000 (3600/3968) [31/186]\n",
      "gender_loss: 0.231576070189476\n",
      "train_loss: 0.231576 | avg_loss: 0.224972 | gender_precise: 90.000000 (3716/4096) [32/186]\n",
      "gender_loss: 0.1827651560306549\n",
      "train_loss: 0.182765 | avg_loss: 0.223693 | gender_precise: 90.000000 (3834/4224) [33/186]\n",
      "gender_loss: 0.32010897994041443\n",
      "train_loss: 0.320109 | avg_loss: 0.226528 | gender_precise: 90.000000 (3948/4352) [34/186]\n",
      "gender_loss: 0.1552044302225113\n",
      "train_loss: 0.155204 | avg_loss: 0.224491 | gender_precise: 90.000000 (4065/4480) [35/186]\n",
      "gender_loss: 0.23164741694927216\n",
      "train_loss: 0.231647 | avg_loss: 0.224689 | gender_precise: 90.000000 (4180/4608) [36/186]\n",
      "gender_loss: 0.22630147635936737\n",
      "train_loss: 0.226301 | avg_loss: 0.224733 | gender_precise: 90.000000 (4293/4736) [37/186]\n",
      "gender_loss: 0.2564074397087097\n",
      "train_loss: 0.256407 | avg_loss: 0.225566 | gender_precise: 90.000000 (4408/4864) [38/186]\n",
      "gender_loss: 0.20674030482769012\n",
      "train_loss: 0.206740 | avg_loss: 0.225084 | gender_precise: 90.000000 (4522/4992) [39/186]\n",
      "gender_loss: 0.17430466413497925\n",
      "train_loss: 0.174305 | avg_loss: 0.223814 | gender_precise: 90.000000 (4641/5120) [40/186]\n",
      "gender_loss: 0.17595697939395905\n",
      "train_loss: 0.175957 | avg_loss: 0.222647 | gender_precise: 90.000000 (4760/5248) [41/186]\n",
      "gender_loss: 0.1371791958808899\n",
      "train_loss: 0.137179 | avg_loss: 0.220612 | gender_precise: 90.000000 (4882/5376) [42/186]\n",
      "gender_loss: 0.2027192860841751\n",
      "train_loss: 0.202719 | avg_loss: 0.220196 | gender_precise: 90.000000 (4998/5504) [43/186]\n",
      "gender_loss: 0.3127000331878662\n",
      "train_loss: 0.312700 | avg_loss: 0.222298 | gender_precise: 90.000000 (5111/5632) [44/186]\n",
      "gender_loss: 0.2630539536476135\n",
      "train_loss: 0.263054 | avg_loss: 0.223204 | gender_precise: 90.000000 (5225/5760) [45/186]\n",
      "gender_loss: 0.17548871040344238\n",
      "train_loss: 0.175489 | avg_loss: 0.222167 | gender_precise: 90.000000 (5344/5888) [46/186]\n",
      "gender_loss: 0.1561536341905594\n",
      "train_loss: 0.156154 | avg_loss: 0.220762 | gender_precise: 90.000000 (5464/6016) [47/186]\n",
      "gender_loss: 0.1915886104106903\n",
      "train_loss: 0.191589 | avg_loss: 0.220154 | gender_precise: 90.000000 (5582/6144) [48/186]\n",
      "gender_loss: 0.25297024846076965\n",
      "train_loss: 0.252970 | avg_loss: 0.220824 | gender_precise: 90.000000 (5695/6272) [49/186]\n",
      "gender_loss: 0.24467821419239044\n",
      "train_loss: 0.244678 | avg_loss: 0.221301 | gender_precise: 90.000000 (5813/6400) [50/186]\n",
      "gender_loss: 0.22289755940437317\n",
      "train_loss: 0.222898 | avg_loss: 0.221332 | gender_precise: 90.000000 (5929/6528) [51/186]\n",
      "gender_loss: 0.31220537424087524\n",
      "train_loss: 0.312205 | avg_loss: 0.223080 | gender_precise: 90.000000 (6038/6656) [52/186]\n",
      "gender_loss: 0.21105365455150604\n",
      "train_loss: 0.211054 | avg_loss: 0.222853 | gender_precise: 90.000000 (6151/6784) [53/186]\n",
      "gender_loss: 0.18509137630462646\n",
      "train_loss: 0.185091 | avg_loss: 0.222154 | gender_precise: 90.000000 (6268/6912) [54/186]\n",
      "gender_loss: 0.23942092061042786\n",
      "train_loss: 0.239421 | avg_loss: 0.222468 | gender_precise: 90.000000 (6382/7040) [55/186]\n",
      "gender_loss: 0.25542035698890686\n",
      "train_loss: 0.255420 | avg_loss: 0.223056 | gender_precise: 90.000000 (6496/7168) [56/186]\n",
      "gender_loss: 0.1651279479265213\n",
      "train_loss: 0.165128 | avg_loss: 0.222040 | gender_precise: 90.000000 (6614/7296) [57/186]\n",
      "gender_loss: 0.2671307325363159\n",
      "train_loss: 0.267131 | avg_loss: 0.222817 | gender_precise: 90.000000 (6722/7424) [58/186]\n",
      "gender_loss: 0.24871453642845154\n",
      "train_loss: 0.248715 | avg_loss: 0.223256 | gender_precise: 90.000000 (6837/7552) [59/186]\n",
      "gender_loss: 0.16281285881996155\n",
      "train_loss: 0.162813 | avg_loss: 0.222249 | gender_precise: 90.000000 (6954/7680) [60/186]\n",
      "gender_loss: 0.13339798152446747\n",
      "train_loss: 0.133398 | avg_loss: 0.220792 | gender_precise: 90.000000 (7074/7808) [61/186]\n",
      "gender_loss: 0.22683072090148926\n",
      "train_loss: 0.226831 | avg_loss: 0.220890 | gender_precise: 90.000000 (7191/7936) [62/186]\n",
      "gender_loss: 0.23264314234256744\n",
      "train_loss: 0.232643 | avg_loss: 0.221076 | gender_precise: 90.000000 (7305/8064) [63/186]\n",
      "gender_loss: 0.1825672686100006\n",
      "train_loss: 0.182567 | avg_loss: 0.220475 | gender_precise: 90.000000 (7425/8192) [64/186]\n",
      "gender_loss: 0.223576158285141\n",
      "train_loss: 0.223576 | avg_loss: 0.220522 | gender_precise: 90.000000 (7545/8320) [65/186]\n",
      "gender_loss: 0.32128921151161194\n",
      "train_loss: 0.321289 | avg_loss: 0.222049 | gender_precise: 90.000000 (7660/8448) [66/186]\n",
      "gender_loss: 0.29224562644958496\n",
      "train_loss: 0.292246 | avg_loss: 0.223097 | gender_precise: 90.000000 (7770/8576) [67/186]\n",
      "gender_loss: 0.23420760035514832\n",
      "train_loss: 0.234208 | avg_loss: 0.223260 | gender_precise: 90.000000 (7883/8704) [68/186]\n",
      "gender_loss: 0.18994155526161194\n",
      "train_loss: 0.189942 | avg_loss: 0.222777 | gender_precise: 90.000000 (8002/8832) [69/186]\n",
      "gender_loss: 0.19054661691188812\n",
      "train_loss: 0.190547 | avg_loss: 0.222317 | gender_precise: 90.000000 (8122/8960) [70/186]\n",
      "gender_loss: 0.20732136070728302\n",
      "train_loss: 0.207321 | avg_loss: 0.222106 | gender_precise: 90.000000 (8238/9088) [71/186]\n",
      "gender_loss: 0.18605445325374603\n",
      "train_loss: 0.186054 | avg_loss: 0.221605 | gender_precise: 90.000000 (8358/9216) [72/186]\n",
      "gender_loss: 0.24263562262058258\n",
      "train_loss: 0.242636 | avg_loss: 0.221893 | gender_precise: 90.000000 (8469/9344) [73/186]\n",
      "gender_loss: 0.2237815260887146\n",
      "train_loss: 0.223782 | avg_loss: 0.221919 | gender_precise: 90.000000 (8587/9472) [74/186]\n",
      "gender_loss: 0.1794465184211731\n",
      "train_loss: 0.179447 | avg_loss: 0.221352 | gender_precise: 90.000000 (8703/9600) [75/186]\n",
      "gender_loss: 0.33468711376190186\n",
      "train_loss: 0.334687 | avg_loss: 0.222843 | gender_precise: 90.000000 (8811/9728) [76/186]\n",
      "gender_loss: 0.2881419360637665\n",
      "train_loss: 0.288142 | avg_loss: 0.223692 | gender_precise: 90.000000 (8924/9856) [77/186]\n",
      "gender_loss: 0.20042110979557037\n",
      "train_loss: 0.200421 | avg_loss: 0.223393 | gender_precise: 90.000000 (9043/9984) [78/186]\n",
      "gender_loss: 0.19105324149131775\n",
      "train_loss: 0.191053 | avg_loss: 0.222984 | gender_precise: 90.000000 (9162/10112) [79/186]\n",
      "gender_loss: 0.22256247699260712\n",
      "train_loss: 0.222562 | avg_loss: 0.222979 | gender_precise: 90.000000 (9277/10240) [80/186]\n",
      "gender_loss: 0.17828457057476044\n",
      "train_loss: 0.178285 | avg_loss: 0.222427 | gender_precise: 90.000000 (9393/10368) [81/186]\n",
      "gender_loss: 0.2178766131401062\n",
      "train_loss: 0.217877 | avg_loss: 0.222371 | gender_precise: 90.000000 (9511/10496) [82/186]\n",
      "gender_loss: 0.19808396697044373\n",
      "train_loss: 0.198084 | avg_loss: 0.222079 | gender_precise: 90.000000 (9628/10624) [83/186]\n",
      "gender_loss: 0.18470050394535065\n",
      "train_loss: 0.184701 | avg_loss: 0.221634 | gender_precise: 90.000000 (9747/10752) [84/186]\n",
      "gender_loss: 0.19388215243816376\n",
      "train_loss: 0.193882 | avg_loss: 0.221307 | gender_precise: 90.000000 (9867/10880) [85/186]\n",
      "gender_loss: 0.32801294326782227\n",
      "train_loss: 0.328013 | avg_loss: 0.222548 | gender_precise: 90.000000 (9979/11008) [86/186]\n",
      "gender_loss: 0.23134005069732666\n",
      "train_loss: 0.231340 | avg_loss: 0.222649 | gender_precise: 90.000000 (10095/11136) [87/186]\n",
      "gender_loss: 0.28643324971199036\n",
      "train_loss: 0.286433 | avg_loss: 0.223374 | gender_precise: 90.000000 (10205/11264) [88/186]\n",
      "gender_loss: 0.17135530710220337\n",
      "train_loss: 0.171355 | avg_loss: 0.222789 | gender_precise: 90.000000 (10326/11392) [89/186]\n",
      "gender_loss: 0.19745579361915588\n",
      "train_loss: 0.197456 | avg_loss: 0.222508 | gender_precise: 90.000000 (10442/11520) [90/186]\n",
      "gender_loss: 0.21429115533828735\n",
      "train_loss: 0.214291 | avg_loss: 0.222418 | gender_precise: 90.000000 (10557/11648) [91/186]\n",
      "gender_loss: 0.18016433715820312\n",
      "train_loss: 0.180164 | avg_loss: 0.221958 | gender_precise: 90.000000 (10672/11776) [92/186]\n",
      "gender_loss: 0.26410213112831116\n",
      "train_loss: 0.264102 | avg_loss: 0.222411 | gender_precise: 90.000000 (10785/11904) [93/186]\n",
      "gender_loss: 0.14936485886573792\n",
      "train_loss: 0.149365 | avg_loss: 0.221634 | gender_precise: 90.000000 (10905/12032) [94/186]\n",
      "gender_loss: 0.16529035568237305\n",
      "train_loss: 0.165290 | avg_loss: 0.221041 | gender_precise: 90.000000 (11026/12160) [95/186]\n",
      "gender_loss: 0.27596232295036316\n",
      "train_loss: 0.275962 | avg_loss: 0.221613 | gender_precise: 90.000000 (11137/12288) [96/186]\n",
      "gender_loss: 0.16657894849777222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.166579 | avg_loss: 0.221046 | gender_precise: 90.000000 (11256/12416) [97/186]\n",
      "gender_loss: 0.2835696339607239\n",
      "train_loss: 0.283570 | avg_loss: 0.221684 | gender_precise: 90.000000 (11368/12544) [98/186]\n",
      "gender_loss: 0.19875848293304443\n",
      "train_loss: 0.198758 | avg_loss: 0.221452 | gender_precise: 90.000000 (11483/12672) [99/186]\n",
      "gender_loss: 0.19460158050060272\n",
      "train_loss: 0.194602 | avg_loss: 0.221184 | gender_precise: 90.000000 (11599/12800) [100/186]\n",
      "gender_loss: 0.15435725450515747\n",
      "train_loss: 0.154357 | avg_loss: 0.220522 | gender_precise: 90.000000 (11722/12928) [101/186]\n",
      "gender_loss: 0.2818053364753723\n",
      "train_loss: 0.281805 | avg_loss: 0.221123 | gender_precise: 90.000000 (11835/13056) [102/186]\n",
      "gender_loss: 0.1925557404756546\n",
      "train_loss: 0.192556 | avg_loss: 0.220846 | gender_precise: 90.000000 (11952/13184) [103/186]\n",
      "gender_loss: 0.25864362716674805\n",
      "train_loss: 0.258644 | avg_loss: 0.221209 | gender_precise: 90.000000 (12062/13312) [104/186]\n",
      "gender_loss: 0.20496636629104614\n",
      "train_loss: 0.204966 | avg_loss: 0.221055 | gender_precise: 90.000000 (12176/13440) [105/186]\n",
      "gender_loss: 0.23942731320858002\n",
      "train_loss: 0.239427 | avg_loss: 0.221228 | gender_precise: 90.000000 (12287/13568) [106/186]\n",
      "gender_loss: 0.2372848093509674\n",
      "train_loss: 0.237285 | avg_loss: 0.221378 | gender_precise: 90.000000 (12401/13696) [107/186]\n",
      "gender_loss: 0.2593754231929779\n",
      "train_loss: 0.259375 | avg_loss: 0.221730 | gender_precise: 90.000000 (12515/13824) [108/186]\n",
      "gender_loss: 0.14453843235969543\n",
      "train_loss: 0.144538 | avg_loss: 0.221022 | gender_precise: 90.000000 (12632/13952) [109/186]\n",
      "gender_loss: 0.2777476906776428\n",
      "train_loss: 0.277748 | avg_loss: 0.221537 | gender_precise: 90.000000 (12745/14080) [110/186]\n",
      "gender_loss: 0.25032660365104675\n",
      "train_loss: 0.250327 | avg_loss: 0.221797 | gender_precise: 90.000000 (12862/14208) [111/186]\n",
      "gender_loss: 0.2334703505039215\n",
      "train_loss: 0.233470 | avg_loss: 0.221901 | gender_precise: 90.000000 (12976/14336) [112/186]\n",
      "gender_loss: 0.2052953839302063\n",
      "train_loss: 0.205295 | avg_loss: 0.221754 | gender_precise: 90.000000 (13090/14464) [113/186]\n",
      "gender_loss: 0.2242003232240677\n",
      "train_loss: 0.224200 | avg_loss: 0.221775 | gender_precise: 90.000000 (13208/14592) [114/186]\n",
      "gender_loss: 0.1975914090871811\n",
      "train_loss: 0.197591 | avg_loss: 0.221565 | gender_precise: 90.000000 (13326/14720) [115/186]\n",
      "gender_loss: 0.18416161835193634\n",
      "train_loss: 0.184162 | avg_loss: 0.221243 | gender_precise: 90.000000 (13444/14848) [116/186]\n",
      "gender_loss: 0.165179044008255\n",
      "train_loss: 0.165179 | avg_loss: 0.220763 | gender_precise: 90.000000 (13563/14976) [117/186]\n",
      "gender_loss: 0.22687998414039612\n",
      "train_loss: 0.226880 | avg_loss: 0.220815 | gender_precise: 90.000000 (13678/15104) [118/186]\n",
      "gender_loss: 0.2614659368991852\n",
      "train_loss: 0.261466 | avg_loss: 0.221157 | gender_precise: 90.000000 (13791/15232) [119/186]\n",
      "gender_loss: 0.2325296849012375\n",
      "train_loss: 0.232530 | avg_loss: 0.221252 | gender_precise: 90.000000 (13905/15360) [120/186]\n",
      "gender_loss: 0.2016953080892563\n",
      "train_loss: 0.201695 | avg_loss: 0.221090 | gender_precise: 90.000000 (14024/15488) [121/186]\n",
      "gender_loss: 0.23104237020015717\n",
      "train_loss: 0.231042 | avg_loss: 0.221172 | gender_precise: 90.000000 (14139/15616) [122/186]\n",
      "gender_loss: 0.25922900438308716\n",
      "train_loss: 0.259229 | avg_loss: 0.221481 | gender_precise: 90.000000 (14251/15744) [123/186]\n",
      "gender_loss: 0.20242108404636383\n",
      "train_loss: 0.202421 | avg_loss: 0.221327 | gender_precise: 90.000000 (14366/15872) [124/186]\n",
      "gender_loss: 0.25553154945373535\n",
      "train_loss: 0.255532 | avg_loss: 0.221601 | gender_precise: 90.000000 (14479/16000) [125/186]\n",
      "gender_loss: 0.12665526568889618\n",
      "train_loss: 0.126655 | avg_loss: 0.220847 | gender_precise: 90.000000 (14603/16128) [126/186]\n",
      "gender_loss: 0.28576749563217163\n",
      "train_loss: 0.285767 | avg_loss: 0.221359 | gender_precise: 90.000000 (14716/16256) [127/186]\n",
      "gender_loss: 0.2460140734910965\n",
      "train_loss: 0.246014 | avg_loss: 0.221551 | gender_precise: 90.000000 (14830/16384) [128/186]\n",
      "gender_loss: 0.25882962346076965\n",
      "train_loss: 0.258830 | avg_loss: 0.221840 | gender_precise: 90.000000 (14939/16512) [129/186]\n",
      "gender_loss: 0.244853213429451\n",
      "train_loss: 0.244853 | avg_loss: 0.222017 | gender_precise: 90.000000 (15052/16640) [130/186]\n",
      "gender_loss: 0.25510066747665405\n",
      "train_loss: 0.255101 | avg_loss: 0.222270 | gender_precise: 90.000000 (15167/16768) [131/186]\n",
      "gender_loss: 0.2068568766117096\n",
      "train_loss: 0.206857 | avg_loss: 0.222153 | gender_precise: 90.000000 (15285/16896) [132/186]\n",
      "gender_loss: 0.20823334157466888\n",
      "train_loss: 0.208233 | avg_loss: 0.222048 | gender_precise: 90.000000 (15401/17024) [133/186]\n",
      "gender_loss: 0.17888596653938293\n",
      "train_loss: 0.178886 | avg_loss: 0.221726 | gender_precise: 90.000000 (15518/17152) [134/186]\n",
      "gender_loss: 0.1812543421983719\n",
      "train_loss: 0.181254 | avg_loss: 0.221426 | gender_precise: 90.000000 (15637/17280) [135/186]\n",
      "gender_loss: 0.22444356977939606\n",
      "train_loss: 0.224444 | avg_loss: 0.221449 | gender_precise: 90.000000 (15753/17408) [136/186]\n",
      "gender_loss: 0.28709664940834045\n",
      "train_loss: 0.287097 | avg_loss: 0.221928 | gender_precise: 90.000000 (15865/17536) [137/186]\n",
      "gender_loss: 0.24816392362117767\n",
      "train_loss: 0.248164 | avg_loss: 0.222118 | gender_precise: 90.000000 (15984/17664) [138/186]\n",
      "gender_loss: 0.21448968350887299\n",
      "train_loss: 0.214490 | avg_loss: 0.222063 | gender_precise: 90.000000 (16099/17792) [139/186]\n",
      "gender_loss: 0.16015082597732544\n",
      "train_loss: 0.160151 | avg_loss: 0.221621 | gender_precise: 90.000000 (16219/17920) [140/186]\n",
      "gender_loss: 0.26458612084388733\n",
      "train_loss: 0.264586 | avg_loss: 0.221925 | gender_precise: 90.000000 (16331/18048) [141/186]\n",
      "gender_loss: 0.14270354807376862\n",
      "train_loss: 0.142704 | avg_loss: 0.221368 | gender_precise: 90.000000 (16452/18176) [142/186]\n",
      "gender_loss: 0.24354299902915955\n",
      "train_loss: 0.243543 | avg_loss: 0.221523 | gender_precise: 90.000000 (16564/18304) [143/186]\n",
      "gender_loss: 0.3130108118057251\n",
      "train_loss: 0.313011 | avg_loss: 0.222158 | gender_precise: 90.000000 (16676/18432) [144/186]\n",
      "gender_loss: 0.1978885680437088\n",
      "train_loss: 0.197889 | avg_loss: 0.221991 | gender_precise: 90.000000 (16793/18560) [145/186]\n",
      "gender_loss: 0.2539829909801483\n",
      "train_loss: 0.253983 | avg_loss: 0.222210 | gender_precise: 90.000000 (16909/18688) [146/186]\n",
      "gender_loss: 0.20851266384124756\n",
      "train_loss: 0.208513 | avg_loss: 0.222117 | gender_precise: 90.000000 (17027/18816) [147/186]\n",
      "gender_loss: 0.29436126351356506\n",
      "train_loss: 0.294361 | avg_loss: 0.222605 | gender_precise: 90.000000 (17138/18944) [148/186]\n",
      "gender_loss: 0.21493181586265564\n",
      "train_loss: 0.214932 | avg_loss: 0.222553 | gender_precise: 90.000000 (17254/19072) [149/186]\n",
      "gender_loss: 0.2181265652179718\n",
      "train_loss: 0.218127 | avg_loss: 0.222524 | gender_precise: 90.000000 (17371/19200) [150/186]\n",
      "gender_loss: 0.1839429885149002\n",
      "train_loss: 0.183943 | avg_loss: 0.222268 | gender_precise: 90.000000 (17489/19328) [151/186]\n",
      "gender_loss: 0.18270865082740784\n",
      "train_loss: 0.182709 | avg_loss: 0.222008 | gender_precise: 90.000000 (17604/19456) [152/186]\n",
      "gender_loss: 0.19301947951316833\n",
      "train_loss: 0.193019 | avg_loss: 0.221818 | gender_precise: 90.000000 (17726/19584) [153/186]\n",
      "gender_loss: 0.20274688303470612\n",
      "train_loss: 0.202747 | avg_loss: 0.221695 | gender_precise: 90.000000 (17837/19712) [154/186]\n",
      "gender_loss: 0.14746254682540894\n",
      "train_loss: 0.147463 | avg_loss: 0.221216 | gender_precise: 90.000000 (17956/19840) [155/186]\n",
      "gender_loss: 0.2104596346616745\n",
      "train_loss: 0.210460 | avg_loss: 0.221147 | gender_precise: 90.000000 (18076/19968) [156/186]\n",
      "gender_loss: 0.19798363745212555\n",
      "train_loss: 0.197984 | avg_loss: 0.220999 | gender_precise: 90.000000 (18191/20096) [157/186]\n",
      "gender_loss: 0.19971103966236115\n",
      "train_loss: 0.199711 | avg_loss: 0.220865 | gender_precise: 90.000000 (18307/20224) [158/186]\n",
      "gender_loss: 0.2120920866727829\n",
      "train_loss: 0.212092 | avg_loss: 0.220809 | gender_precise: 90.000000 (18421/20352) [159/186]\n",
      "gender_loss: 0.22469033300876617\n",
      "train_loss: 0.224690 | avg_loss: 0.220834 | gender_precise: 90.000000 (18533/20480) [160/186]\n",
      "gender_loss: 0.2451322078704834\n",
      "train_loss: 0.245132 | avg_loss: 0.220985 | gender_precise: 90.000000 (18646/20608) [161/186]\n",
      "gender_loss: 0.18656884133815765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.186569 | avg_loss: 0.220772 | gender_precise: 90.000000 (18765/20736) [162/186]\n",
      "gender_loss: 0.1370554119348526\n",
      "train_loss: 0.137055 | avg_loss: 0.220258 | gender_precise: 90.000000 (18884/20864) [163/186]\n",
      "gender_loss: 0.3188832402229309\n",
      "train_loss: 0.318883 | avg_loss: 0.220860 | gender_precise: 90.000000 (18994/20992) [164/186]\n",
      "gender_loss: 0.21327313780784607\n",
      "train_loss: 0.213273 | avg_loss: 0.220814 | gender_precise: 90.000000 (19110/21120) [165/186]\n",
      "gender_loss: 0.23837226629257202\n",
      "train_loss: 0.238372 | avg_loss: 0.220920 | gender_precise: 90.000000 (19223/21248) [166/186]\n",
      "gender_loss: 0.30415794253349304\n",
      "train_loss: 0.304158 | avg_loss: 0.221418 | gender_precise: 90.000000 (19333/21376) [167/186]\n",
      "gender_loss: 0.2750428020954132\n",
      "train_loss: 0.275043 | avg_loss: 0.221737 | gender_precise: 90.000000 (19441/21504) [168/186]\n",
      "gender_loss: 0.19452346861362457\n",
      "train_loss: 0.194523 | avg_loss: 0.221576 | gender_precise: 90.000000 (19557/21632) [169/186]\n",
      "gender_loss: 0.21937158703804016\n",
      "train_loss: 0.219372 | avg_loss: 0.221563 | gender_precise: 90.000000 (19677/21760) [170/186]\n",
      "gender_loss: 0.15787093341350555\n",
      "train_loss: 0.157871 | avg_loss: 0.221191 | gender_precise: 90.000000 (19796/21888) [171/186]\n",
      "gender_loss: 0.2391057163476944\n",
      "train_loss: 0.239106 | avg_loss: 0.221295 | gender_precise: 90.000000 (19912/22016) [172/186]\n",
      "gender_loss: 0.16440635919570923\n",
      "train_loss: 0.164406 | avg_loss: 0.220966 | gender_precise: 90.000000 (20031/22144) [173/186]\n",
      "gender_loss: 0.2113085389137268\n",
      "train_loss: 0.211309 | avg_loss: 0.220911 | gender_precise: 90.000000 (20145/22272) [174/186]\n",
      "gender_loss: 0.2899857759475708\n",
      "train_loss: 0.289986 | avg_loss: 0.221305 | gender_precise: 90.000000 (20261/22400) [175/186]\n",
      "gender_loss: 0.26937171816825867\n",
      "train_loss: 0.269372 | avg_loss: 0.221578 | gender_precise: 90.000000 (20371/22528) [176/186]\n",
      "gender_loss: 0.25007471442222595\n",
      "train_loss: 0.250075 | avg_loss: 0.221739 | gender_precise: 90.000000 (20487/22656) [177/186]\n",
      "gender_loss: 0.26936063170433044\n",
      "train_loss: 0.269361 | avg_loss: 0.222007 | gender_precise: 90.000000 (20601/22784) [178/186]\n",
      "gender_loss: 0.22780923545360565\n",
      "train_loss: 0.227809 | avg_loss: 0.222039 | gender_precise: 90.000000 (20714/22912) [179/186]\n",
      "gender_loss: 0.14503397047519684\n",
      "train_loss: 0.145034 | avg_loss: 0.221612 | gender_precise: 90.000000 (20837/23040) [180/186]\n",
      "gender_loss: 0.24413332343101501\n",
      "train_loss: 0.244133 | avg_loss: 0.221736 | gender_precise: 90.000000 (20949/23168) [181/186]\n",
      "gender_loss: 0.21466940641403198\n",
      "train_loss: 0.214669 | avg_loss: 0.221697 | gender_precise: 90.000000 (21066/23296) [182/186]\n",
      "gender_loss: 0.3186189830303192\n",
      "train_loss: 0.318619 | avg_loss: 0.222227 | gender_precise: 90.000000 (21181/23424) [183/186]\n",
      "gender_loss: 0.2105090320110321\n",
      "train_loss: 0.210509 | avg_loss: 0.222163 | gender_precise: 90.000000 (21298/23552) [184/186]\n",
      "gender_loss: 0.20777316391468048\n",
      "train_loss: 0.207773 | avg_loss: 0.222085 | gender_precise: 90.000000 (21414/23680) [185/186]\n",
      "gender_loss: 0.12395966053009033\n",
      "train_loss: 0.123960 | avg_loss: 0.221558 | gender_precise: 90.000000 (21441/23708) [186/186]\n",
      "\n",
      "Test\n",
      "gender_prec: 84.000000 (108/128) [1/2]\n",
      "gender_prec: 84.000000 (113/134) [2/2]\n",
      "Number epoch: 9\n",
      "gender_loss: 0.2331572026014328\n",
      "train_loss: 0.233157 | avg_loss: 0.233157 | gender_precise: 91.000000 (117/128) [1/186]\n",
      "gender_loss: 0.1858634501695633\n",
      "train_loss: 0.185863 | avg_loss: 0.209510 | gender_precise: 92.000000 (237/256) [2/186]\n",
      "gender_loss: 0.17739000916481018\n",
      "train_loss: 0.177390 | avg_loss: 0.198804 | gender_precise: 91.000000 (353/384) [3/186]\n",
      "gender_loss: 0.1726807951927185\n",
      "train_loss: 0.172681 | avg_loss: 0.192273 | gender_precise: 92.000000 (475/512) [4/186]\n",
      "gender_loss: 0.2597583532333374\n",
      "train_loss: 0.259758 | avg_loss: 0.205770 | gender_precise: 91.000000 (587/640) [5/186]\n",
      "gender_loss: 0.14923904836177826\n",
      "train_loss: 0.149239 | avg_loss: 0.196348 | gender_precise: 91.000000 (704/768) [6/186]\n",
      "gender_loss: 0.16944043338298798\n",
      "train_loss: 0.169440 | avg_loss: 0.192504 | gender_precise: 91.000000 (820/896) [7/186]\n",
      "gender_loss: 0.2564450204372406\n",
      "train_loss: 0.256445 | avg_loss: 0.200497 | gender_precise: 91.000000 (933/1024) [8/186]\n",
      "gender_loss: 0.2673107981681824\n",
      "train_loss: 0.267311 | avg_loss: 0.207921 | gender_precise: 90.000000 (1046/1152) [9/186]\n",
      "gender_loss: 0.2952161133289337\n",
      "train_loss: 0.295216 | avg_loss: 0.216650 | gender_precise: 90.000000 (1161/1280) [10/186]\n",
      "gender_loss: 0.20517194271087646\n",
      "train_loss: 0.205172 | avg_loss: 0.215607 | gender_precise: 90.000000 (1275/1408) [11/186]\n",
      "gender_loss: 0.13226652145385742\n",
      "train_loss: 0.132267 | avg_loss: 0.208662 | gender_precise: 91.000000 (1398/1536) [12/186]\n",
      "gender_loss: 0.18268589675426483\n",
      "train_loss: 0.182686 | avg_loss: 0.206664 | gender_precise: 90.000000 (1514/1664) [13/186]\n",
      "gender_loss: 0.15252916514873505\n",
      "train_loss: 0.152529 | avg_loss: 0.202797 | gender_precise: 91.000000 (1632/1792) [14/186]\n",
      "gender_loss: 0.19667480885982513\n",
      "train_loss: 0.196675 | avg_loss: 0.202389 | gender_precise: 91.000000 (1748/1920) [15/186]\n",
      "gender_loss: 0.2567778527736664\n",
      "train_loss: 0.256778 | avg_loss: 0.205788 | gender_precise: 90.000000 (1863/2048) [16/186]\n",
      "gender_loss: 0.2238083928823471\n",
      "train_loss: 0.223808 | avg_loss: 0.206848 | gender_precise: 90.000000 (1980/2176) [17/186]\n",
      "gender_loss: 0.31089380383491516\n",
      "train_loss: 0.310894 | avg_loss: 0.212628 | gender_precise: 90.000000 (2089/2304) [18/186]\n",
      "gender_loss: 0.16414982080459595\n",
      "train_loss: 0.164150 | avg_loss: 0.210077 | gender_precise: 90.000000 (2209/2432) [19/186]\n",
      "gender_loss: 0.28040340542793274\n",
      "train_loss: 0.280403 | avg_loss: 0.213593 | gender_precise: 90.000000 (2325/2560) [20/186]\n",
      "gender_loss: 0.1628635823726654\n",
      "train_loss: 0.162864 | avg_loss: 0.211177 | gender_precise: 90.000000 (2446/2688) [21/186]\n",
      "gender_loss: 0.16859613358974457\n",
      "train_loss: 0.168596 | avg_loss: 0.209242 | gender_precise: 91.000000 (2566/2816) [22/186]\n",
      "gender_loss: 0.2819961905479431\n",
      "train_loss: 0.281996 | avg_loss: 0.212405 | gender_precise: 91.000000 (2680/2944) [23/186]\n",
      "gender_loss: 0.2111818939447403\n",
      "train_loss: 0.211182 | avg_loss: 0.212354 | gender_precise: 91.000000 (2797/3072) [24/186]\n",
      "gender_loss: 0.13668453693389893\n",
      "train_loss: 0.136685 | avg_loss: 0.209327 | gender_precise: 91.000000 (2919/3200) [25/186]\n",
      "gender_loss: 0.1502770185470581\n",
      "train_loss: 0.150277 | avg_loss: 0.207056 | gender_precise: 91.000000 (3037/3328) [26/186]\n",
      "gender_loss: 0.19827574491500854\n",
      "train_loss: 0.198276 | avg_loss: 0.206731 | gender_precise: 91.000000 (3155/3456) [27/186]\n",
      "gender_loss: 0.20066668093204498\n",
      "train_loss: 0.200667 | avg_loss: 0.206514 | gender_precise: 91.000000 (3271/3584) [28/186]\n",
      "gender_loss: 0.16218119859695435\n",
      "train_loss: 0.162181 | avg_loss: 0.204986 | gender_precise: 91.000000 (3390/3712) [29/186]\n",
      "gender_loss: 0.19980144500732422\n",
      "train_loss: 0.199801 | avg_loss: 0.204813 | gender_precise: 91.000000 (3506/3840) [30/186]\n",
      "gender_loss: 0.2709573209285736\n",
      "train_loss: 0.270957 | avg_loss: 0.206947 | gender_precise: 91.000000 (3618/3968) [31/186]\n",
      "gender_loss: 0.18810784816741943\n",
      "train_loss: 0.188108 | avg_loss: 0.206358 | gender_precise: 91.000000 (3740/4096) [32/186]\n",
      "gender_loss: 0.17545589804649353\n",
      "train_loss: 0.175456 | avg_loss: 0.205421 | gender_precise: 91.000000 (3857/4224) [33/186]\n",
      "gender_loss: 0.15124163031578064\n",
      "train_loss: 0.151242 | avg_loss: 0.203828 | gender_precise: 91.000000 (3975/4352) [34/186]\n",
      "gender_loss: 0.1954694390296936\n",
      "train_loss: 0.195469 | avg_loss: 0.203589 | gender_precise: 91.000000 (4091/4480) [35/186]\n",
      "gender_loss: 0.18226902186870575\n",
      "train_loss: 0.182269 | avg_loss: 0.202997 | gender_precise: 91.000000 (4208/4608) [36/186]\n",
      "gender_loss: 0.2036188840866089\n",
      "train_loss: 0.203619 | avg_loss: 0.203014 | gender_precise: 91.000000 (4324/4736) [37/186]\n",
      "gender_loss: 0.2038845419883728\n",
      "train_loss: 0.203885 | avg_loss: 0.203037 | gender_precise: 91.000000 (4439/4864) [38/186]\n",
      "gender_loss: 0.09378789365291595\n",
      "train_loss: 0.093788 | avg_loss: 0.200235 | gender_precise: 91.000000 (4562/4992) [39/186]\n",
      "gender_loss: 0.1473868489265442\n",
      "train_loss: 0.147387 | avg_loss: 0.198914 | gender_precise: 91.000000 (4679/5120) [40/186]\n",
      "gender_loss: 0.19024990499019623\n",
      "train_loss: 0.190250 | avg_loss: 0.198703 | gender_precise: 91.000000 (4796/5248) [41/186]\n",
      "gender_loss: 0.32436200976371765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.324362 | avg_loss: 0.201695 | gender_precise: 91.000000 (4907/5376) [42/186]\n",
      "gender_loss: 0.2267947494983673\n",
      "train_loss: 0.226795 | avg_loss: 0.202278 | gender_precise: 91.000000 (5024/5504) [43/186]\n",
      "gender_loss: 0.18780189752578735\n",
      "train_loss: 0.187802 | avg_loss: 0.201949 | gender_precise: 91.000000 (5143/5632) [44/186]\n",
      "gender_loss: 0.19326958060264587\n",
      "train_loss: 0.193270 | avg_loss: 0.201757 | gender_precise: 91.000000 (5258/5760) [45/186]\n",
      "gender_loss: 0.17167869210243225\n",
      "train_loss: 0.171679 | avg_loss: 0.201103 | gender_precise: 91.000000 (5376/5888) [46/186]\n",
      "gender_loss: 0.17775772511959076\n",
      "train_loss: 0.177758 | avg_loss: 0.200606 | gender_precise: 91.000000 (5494/6016) [47/186]\n",
      "gender_loss: 0.295192688703537\n",
      "train_loss: 0.295193 | avg_loss: 0.202577 | gender_precise: 91.000000 (5610/6144) [48/186]\n",
      "gender_loss: 0.2308320701122284\n",
      "train_loss: 0.230832 | avg_loss: 0.203153 | gender_precise: 91.000000 (5730/6272) [49/186]\n",
      "gender_loss: 0.13377968966960907\n",
      "train_loss: 0.133780 | avg_loss: 0.201766 | gender_precise: 91.000000 (5850/6400) [50/186]\n",
      "gender_loss: 0.17325140535831451\n",
      "train_loss: 0.173251 | avg_loss: 0.201207 | gender_precise: 91.000000 (5968/6528) [51/186]\n",
      "gender_loss: 0.21004247665405273\n",
      "train_loss: 0.210042 | avg_loss: 0.201377 | gender_precise: 91.000000 (6081/6656) [52/186]\n",
      "gender_loss: 0.3363156318664551\n",
      "train_loss: 0.336316 | avg_loss: 0.203923 | gender_precise: 91.000000 (6195/6784) [53/186]\n",
      "gender_loss: 0.23470832407474518\n",
      "train_loss: 0.234708 | avg_loss: 0.204493 | gender_precise: 91.000000 (6309/6912) [54/186]\n",
      "gender_loss: 0.19780384004116058\n",
      "train_loss: 0.197804 | avg_loss: 0.204371 | gender_precise: 91.000000 (6428/7040) [55/186]\n",
      "gender_loss: 0.12838374078273773\n",
      "train_loss: 0.128384 | avg_loss: 0.203014 | gender_precise: 91.000000 (6548/7168) [56/186]\n",
      "gender_loss: 0.19402281939983368\n",
      "train_loss: 0.194023 | avg_loss: 0.202856 | gender_precise: 91.000000 (6668/7296) [57/186]\n",
      "gender_loss: 0.2516244053840637\n",
      "train_loss: 0.251624 | avg_loss: 0.203697 | gender_precise: 91.000000 (6780/7424) [58/186]\n",
      "gender_loss: 0.24205520749092102\n",
      "train_loss: 0.242055 | avg_loss: 0.204347 | gender_precise: 91.000000 (6892/7552) [59/186]\n",
      "gender_loss: 0.23077033460140228\n",
      "train_loss: 0.230770 | avg_loss: 0.204788 | gender_precise: 91.000000 (7007/7680) [60/186]\n",
      "gender_loss: 0.3213362991809845\n",
      "train_loss: 0.321336 | avg_loss: 0.206698 | gender_precise: 91.000000 (7117/7808) [61/186]\n",
      "gender_loss: 0.18196122348308563\n",
      "train_loss: 0.181961 | avg_loss: 0.206299 | gender_precise: 91.000000 (7235/7936) [62/186]\n",
      "gender_loss: 0.21340394020080566\n",
      "train_loss: 0.213404 | avg_loss: 0.206412 | gender_precise: 91.000000 (7352/8064) [63/186]\n",
      "gender_loss: 0.20627348124980927\n",
      "train_loss: 0.206273 | avg_loss: 0.206410 | gender_precise: 91.000000 (7471/8192) [64/186]\n",
      "gender_loss: 0.23808322846889496\n",
      "train_loss: 0.238083 | avg_loss: 0.206897 | gender_precise: 91.000000 (7586/8320) [65/186]\n",
      "gender_loss: 0.28142493963241577\n",
      "train_loss: 0.281425 | avg_loss: 0.208026 | gender_precise: 91.000000 (7698/8448) [66/186]\n",
      "gender_loss: 0.1967170387506485\n",
      "train_loss: 0.196717 | avg_loss: 0.207858 | gender_precise: 91.000000 (7816/8576) [67/186]\n",
      "gender_loss: 0.213136687874794\n",
      "train_loss: 0.213137 | avg_loss: 0.207935 | gender_precise: 91.000000 (7931/8704) [68/186]\n",
      "gender_loss: 0.23082230985164642\n",
      "train_loss: 0.230822 | avg_loss: 0.208267 | gender_precise: 91.000000 (8042/8832) [69/186]\n",
      "gender_loss: 0.13383693993091583\n",
      "train_loss: 0.133837 | avg_loss: 0.207204 | gender_precise: 91.000000 (8164/8960) [70/186]\n",
      "gender_loss: 0.23244301974773407\n",
      "train_loss: 0.232443 | avg_loss: 0.207559 | gender_precise: 91.000000 (8277/9088) [71/186]\n",
      "gender_loss: 0.2512088716030121\n",
      "train_loss: 0.251209 | avg_loss: 0.208165 | gender_precise: 91.000000 (8389/9216) [72/186]\n",
      "gender_loss: 0.21665498614311218\n",
      "train_loss: 0.216655 | avg_loss: 0.208282 | gender_precise: 91.000000 (8506/9344) [73/186]\n",
      "gender_loss: 0.20701003074645996\n",
      "train_loss: 0.207010 | avg_loss: 0.208265 | gender_precise: 91.000000 (8622/9472) [74/186]\n",
      "gender_loss: 0.21625593304634094\n",
      "train_loss: 0.216256 | avg_loss: 0.208371 | gender_precise: 91.000000 (8743/9600) [75/186]\n",
      "gender_loss: 0.18685078620910645\n",
      "train_loss: 0.186851 | avg_loss: 0.208088 | gender_precise: 91.000000 (8860/9728) [76/186]\n",
      "gender_loss: 0.1562158614397049\n",
      "train_loss: 0.156216 | avg_loss: 0.207414 | gender_precise: 91.000000 (8978/9856) [77/186]\n",
      "gender_loss: 0.2697333097457886\n",
      "train_loss: 0.269733 | avg_loss: 0.208213 | gender_precise: 91.000000 (9091/9984) [78/186]\n",
      "gender_loss: 0.2691996991634369\n",
      "train_loss: 0.269200 | avg_loss: 0.208985 | gender_precise: 90.000000 (9199/10112) [79/186]\n",
      "gender_loss: 0.34269657731056213\n",
      "train_loss: 0.342697 | avg_loss: 0.210657 | gender_precise: 90.000000 (9309/10240) [80/186]\n",
      "gender_loss: 0.1914149522781372\n",
      "train_loss: 0.191415 | avg_loss: 0.210419 | gender_precise: 90.000000 (9427/10368) [81/186]\n",
      "gender_loss: 0.13742457330226898\n",
      "train_loss: 0.137425 | avg_loss: 0.209529 | gender_precise: 90.000000 (9549/10496) [82/186]\n",
      "gender_loss: 0.17616426944732666\n",
      "train_loss: 0.176164 | avg_loss: 0.209127 | gender_precise: 90.000000 (9666/10624) [83/186]\n",
      "gender_loss: 0.2655886113643646\n",
      "train_loss: 0.265589 | avg_loss: 0.209799 | gender_precise: 90.000000 (9778/10752) [84/186]\n",
      "gender_loss: 0.19142886996269226\n",
      "train_loss: 0.191429 | avg_loss: 0.209583 | gender_precise: 90.000000 (9893/10880) [85/186]\n",
      "gender_loss: 0.1980493664741516\n",
      "train_loss: 0.198049 | avg_loss: 0.209449 | gender_precise: 90.000000 (10007/11008) [86/186]\n",
      "gender_loss: 0.2064102590084076\n",
      "train_loss: 0.206410 | avg_loss: 0.209414 | gender_precise: 90.000000 (10124/11136) [87/186]\n",
      "gender_loss: 0.21427114307880402\n",
      "train_loss: 0.214271 | avg_loss: 0.209469 | gender_precise: 90.000000 (10237/11264) [88/186]\n",
      "gender_loss: 0.29452458024024963\n",
      "train_loss: 0.294525 | avg_loss: 0.210425 | gender_precise: 90.000000 (10348/11392) [89/186]\n",
      "gender_loss: 0.23351022601127625\n",
      "train_loss: 0.233510 | avg_loss: 0.210681 | gender_precise: 90.000000 (10460/11520) [90/186]\n",
      "gender_loss: 0.21859422326087952\n",
      "train_loss: 0.218594 | avg_loss: 0.210768 | gender_precise: 90.000000 (10575/11648) [91/186]\n",
      "gender_loss: 0.1706632375717163\n",
      "train_loss: 0.170663 | avg_loss: 0.210332 | gender_precise: 90.000000 (10693/11776) [92/186]\n",
      "gender_loss: 0.26514777541160583\n",
      "train_loss: 0.265148 | avg_loss: 0.210922 | gender_precise: 90.000000 (10809/11904) [93/186]\n",
      "gender_loss: 0.23319917917251587\n",
      "train_loss: 0.233199 | avg_loss: 0.211159 | gender_precise: 90.000000 (10929/12032) [94/186]\n",
      "gender_loss: 0.15068987011909485\n",
      "train_loss: 0.150690 | avg_loss: 0.210522 | gender_precise: 90.000000 (11047/12160) [95/186]\n",
      "gender_loss: 0.27912116050720215\n",
      "train_loss: 0.279121 | avg_loss: 0.211237 | gender_precise: 90.000000 (11160/12288) [96/186]\n",
      "gender_loss: 0.20621530711650848\n",
      "train_loss: 0.206215 | avg_loss: 0.211185 | gender_precise: 90.000000 (11278/12416) [97/186]\n",
      "gender_loss: 0.15541864931583405\n",
      "train_loss: 0.155419 | avg_loss: 0.210616 | gender_precise: 90.000000 (11396/12544) [98/186]\n",
      "gender_loss: 0.21741648018360138\n",
      "train_loss: 0.217416 | avg_loss: 0.210685 | gender_precise: 90.000000 (11514/12672) [99/186]\n",
      "gender_loss: 0.19467736780643463\n",
      "train_loss: 0.194677 | avg_loss: 0.210525 | gender_precise: 90.000000 (11632/12800) [100/186]\n",
      "gender_loss: 0.18365345895290375\n",
      "train_loss: 0.183653 | avg_loss: 0.210259 | gender_precise: 90.000000 (11751/12928) [101/186]\n",
      "gender_loss: 0.22076058387756348\n",
      "train_loss: 0.220761 | avg_loss: 0.210362 | gender_precise: 90.000000 (11868/13056) [102/186]\n",
      "gender_loss: 0.20927336812019348\n",
      "train_loss: 0.209273 | avg_loss: 0.210351 | gender_precise: 90.000000 (11986/13184) [103/186]\n",
      "gender_loss: 0.2745024859905243\n",
      "train_loss: 0.274502 | avg_loss: 0.210968 | gender_precise: 90.000000 (12103/13312) [104/186]\n",
      "gender_loss: 0.225519597530365\n",
      "train_loss: 0.225520 | avg_loss: 0.211106 | gender_precise: 90.000000 (12217/13440) [105/186]\n",
      "gender_loss: 0.11676391214132309\n",
      "train_loss: 0.116764 | avg_loss: 0.210216 | gender_precise: 90.000000 (12339/13568) [106/186]\n",
      "gender_loss: 0.20869269967079163\n",
      "train_loss: 0.208693 | avg_loss: 0.210202 | gender_precise: 90.000000 (12455/13696) [107/186]\n",
      "gender_loss: 0.19977755844593048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.199778 | avg_loss: 0.210106 | gender_precise: 90.000000 (12574/13824) [108/186]\n",
      "gender_loss: 0.20604848861694336\n",
      "train_loss: 0.206048 | avg_loss: 0.210068 | gender_precise: 90.000000 (12692/13952) [109/186]\n",
      "gender_loss: 0.20235905051231384\n",
      "train_loss: 0.202359 | avg_loss: 0.209998 | gender_precise: 90.000000 (12812/14080) [110/186]\n",
      "gender_loss: 0.17774313688278198\n",
      "train_loss: 0.177743 | avg_loss: 0.209708 | gender_precise: 91.000000 (12933/14208) [111/186]\n",
      "gender_loss: 0.25385263562202454\n",
      "train_loss: 0.253853 | avg_loss: 0.210102 | gender_precise: 91.000000 (13047/14336) [112/186]\n",
      "gender_loss: 0.27970972657203674\n",
      "train_loss: 0.279710 | avg_loss: 0.210718 | gender_precise: 90.000000 (13156/14464) [113/186]\n",
      "gender_loss: 0.21587315201759338\n",
      "train_loss: 0.215873 | avg_loss: 0.210763 | gender_precise: 90.000000 (13269/14592) [114/186]\n",
      "gender_loss: 0.19915196299552917\n",
      "train_loss: 0.199152 | avg_loss: 0.210662 | gender_precise: 90.000000 (13385/14720) [115/186]\n",
      "gender_loss: 0.17486974596977234\n",
      "train_loss: 0.174870 | avg_loss: 0.210354 | gender_precise: 90.000000 (13505/14848) [116/186]\n",
      "gender_loss: 0.23281483352184296\n",
      "train_loss: 0.232815 | avg_loss: 0.210546 | gender_precise: 90.000000 (13617/14976) [117/186]\n",
      "gender_loss: 0.2670864760875702\n",
      "train_loss: 0.267086 | avg_loss: 0.211025 | gender_precise: 90.000000 (13731/15104) [118/186]\n",
      "gender_loss: 0.2828548848628998\n",
      "train_loss: 0.282855 | avg_loss: 0.211628 | gender_precise: 90.000000 (13843/15232) [119/186]\n",
      "gender_loss: 0.2078312486410141\n",
      "train_loss: 0.207831 | avg_loss: 0.211597 | gender_precise: 90.000000 (13959/15360) [120/186]\n",
      "gender_loss: 0.27515143156051636\n",
      "train_loss: 0.275151 | avg_loss: 0.212122 | gender_precise: 90.000000 (14075/15488) [121/186]\n",
      "gender_loss: 0.20995068550109863\n",
      "train_loss: 0.209951 | avg_loss: 0.212104 | gender_precise: 90.000000 (14189/15616) [122/186]\n",
      "gender_loss: 0.24595670402050018\n",
      "train_loss: 0.245957 | avg_loss: 0.212379 | gender_precise: 90.000000 (14301/15744) [123/186]\n",
      "gender_loss: 0.28577089309692383\n",
      "train_loss: 0.285771 | avg_loss: 0.212971 | gender_precise: 90.000000 (14415/15872) [124/186]\n",
      "gender_loss: 0.1476309597492218\n",
      "train_loss: 0.147631 | avg_loss: 0.212448 | gender_precise: 90.000000 (14535/16000) [125/186]\n",
      "gender_loss: 0.2538323998451233\n",
      "train_loss: 0.253832 | avg_loss: 0.212777 | gender_precise: 90.000000 (14649/16128) [126/186]\n",
      "gender_loss: 0.22342664003372192\n",
      "train_loss: 0.223427 | avg_loss: 0.212861 | gender_precise: 90.000000 (14762/16256) [127/186]\n",
      "gender_loss: 0.18145060539245605\n",
      "train_loss: 0.181451 | avg_loss: 0.212615 | gender_precise: 90.000000 (14884/16384) [128/186]\n",
      "gender_loss: 0.2006607949733734\n",
      "train_loss: 0.200661 | avg_loss: 0.212523 | gender_precise: 90.000000 (14998/16512) [129/186]\n",
      "gender_loss: 0.18327374756336212\n",
      "train_loss: 0.183274 | avg_loss: 0.212298 | gender_precise: 90.000000 (15116/16640) [130/186]\n",
      "gender_loss: 0.1939702332019806\n",
      "train_loss: 0.193970 | avg_loss: 0.212158 | gender_precise: 90.000000 (15236/16768) [131/186]\n",
      "gender_loss: 0.22585904598236084\n",
      "train_loss: 0.225859 | avg_loss: 0.212262 | gender_precise: 90.000000 (15351/16896) [132/186]\n",
      "gender_loss: 0.1980682611465454\n",
      "train_loss: 0.198068 | avg_loss: 0.212155 | gender_precise: 90.000000 (15468/17024) [133/186]\n",
      "gender_loss: 0.2434801459312439\n",
      "train_loss: 0.243480 | avg_loss: 0.212389 | gender_precise: 90.000000 (15584/17152) [134/186]\n",
      "gender_loss: 0.261197566986084\n",
      "train_loss: 0.261198 | avg_loss: 0.212750 | gender_precise: 90.000000 (15699/17280) [135/186]\n",
      "gender_loss: 0.2351522147655487\n",
      "train_loss: 0.235152 | avg_loss: 0.212915 | gender_precise: 90.000000 (15819/17408) [136/186]\n",
      "gender_loss: 0.15458029508590698\n",
      "train_loss: 0.154580 | avg_loss: 0.212489 | gender_precise: 90.000000 (15940/17536) [137/186]\n",
      "gender_loss: 0.23573271930217743\n",
      "train_loss: 0.235733 | avg_loss: 0.212658 | gender_precise: 90.000000 (16055/17664) [138/186]\n",
      "gender_loss: 0.17727604508399963\n",
      "train_loss: 0.177276 | avg_loss: 0.212403 | gender_precise: 90.000000 (16175/17792) [139/186]\n",
      "gender_loss: 0.22439292073249817\n",
      "train_loss: 0.224393 | avg_loss: 0.212489 | gender_precise: 90.000000 (16288/17920) [140/186]\n",
      "gender_loss: 0.262135773897171\n",
      "train_loss: 0.262136 | avg_loss: 0.212841 | gender_precise: 90.000000 (16402/18048) [141/186]\n",
      "gender_loss: 0.18689148128032684\n",
      "train_loss: 0.186891 | avg_loss: 0.212658 | gender_precise: 90.000000 (16522/18176) [142/186]\n",
      "gender_loss: 0.31132224202156067\n",
      "train_loss: 0.311322 | avg_loss: 0.213348 | gender_precise: 90.000000 (16635/18304) [143/186]\n",
      "gender_loss: 0.15745370090007782\n",
      "train_loss: 0.157454 | avg_loss: 0.212960 | gender_precise: 90.000000 (16755/18432) [144/186]\n",
      "gender_loss: 0.17692139744758606\n",
      "train_loss: 0.176921 | avg_loss: 0.212711 | gender_precise: 90.000000 (16873/18560) [145/186]\n",
      "gender_loss: 0.21730937063694\n",
      "train_loss: 0.217309 | avg_loss: 0.212743 | gender_precise: 90.000000 (16986/18688) [146/186]\n",
      "gender_loss: 0.2600654661655426\n",
      "train_loss: 0.260065 | avg_loss: 0.213065 | gender_precise: 90.000000 (17098/18816) [147/186]\n",
      "gender_loss: 0.2976813316345215\n",
      "train_loss: 0.297681 | avg_loss: 0.213636 | gender_precise: 90.000000 (17210/18944) [148/186]\n",
      "gender_loss: 0.23334617912769318\n",
      "train_loss: 0.233346 | avg_loss: 0.213769 | gender_precise: 90.000000 (17323/19072) [149/186]\n",
      "gender_loss: 0.10675480961799622\n",
      "train_loss: 0.106755 | avg_loss: 0.213055 | gender_precise: 90.000000 (17446/19200) [150/186]\n",
      "gender_loss: 0.24902155995368958\n",
      "train_loss: 0.249022 | avg_loss: 0.213294 | gender_precise: 90.000000 (17564/19328) [151/186]\n",
      "gender_loss: 0.18834155797958374\n",
      "train_loss: 0.188342 | avg_loss: 0.213129 | gender_precise: 90.000000 (17679/19456) [152/186]\n",
      "gender_loss: 0.36200863122940063\n",
      "train_loss: 0.362009 | avg_loss: 0.214102 | gender_precise: 90.000000 (17789/19584) [153/186]\n",
      "gender_loss: 0.2413267195224762\n",
      "train_loss: 0.241327 | avg_loss: 0.214279 | gender_precise: 90.000000 (17900/19712) [154/186]\n",
      "gender_loss: 0.18159827589988708\n",
      "train_loss: 0.181598 | avg_loss: 0.214068 | gender_precise: 90.000000 (18018/19840) [155/186]\n",
      "gender_loss: 0.24839292466640472\n",
      "train_loss: 0.248393 | avg_loss: 0.214288 | gender_precise: 90.000000 (18135/19968) [156/186]\n",
      "gender_loss: 0.16255120933055878\n",
      "train_loss: 0.162551 | avg_loss: 0.213959 | gender_precise: 90.000000 (18255/20096) [157/186]\n",
      "gender_loss: 0.0973065197467804\n",
      "train_loss: 0.097307 | avg_loss: 0.213221 | gender_precise: 90.000000 (18381/20224) [158/186]\n",
      "gender_loss: 0.22224737703800201\n",
      "train_loss: 0.222247 | avg_loss: 0.213277 | gender_precise: 90.000000 (18494/20352) [159/186]\n",
      "gender_loss: 0.2205919772386551\n",
      "train_loss: 0.220592 | avg_loss: 0.213323 | gender_precise: 90.000000 (18606/20480) [160/186]\n",
      "gender_loss: 0.30457016825675964\n",
      "train_loss: 0.304570 | avg_loss: 0.213890 | gender_precise: 90.000000 (18717/20608) [161/186]\n",
      "gender_loss: 0.12181909382343292\n",
      "train_loss: 0.121819 | avg_loss: 0.213321 | gender_precise: 90.000000 (18839/20736) [162/186]\n",
      "gender_loss: 0.24845461547374725\n",
      "train_loss: 0.248455 | avg_loss: 0.213537 | gender_precise: 90.000000 (18951/20864) [163/186]\n",
      "gender_loss: 0.21202382445335388\n",
      "train_loss: 0.212024 | avg_loss: 0.213528 | gender_precise: 90.000000 (19066/20992) [164/186]\n",
      "gender_loss: 0.20012706518173218\n",
      "train_loss: 0.200127 | avg_loss: 0.213447 | gender_precise: 90.000000 (19185/21120) [165/186]\n",
      "gender_loss: 0.22863131761550903\n",
      "train_loss: 0.228631 | avg_loss: 0.213538 | gender_precise: 90.000000 (19302/21248) [166/186]\n",
      "gender_loss: 0.1678967922925949\n",
      "train_loss: 0.167897 | avg_loss: 0.213265 | gender_precise: 90.000000 (19422/21376) [167/186]\n",
      "gender_loss: 0.1264803558588028\n",
      "train_loss: 0.126480 | avg_loss: 0.212748 | gender_precise: 90.000000 (19544/21504) [168/186]\n",
      "gender_loss: 0.1939690113067627\n",
      "train_loss: 0.193969 | avg_loss: 0.212637 | gender_precise: 90.000000 (19659/21632) [169/186]\n",
      "gender_loss: 0.18525291979312897\n",
      "train_loss: 0.185253 | avg_loss: 0.212476 | gender_precise: 90.000000 (19779/21760) [170/186]\n",
      "gender_loss: 0.13160225749015808\n",
      "train_loss: 0.131602 | avg_loss: 0.212003 | gender_precise: 90.000000 (19899/21888) [171/186]\n",
      "gender_loss: 0.13023316860198975\n",
      "train_loss: 0.130233 | avg_loss: 0.211528 | gender_precise: 90.000000 (20019/22016) [172/186]\n",
      "gender_loss: 0.19341863691806793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.193419 | avg_loss: 0.211423 | gender_precise: 90.000000 (20137/22144) [173/186]\n",
      "gender_loss: 0.24388989806175232\n",
      "train_loss: 0.243890 | avg_loss: 0.211610 | gender_precise: 90.000000 (20251/22272) [174/186]\n",
      "gender_loss: 0.2728992998600006\n",
      "train_loss: 0.272899 | avg_loss: 0.211960 | gender_precise: 90.000000 (20362/22400) [175/186]\n",
      "gender_loss: 0.21734963357448578\n",
      "train_loss: 0.217350 | avg_loss: 0.211990 | gender_precise: 90.000000 (20481/22528) [176/186]\n",
      "gender_loss: 0.20179924368858337\n",
      "train_loss: 0.201799 | avg_loss: 0.211933 | gender_precise: 90.000000 (20596/22656) [177/186]\n",
      "gender_loss: 0.1646464616060257\n",
      "train_loss: 0.164646 | avg_loss: 0.211667 | gender_precise: 90.000000 (20713/22784) [178/186]\n",
      "gender_loss: 0.1549515575170517\n",
      "train_loss: 0.154952 | avg_loss: 0.211350 | gender_precise: 90.000000 (20832/22912) [179/186]\n",
      "gender_loss: 0.2360949069261551\n",
      "train_loss: 0.236095 | avg_loss: 0.211488 | gender_precise: 90.000000 (20947/23040) [180/186]\n",
      "gender_loss: 0.26989784836769104\n",
      "train_loss: 0.269898 | avg_loss: 0.211810 | gender_precise: 90.000000 (21055/23168) [181/186]\n",
      "gender_loss: 0.23027704656124115\n",
      "train_loss: 0.230277 | avg_loss: 0.211912 | gender_precise: 90.000000 (21165/23296) [182/186]\n",
      "gender_loss: 0.15834283828735352\n",
      "train_loss: 0.158343 | avg_loss: 0.211619 | gender_precise: 90.000000 (21282/23424) [183/186]\n",
      "gender_loss: 0.19162066280841827\n",
      "train_loss: 0.191621 | avg_loss: 0.211511 | gender_precise: 90.000000 (21400/23552) [184/186]\n",
      "gender_loss: 0.1885136216878891\n",
      "train_loss: 0.188514 | avg_loss: 0.211386 | gender_precise: 90.000000 (21520/23680) [185/186]\n",
      "gender_loss: 0.08013611286878586\n",
      "train_loss: 0.080136 | avg_loss: 0.210681 | gender_precise: 90.000000 (21547/23708) [186/186]\n",
      "\n",
      "Test\n",
      "gender_prec: 87.000000 (112/128) [1/2]\n",
      "gender_prec: 88.000000 (118/134) [2/2]\n",
      "Saving..\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, start_epoch+10):\n",
    "    print(\"Number epoch: {}\".format(epoch))\n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with a image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"/home/neosai/Downloads/46402_1951-02-15_2009.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"/home/neosai/Downloads/download.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = transform_test(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 150, 150])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 150, 150])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_img.unsqueeze_(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 150, 150])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = net(input_img.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.8809], device='cuda:0', grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "gender_preds = F.sigmoid(b)\n",
    "gender_preds = (gender_preds > 0.5).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.random.rand(128, 116)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 116)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.sum(np.arange(1, 117) * b, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3620.47253613])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[85,\n",
       " 102,\n",
       " 68,\n",
       " 83,\n",
       " 52,\n",
       " 13,\n",
       " 114,\n",
       " 105,\n",
       " 74,\n",
       " 19,\n",
       " 42,\n",
       " 1,\n",
       " 21,\n",
       " 95,\n",
       " 109,\n",
       " 83,\n",
       " 48,\n",
       " 104,\n",
       " 91,\n",
       " 39,\n",
       " 64,\n",
       " 3,\n",
       " 83,\n",
       " 9,\n",
       " 52,\n",
       " 26,\n",
       " 106,\n",
       " 25,\n",
       " 103,\n",
       " 34,\n",
       " 73,\n",
       " 27,\n",
       " 82,\n",
       " 54,\n",
       " 81,\n",
       " 34,\n",
       " 71,\n",
       " 112,\n",
       " 24,\n",
       " 77,\n",
       " 21,\n",
       " 39,\n",
       " 17,\n",
       " 83,\n",
       " 102,\n",
       " 21,\n",
       " 106,\n",
       " 101,\n",
       " 114,\n",
       " 101,\n",
       " 69,\n",
       " 44,\n",
       " 77,\n",
       " 103,\n",
       " 12,\n",
       " 47,\n",
       " 101,\n",
       " 30,\n",
       " 84,\n",
       " 48,\n",
       " 50,\n",
       " 100,\n",
       " 38,\n",
       " 8,\n",
       " 105,\n",
       " 97,\n",
       " 58,\n",
       " 13,\n",
       " 91,\n",
       " 47,\n",
       " 93,\n",
       " 97,\n",
       " 61,\n",
       " 16,\n",
       " 41,\n",
       " 114,\n",
       " 105,\n",
       " 102,\n",
       " 39,\n",
       " 42,\n",
       " 87,\n",
       " 106,\n",
       " 70,\n",
       " 13,\n",
       " 51,\n",
       " 106,\n",
       " 51,\n",
       " 55,\n",
       " 104,\n",
       " 48,\n",
       " 90,\n",
       " 64,\n",
       " 40,\n",
       " 99,\n",
       " 5,\n",
       " 0,\n",
       " 45,\n",
       " 90,\n",
       " 5,\n",
       " 16,\n",
       " 1,\n",
       " 39,\n",
       " 67,\n",
       " 56,\n",
       " 62,\n",
       " 112,\n",
       " 35,\n",
       " 42,\n",
       " 86,\n",
       " 11,\n",
       " 41,\n",
       " 102,\n",
       " 19,\n",
       " 78,\n",
       " 71,\n",
       " 74]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.argmax(b[i]) for i in range(0, 116)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function ndarray.argmax>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0].argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7162959670689439"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0][55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.48304033, 0.77516863, 0.97833413, 0.3871517 , 0.24357855,\n",
       "        0.15773135, 0.53445515, 0.92273702, 0.13137669, 0.14347272,\n",
       "        0.39719973, 0.95451412, 0.04828658, 0.97270312, 0.11151566,\n",
       "        0.59834198, 0.20499689, 0.76103823, 0.11478081, 0.64958808,\n",
       "        0.67512689, 0.85111405, 0.96028944, 0.50181462, 0.83416862,\n",
       "        0.99322512, 0.60526135, 0.11691834, 0.27786215, 0.47205074,\n",
       "        0.77459759, 0.06659621, 0.94212423, 0.27200115, 0.13643705,\n",
       "        0.42923546, 0.59603223, 0.10297902, 0.3353779 , 0.73987667,\n",
       "        0.70128138, 0.98503977, 0.99805381, 0.11922939, 0.72293112,\n",
       "        0.24500441, 0.57040028, 0.03973017, 0.39401589, 0.05505866,\n",
       "        0.44677099, 0.14949467, 0.79249604, 0.61423846, 0.8821324 ,\n",
       "        0.99992684, 0.82861075, 0.99426677, 0.36245055, 0.19003802,\n",
       "        0.91026761, 0.21190709, 0.21237699, 0.68614634, 0.65465492,\n",
       "        0.9076976 , 0.13159407, 0.80854219, 0.24745792, 0.92374191,\n",
       "        0.90822876, 0.06291042, 0.6143676 , 0.22407705, 0.86394089,\n",
       "        0.75085163, 0.57894359, 0.84943937, 0.25297228, 0.54708524,\n",
       "        0.55864296, 0.03277644, 0.81844203, 0.44177229, 0.91436546,\n",
       "        0.9903016 , 0.82783808, 0.75364316, 0.0685033 , 0.54779228,\n",
       "        0.41567697, 0.97484005, 0.17508363, 0.91610037, 0.65812347,\n",
       "        0.32195311, 0.29423009, 0.30784196, 0.75864148, 0.56710566,\n",
       "        0.02296905, 0.06267149, 0.08902721, 0.68261061, 0.40277359,\n",
       "        0.94656316, 0.89192867, 0.16012449, 0.56329313, 0.31302107,\n",
       "        0.70360976, 0.80798811, 0.87701027, 0.03504195, 0.55738684,\n",
       "        0.45281138]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = torch.rand(128, 116)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7913, 0.4329, 0.3026,  ..., 0.6049, 0.1280, 0.6655],\n",
       "        [0.0876, 0.1363, 0.9883,  ..., 0.1942, 0.0160, 0.9075],\n",
       "        [0.3080, 0.1526, 0.0819,  ..., 0.0956, 0.0059, 0.6564],\n",
       "        ...,\n",
       "        [0.2536, 0.8113, 0.0131,  ..., 0.8667, 0.0907, 0.9448],\n",
       "        [0.2560, 0.2959, 0.4659,  ..., 0.0078, 0.2909, 0.6288],\n",
       "        [0.0643, 0.0982, 0.2114,  ..., 0.5803, 0.1505, 0.2233]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [torch.argmax(a[i]) for i in range(0, 116)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.from_numpy(np.array(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([116])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
